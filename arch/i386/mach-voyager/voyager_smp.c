multiline_comment|/* -*- mode: c; c-basic-offset: 8 -*- */
multiline_comment|/* Copyright (C) 1999,2001&n; *&n; * Author: J.E.J.Bottomley@HansenPartnership.com&n; *&n; * linux/arch/i386/kernel/voyager_smp.c&n; *&n; * This file provides all the same external entries as smp.c but uses&n; * the voyager hal to provide the functionality&n; */
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/delay.h&gt;
macro_line|#include &lt;linux/mc146818rtc.h&gt;
macro_line|#include &lt;linux/cache.h&gt;
macro_line|#include &lt;linux/interrupt.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/bootmem.h&gt;
macro_line|#include &lt;linux/completion.h&gt;
macro_line|#include &lt;asm/desc.h&gt;
macro_line|#include &lt;asm/voyager.h&gt;
macro_line|#include &lt;asm/vic.h&gt;
macro_line|#include &lt;asm/pgalloc.h&gt;
macro_line|#include &lt;asm/mtrr.h&gt;
macro_line|#include &lt;asm/pgalloc.h&gt;
macro_line|#include &lt;asm/tlbflush.h&gt;
macro_line|#include &lt;asm/desc.h&gt;
macro_line|#include &lt;asm/arch_hooks.h&gt;
macro_line|#include &lt;linux/irq.h&gt;
DECL|variable|reboot_smp
r_int
id|reboot_smp
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* TLB state -- visible externally, indexed physically */
DECL|variable|__cacheline_aligned
r_struct
id|tlb_state
id|cpu_tlbstate
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
op_assign
(brace
(braket
l_int|0
dot
dot
dot
id|NR_CPUS
op_minus
l_int|1
)braket
op_assign
(brace
op_amp
id|init_mm
comma
l_int|0
)brace
)brace
suffix:semicolon
multiline_comment|/* CPU IRQ affinity -- set to all ones initially */
DECL|variable|__cacheline_aligned
r_static
r_int
r_int
id|cpu_irq_affinity
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
op_assign
(brace
(braket
l_int|0
dot
dot
dot
id|NR_CPUS
op_minus
l_int|1
)braket
op_assign
op_complement
l_int|0UL
)brace
suffix:semicolon
multiline_comment|/* Set when the idlers are all forked - Set in main.c but not actually&n; * used by any other parts of the kernel */
DECL|variable|smp_threads_ready
r_int
id|smp_threads_ready
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* per CPU data structure (for /proc/cpuinfo et al), visible externally&n; * indexed physically */
DECL|variable|__cacheline_aligned
r_struct
id|cpuinfo_x86
id|cpu_data
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
multiline_comment|/* physical ID of the CPU used to boot the system */
DECL|variable|boot_cpu_id
r_int
r_char
id|boot_cpu_id
suffix:semicolon
multiline_comment|/* The memory line addresses for the Quad CPIs */
DECL|variable|__cacheline_aligned
r_struct
id|voyager_qic_cpi
op_star
id|voyager_quad_cpi_addr
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
multiline_comment|/* The masks for the Extended VIC processors, filled in by cat_init */
DECL|variable|voyager_extended_vic_processors
id|__u32
id|voyager_extended_vic_processors
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* Masks for the extended Quad processors which cannot be VIC booted */
DECL|variable|voyager_allowed_boot_processors
id|__u32
id|voyager_allowed_boot_processors
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* The mask for the Quad Processors (both extended and non-extended) */
DECL|variable|voyager_quad_processors
id|__u32
id|voyager_quad_processors
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* Total count of live CPUs, used in process.c to display&n; * the CPU information and in irq.c for the per CPU irq&n; * activity count.  Finally exported by i386_ksyms.c */
DECL|variable|voyager_extended_cpus
r_static
r_int
id|voyager_extended_cpus
op_assign
l_int|1
suffix:semicolon
multiline_comment|/* Have we found an SMP box - used by time.c to do the profiling&n;   interrupt for timeslicing; do not set to 1 until the per CPU timer&n;   interrupt is active */
DECL|variable|smp_found_config
r_int
id|smp_found_config
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* Used for the invalidate map that&squot;s also checked in the spinlock */
DECL|variable|smp_invalidate_needed
r_volatile
r_int
r_int
id|smp_invalidate_needed
suffix:semicolon
multiline_comment|/* Bitmask of currently online CPUs - used by setup.c for&n;   /proc/cpuinfo, visible externally but still physical */
DECL|variable|cpu_online_map
r_int
r_int
id|cpu_online_map
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* Bitmask of CPUs present in the system - exported by i386_syms.c, used&n; * by scheduler but indexed physically */
DECL|variable|phys_cpu_present_map
r_int
r_int
id|phys_cpu_present_map
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* estimate of time used to flush the SMP-local cache - used in&n; * processor affinity calculations */
DECL|variable|cacheflush_time
id|cycles_t
id|cacheflush_time
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* cache decay ticks for scheduler---a fairly useless quantity for the&n;   voyager system with its odd affinity and huge L3 cache */
DECL|variable|cache_decay_ticks
r_int
r_int
id|cache_decay_ticks
op_assign
l_int|20
suffix:semicolon
multiline_comment|/* The internal functions */
r_static
r_void
id|send_CPI
c_func
(paren
id|__u32
id|cpuset
comma
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_void
id|ack_CPI
c_func
(paren
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_int
id|ack_QIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_void
id|ack_special_QIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_void
id|ack_VIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_void
id|send_CPI_allbutself
c_func
(paren
id|__u8
id|cpi
)paren
suffix:semicolon
r_static
r_void
id|enable_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|disable_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_int
r_int
id|startup_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|enable_local_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|disable_local_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|before_handle_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|after_handle_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|set_vic_irq_affinity
c_func
(paren
r_int
r_int
id|irq
comma
r_int
r_int
id|mask
)paren
suffix:semicolon
r_static
r_void
id|ack_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
suffix:semicolon
r_static
r_void
id|vic_enable_cpi
c_func
(paren
r_void
)paren
suffix:semicolon
r_static
r_void
id|do_boot_cpu
c_func
(paren
id|__u8
id|cpuid
)paren
suffix:semicolon
r_static
r_void
id|do_quad_bootstrap
c_func
(paren
r_void
)paren
suffix:semicolon
r_static
r_inline
r_void
id|wrapper_smp_local_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
)paren
suffix:semicolon
r_int
id|hard_smp_processor_id
c_func
(paren
r_void
)paren
suffix:semicolon
multiline_comment|/* Inline functions */
r_static
r_inline
r_void
DECL|function|send_one_QIC_CPI
id|send_one_QIC_CPI
c_func
(paren
id|__u8
id|cpu
comma
id|__u8
id|cpi
)paren
(brace
id|voyager_quad_cpi_addr
(braket
id|cpu
)braket
op_member_access_from_pointer
id|qic_cpi
(braket
id|cpi
)braket
dot
id|cpi
op_assign
(paren
id|smp_processor_id
c_func
(paren
)paren
op_lshift
l_int|16
)paren
op_plus
id|cpi
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|send_QIC_CPI
id|send_QIC_CPI
c_func
(paren
id|__u32
id|cpuset
comma
id|__u8
id|cpi
)paren
(brace
r_int
id|mask
suffix:semicolon
id|__u8
id|cpu
suffix:semicolon
id|for_each_cpu
c_func
(paren
id|cpu
comma
id|mask
)paren
(brace
r_if
c_cond
(paren
id|cpuset
op_amp
(paren
l_int|1
op_lshift
id|cpu
)paren
)paren
(brace
macro_line|#ifdef VOYAGER_DEBUG
r_if
c_cond
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|cpu
comma
id|cpu_online_map
)paren
)paren
(brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;CPU%d sending cpi %d to CPU%d not in cpu_online_map&bslash;n&quot;
comma
id|hard_smp_processor_id
c_func
(paren
)paren
comma
id|cpi
comma
id|cpu
)paren
)paren
suffix:semicolon
)brace
macro_line|#endif
id|send_one_QIC_CPI
c_func
(paren
id|cpu
comma
id|cpi
op_minus
id|QIC_CPI_OFFSET
)paren
suffix:semicolon
)brace
)brace
)brace
r_static
r_inline
r_void
DECL|function|send_one_CPI
id|send_one_CPI
c_func
(paren
id|__u8
id|cpu
comma
id|__u8
id|cpi
)paren
(brace
r_if
c_cond
(paren
id|voyager_quad_processors
op_amp
(paren
l_int|1
op_lshift
id|cpu
)paren
)paren
(brace
id|send_one_QIC_CPI
c_func
(paren
id|cpu
comma
id|cpi
op_minus
id|QIC_CPI_OFFSET
)paren
suffix:semicolon
)brace
r_else
id|send_CPI
c_func
(paren
l_int|1
op_lshift
id|cpu
comma
id|cpi
)paren
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|send_CPI_allbutself
id|send_CPI_allbutself
c_func
(paren
id|__u8
id|cpi
)paren
(brace
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|__u32
id|mask
op_assign
(paren
id|cpu_online_map
op_amp
(paren
op_complement
(paren
l_int|1
op_lshift
id|cpu
)paren
)paren
)paren
suffix:semicolon
id|send_CPI
c_func
(paren
id|mask
comma
id|cpi
)paren
suffix:semicolon
)brace
r_static
r_inline
r_int
DECL|function|is_cpu_quad
id|is_cpu_quad
c_func
(paren
r_void
)paren
(brace
id|__u8
id|cpumask
op_assign
id|inb
c_func
(paren
id|VIC_PROC_WHO_AM_I
)paren
suffix:semicolon
r_return
(paren
(paren
id|cpumask
op_amp
id|QUAD_IDENTIFIER
)paren
op_eq
id|QUAD_IDENTIFIER
)paren
suffix:semicolon
)brace
r_static
r_inline
r_int
DECL|function|is_cpu_extended
id|is_cpu_extended
c_func
(paren
r_void
)paren
(brace
id|__u8
id|cpu
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
r_return
id|voyager_extended_vic_processors
op_amp
(paren
l_int|1
op_lshift
id|cpu
)paren
suffix:semicolon
)brace
r_static
r_inline
r_int
DECL|function|is_cpu_vic_boot
id|is_cpu_vic_boot
c_func
(paren
r_void
)paren
(brace
id|__u8
id|cpu
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
r_return
id|voyager_extended_vic_processors
op_amp
id|voyager_allowed_boot_processors
op_amp
(paren
l_int|1
op_lshift
id|cpu
)paren
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|ack_CPI
id|ack_CPI
c_func
(paren
id|__u8
id|cpi
)paren
(brace
r_switch
c_cond
(paren
id|cpi
)paren
(brace
r_case
id|VIC_CPU_BOOT_CPI
suffix:colon
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
op_logical_and
op_logical_neg
id|is_cpu_vic_boot
c_func
(paren
)paren
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|cpi
)paren
suffix:semicolon
)brace
r_else
id|ack_VIC_CPI
c_func
(paren
id|cpi
)paren
suffix:semicolon
r_break
suffix:semicolon
r_case
id|VIC_SYS_INT
suffix:colon
r_case
id|VIC_CMN_INT
suffix:colon
multiline_comment|/* These are slightly strange.  Even on the Quad card,&n;&t;&t; * They are vectored as VIC CPIs */
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
)paren
(brace
id|ack_special_QIC_CPI
c_func
(paren
id|cpi
)paren
suffix:semicolon
)brace
r_else
id|ack_VIC_CPI
c_func
(paren
id|cpi
)paren
suffix:semicolon
r_break
suffix:semicolon
r_default
suffix:colon
id|printk
c_func
(paren
l_string|&quot;VOYAGER ERROR: CPI%d is in common CPI code&bslash;n&quot;
comma
id|cpi
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
)brace
multiline_comment|/* local variables */
multiline_comment|/* The VIC IRQ descriptors -- these look almost identical to the&n; * 8259 IRQs except that masks and things must be kept per processor&n; */
DECL|variable|vic_irq_type
r_static
r_struct
id|hw_interrupt_type
id|vic_irq_type
op_assign
(brace
l_string|&quot;VIC-level&quot;
comma
id|startup_vic_irq
comma
multiline_comment|/* startup */
id|disable_vic_irq
comma
multiline_comment|/* shutdown */
id|enable_vic_irq
comma
multiline_comment|/* enable */
id|disable_vic_irq
comma
multiline_comment|/* disable */
id|before_handle_vic_irq
comma
multiline_comment|/* ack */
id|after_handle_vic_irq
comma
multiline_comment|/* end */
id|set_vic_irq_affinity
comma
multiline_comment|/* affinity */
)brace
suffix:semicolon
multiline_comment|/* used to count up as CPUs are brought on line (starts at 0) */
DECL|variable|cpucount
r_static
r_int
id|cpucount
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* steal a page from the bottom of memory for the trampoline and&n; * squirrel its address away here.  This will be in kernel virtual&n; * space */
DECL|variable|trampoline_base
r_static
id|__u32
id|trampoline_base
suffix:semicolon
multiline_comment|/* The per cpu profile stuff - used in smp_local_timer_interrupt */
r_static
id|DEFINE_PER_CPU
c_func
(paren
r_int
comma
id|prof_multiplier
)paren
op_assign
l_int|1
suffix:semicolon
r_static
id|DEFINE_PER_CPU
c_func
(paren
r_int
comma
id|prof_old_multiplier
)paren
op_assign
l_int|1
suffix:semicolon
r_static
id|DEFINE_PER_CPU
c_func
(paren
r_int
comma
id|prof_counter
)paren
op_assign
l_int|1
suffix:semicolon
multiline_comment|/* the map used to check if a CPU has booted */
DECL|variable|cpu_booted_map
r_static
id|__u32
id|cpu_booted_map
suffix:semicolon
multiline_comment|/* the synchronize flag used to hold all secondary CPUs spinning in&n; * a tight loop until the boot sequence is ready for them */
DECL|variable|smp_commenced_mask
r_static
r_int
r_int
id|smp_commenced_mask
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* This is for the new dynamic CPU boot code */
DECL|variable|cpu_callin_map
r_volatile
r_int
r_int
id|cpu_callin_map
op_assign
l_int|0
suffix:semicolon
DECL|variable|cpu_callout_map
r_volatile
r_int
r_int
id|cpu_callout_map
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* The per processor IRQ masks (these are usually kept in sync) */
DECL|variable|__cacheline_aligned
r_static
id|__u16
id|vic_irq_mask
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
multiline_comment|/* the list of IRQs to be enabled by the VIC_ENABLE_IRQ_CPI */
DECL|variable|__cacheline_aligned
r_static
id|__u16
id|vic_irq_enable_mask
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
op_assign
(brace
l_int|0
)brace
suffix:semicolon
multiline_comment|/* Lock for enable/disable of VIC interrupts */
DECL|variable|__cacheline_aligned
r_static
id|spinlock_t
id|vic_irq_lock
id|__cacheline_aligned
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
multiline_comment|/* The boot processor is correctly set up in PC mode when it &n; * comes up, but the secondaries need their master/slave 8259&n; * pairs initializing correctly */
multiline_comment|/* Interrupt counters (per cpu) and total - used to try to&n; * even up the interrupt handling routines */
DECL|variable|vic_intr_total
r_static
r_int
id|vic_intr_total
op_assign
l_int|0
suffix:semicolon
DECL|variable|__cacheline_aligned
r_static
r_int
id|vic_intr_count
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
op_assign
(brace
l_int|0
)brace
suffix:semicolon
DECL|variable|__cacheline_aligned
r_static
r_int
r_int
id|vic_tick
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
op_assign
(brace
l_int|0
)brace
suffix:semicolon
multiline_comment|/* Since we can only use CPI0, we fake all the other CPIs */
DECL|variable|__cacheline_aligned
r_static
r_int
r_int
id|vic_cpi_mailbox
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
multiline_comment|/* debugging routine to read the isr of the cpu&squot;s pic */
r_static
r_inline
id|__u16
DECL|function|vic_read_isr
id|vic_read_isr
c_func
(paren
r_void
)paren
(brace
id|__u16
id|isr
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0b
comma
l_int|0xa0
)paren
suffix:semicolon
id|isr
op_assign
id|inb
c_func
(paren
l_int|0xa0
)paren
op_lshift
l_int|8
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0b
comma
l_int|0x20
)paren
suffix:semicolon
id|isr
op_or_assign
id|inb
c_func
(paren
l_int|0x20
)paren
suffix:semicolon
r_return
id|isr
suffix:semicolon
)brace
r_static
id|__init
r_void
DECL|function|qic_setup
id|qic_setup
c_func
(paren
r_void
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|is_cpu_quad
c_func
(paren
)paren
)paren
(brace
multiline_comment|/* not a quad, no setup */
r_return
suffix:semicolon
)brace
id|outb
c_func
(paren
id|QIC_DEFAULT_MASK0
comma
id|QIC_MASK_REGISTER0
)paren
suffix:semicolon
id|outb
c_func
(paren
id|QIC_CPI_ENABLE
comma
id|QIC_MASK_REGISTER1
)paren
suffix:semicolon
r_if
c_cond
(paren
id|is_cpu_extended
c_func
(paren
)paren
)paren
(brace
multiline_comment|/* the QIC duplicate of the VIC base register */
id|outb
c_func
(paren
id|VIC_DEFAULT_CPI_BASE
comma
id|QIC_VIC_CPI_BASE_REGISTER
)paren
suffix:semicolon
id|outb
c_func
(paren
id|QIC_DEFAULT_CPI_BASE
comma
id|QIC_CPI_BASE_REGISTER
)paren
suffix:semicolon
multiline_comment|/* FIXME: should set up the QIC timer and memory parity&n;&t;&t; * error vectors here */
)brace
)brace
r_static
id|__init
r_void
DECL|function|vic_setup_pic
id|vic_setup_pic
c_func
(paren
r_void
)paren
(brace
id|outb
c_func
(paren
l_int|1
comma
id|VIC_REDIRECT_REGISTER_1
)paren
suffix:semicolon
multiline_comment|/* clear the claim registers for dynamic routing */
id|outb
c_func
(paren
l_int|0
comma
id|VIC_CLAIM_REGISTER_0
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0
comma
id|VIC_CLAIM_REGISTER_1
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0
comma
id|VIC_PRIORITY_REGISTER
)paren
suffix:semicolon
multiline_comment|/* Set the Primary and Secondary Microchannel vector&n;&t; * bases to be the same as the ordinary interrupts&n;&t; *&n;&t; * FIXME: This would be more efficient using separate&n;&t; * vectors. */
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
comma
id|VIC_PRIMARY_MC_BASE
)paren
suffix:semicolon
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
comma
id|VIC_SECONDARY_MC_BASE
)paren
suffix:semicolon
multiline_comment|/* Now initiallise the master PIC belonging to this CPU by&n;&t; * sending the four ICWs */
multiline_comment|/* ICW1: level triggered, ICW4 needed */
id|outb
c_func
(paren
l_int|0x19
comma
l_int|0x20
)paren
suffix:semicolon
multiline_comment|/* ICW2: vector base */
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
comma
l_int|0x21
)paren
suffix:semicolon
multiline_comment|/* ICW3: slave at line 2 */
id|outb
c_func
(paren
l_int|0x04
comma
l_int|0x21
)paren
suffix:semicolon
multiline_comment|/* ICW4: 8086 mode */
id|outb
c_func
(paren
l_int|0x01
comma
l_int|0x21
)paren
suffix:semicolon
multiline_comment|/* now the same for the slave PIC */
multiline_comment|/* ICW1: level trigger, ICW4 needed */
id|outb
c_func
(paren
l_int|0x19
comma
l_int|0xA0
)paren
suffix:semicolon
multiline_comment|/* ICW2: slave vector base */
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
op_plus
l_int|8
comma
l_int|0xA1
)paren
suffix:semicolon
multiline_comment|/* ICW3: slave ID */
id|outb
c_func
(paren
l_int|0x02
comma
l_int|0xA1
)paren
suffix:semicolon
multiline_comment|/* ICW4: 8086 mode */
id|outb
c_func
(paren
l_int|0x01
comma
l_int|0xA1
)paren
suffix:semicolon
)brace
r_static
r_void
DECL|function|do_quad_bootstrap
id|do_quad_bootstrap
c_func
(paren
r_void
)paren
(brace
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
op_logical_and
id|is_cpu_vic_boot
c_func
(paren
)paren
)paren
(brace
r_int
id|i
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|__u8
id|cpuid
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
l_int|4
suffix:semicolon
id|i
op_increment
)paren
(brace
multiline_comment|/* FIXME: this would be &gt;&gt;3 &amp;0x7 on the 32 way */
r_if
c_cond
(paren
(paren
(paren
id|cpuid
op_rshift
l_int|2
)paren
op_amp
l_int|0x03
)paren
op_eq
id|i
)paren
(brace
multiline_comment|/* don&squot;t lower our own mask! */
r_continue
suffix:semicolon
)brace
multiline_comment|/* masquerade as local Quad CPU */
id|outb
c_func
(paren
id|QIC_CPUID_ENABLE
op_or
id|i
comma
id|QIC_PROCESSOR_ID
)paren
suffix:semicolon
multiline_comment|/* enable the startup CPI */
id|outb
c_func
(paren
id|QIC_BOOT_CPI_MASK
comma
id|QIC_MASK_REGISTER1
)paren
suffix:semicolon
multiline_comment|/* restore cpu id */
id|outb
c_func
(paren
l_int|0
comma
id|QIC_PROCESSOR_ID
)paren
suffix:semicolon
)brace
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* Set up all the basic stuff: read the SMP config and make all the&n; * SMP information reflect only the boot cpu.  All others will be&n; * brought on-line later. */
r_void
id|__init
DECL|function|find_smp_config
id|find_smp_config
c_func
(paren
r_void
)paren
(brace
r_int
id|i
suffix:semicolon
id|boot_cpu_id
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: Boot cpu is %d&bslash;n&quot;
comma
id|boot_cpu_id
)paren
suffix:semicolon
multiline_comment|/* initialize the CPU structures (moved from smp_boot_cpus) */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
id|cpu_irq_affinity
(braket
id|i
)braket
op_assign
op_complement
l_int|0
suffix:semicolon
)brace
id|cpu_online_map
op_assign
(paren
l_int|1
op_lshift
id|boot_cpu_id
)paren
suffix:semicolon
multiline_comment|/* The boot CPU must be extended */
id|voyager_extended_vic_processors
op_assign
l_int|1
op_lshift
id|boot_cpu_id
suffix:semicolon
multiline_comment|/* initially, all of the first 8 cpu&squot;s can boot */
id|voyager_allowed_boot_processors
op_assign
l_int|0xff
suffix:semicolon
multiline_comment|/* set up everything for just this CPU, we can alter&n;&t; * this as we start the other CPUs later */
multiline_comment|/* now get the CPU disposition from the extended CMOS */
id|phys_cpu_present_map
op_assign
id|voyager_extended_cmos_read
c_func
(paren
id|VOYAGER_PROCESSOR_PRESENT_MASK
)paren
suffix:semicolon
id|phys_cpu_present_map
op_or_assign
id|voyager_extended_cmos_read
c_func
(paren
id|VOYAGER_PROCESSOR_PRESENT_MASK
op_plus
l_int|1
)paren
op_lshift
l_int|8
suffix:semicolon
id|phys_cpu_present_map
op_or_assign
id|voyager_extended_cmos_read
c_func
(paren
id|VOYAGER_PROCESSOR_PRESENT_MASK
op_plus
l_int|2
)paren
op_lshift
l_int|16
suffix:semicolon
id|phys_cpu_present_map
op_or_assign
id|voyager_extended_cmos_read
c_func
(paren
id|VOYAGER_PROCESSOR_PRESENT_MASK
op_plus
l_int|3
)paren
op_lshift
l_int|24
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: phys_cpu_present_map = 0x%lx&bslash;n&quot;
comma
id|phys_cpu_present_map
)paren
suffix:semicolon
multiline_comment|/* Here we set up the VIC to enable SMP */
multiline_comment|/* enable the CPIs by writing the base vector to their register */
id|outb
c_func
(paren
id|VIC_DEFAULT_CPI_BASE
comma
id|VIC_CPI_BASE_REGISTER
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|1
comma
id|VIC_REDIRECT_REGISTER_1
)paren
suffix:semicolon
multiline_comment|/* set the claim registers for static routing --- Boot CPU gets&n;&t; * all interrupts untill all other CPUs started */
id|outb
c_func
(paren
l_int|0xff
comma
id|VIC_CLAIM_REGISTER_0
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0xff
comma
id|VIC_CLAIM_REGISTER_1
)paren
suffix:semicolon
multiline_comment|/* Set the Primary and Secondary Microchannel vector&n;&t; * bases to be the same as the ordinary interrupts&n;&t; *&n;&t; * FIXME: This would be more efficient using separate&n;&t; * vectors. */
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
comma
id|VIC_PRIMARY_MC_BASE
)paren
suffix:semicolon
id|outb
c_func
(paren
id|FIRST_EXTERNAL_VECTOR
comma
id|VIC_SECONDARY_MC_BASE
)paren
suffix:semicolon
multiline_comment|/* Finally tell the firmware that we&squot;re driving */
id|outb
c_func
(paren
id|inb
c_func
(paren
id|VOYAGER_SUS_IN_CONTROL_PORT
)paren
op_or
id|VOYAGER_IN_CONTROL_FLAG
comma
id|VOYAGER_SUS_IN_CONTROL_PORT
)paren
suffix:semicolon
id|current_thread_info
c_func
(paren
)paren
op_member_access_from_pointer
id|cpu
op_assign
id|boot_cpu_id
suffix:semicolon
)brace
multiline_comment|/*&n; *&t;The bootstrap kernel entry code has set these up. Save them&n; *&t;for a given CPU, id is physical */
r_void
id|__init
DECL|function|smp_store_cpu_info
id|smp_store_cpu_info
c_func
(paren
r_int
id|id
)paren
(brace
r_struct
id|cpuinfo_x86
op_star
id|c
op_assign
op_amp
id|cpu_data
(braket
id|id
)braket
suffix:semicolon
op_star
id|c
op_assign
id|boot_cpu_data
suffix:semicolon
id|identify_cpu
c_func
(paren
id|c
)paren
suffix:semicolon
)brace
multiline_comment|/* set up the trampoline and return the physical address of the code */
r_static
id|__u32
id|__init
DECL|function|setup_trampoline
id|setup_trampoline
c_func
(paren
r_void
)paren
(brace
multiline_comment|/* these two are global symbols in trampoline.S */
r_extern
id|__u8
id|trampoline_end
(braket
)braket
suffix:semicolon
r_extern
id|__u8
id|trampoline_data
(braket
)braket
suffix:semicolon
id|memcpy
c_func
(paren
(paren
id|__u8
op_star
)paren
id|trampoline_base
comma
id|trampoline_data
comma
id|trampoline_end
op_minus
id|trampoline_data
)paren
suffix:semicolon
r_return
id|virt_to_phys
c_func
(paren
(paren
id|__u8
op_star
)paren
id|trampoline_base
)paren
suffix:semicolon
)brace
multiline_comment|/* Routine initially called when a non-boot CPU is brought online */
r_int
id|__init
DECL|function|start_secondary
id|start_secondary
c_func
(paren
r_void
op_star
id|unused
)paren
(brace
id|__u8
id|cpuid
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* external functions not defined in the headers */
r_extern
r_void
id|calibrate_delay
c_func
(paren
r_void
)paren
suffix:semicolon
r_extern
r_int
id|cpu_idle
c_func
(paren
r_void
)paren
suffix:semicolon
id|cpu_init
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* OK, we&squot;re in the routine */
id|ack_CPI
c_func
(paren
id|VIC_CPU_BOOT_CPI
)paren
suffix:semicolon
multiline_comment|/* setup the 8259 master slave pair belonging to this CPU ---&n;         * we won&squot;t actually receive any until the boot CPU&n;         * relinquishes it&squot;s static routing mask */
id|vic_setup_pic
c_func
(paren
)paren
suffix:semicolon
id|qic_setup
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
op_logical_and
op_logical_neg
id|is_cpu_vic_boot
c_func
(paren
)paren
)paren
(brace
multiline_comment|/* clear the boot CPI */
id|__u8
id|dummy
suffix:semicolon
id|dummy
op_assign
id|voyager_quad_cpi_addr
(braket
id|cpuid
)braket
op_member_access_from_pointer
id|qic_cpi
(braket
id|VIC_CPU_BOOT_CPI
)braket
dot
id|cpi
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;read dummy %d&bslash;n&quot;
comma
id|dummy
)paren
suffix:semicolon
)brace
multiline_comment|/* lower the mask to receive CPIs */
id|vic_enable_cpi
c_func
(paren
)paren
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: CPU%d, stack at about %p&bslash;n&quot;
comma
id|cpuid
comma
op_amp
id|cpuid
)paren
)paren
suffix:semicolon
multiline_comment|/* enable interrupts */
id|local_irq_enable
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* get our bogomips */
id|calibrate_delay
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* save our processor parameters */
id|smp_store_cpu_info
c_func
(paren
id|cpuid
)paren
suffix:semicolon
multiline_comment|/* if we&squot;re a quad, we may need to bootstrap other CPUs */
id|do_quad_bootstrap
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* FIXME: this is rather a poor hack to prevent the CPU&n;&t; * activating softirqs while it&squot;s supposed to be waiting for&n;&t; * permission to proceed.  Without this, the new per CPU stuff&n;&t; * in the softirqs will fail */
id|local_irq_disable
c_func
(paren
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|cpuid
comma
op_amp
id|cpu_callin_map
)paren
suffix:semicolon
multiline_comment|/* signal that we&squot;re done */
id|cpu_booted_map
op_assign
l_int|1
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|cpuid
comma
op_amp
id|smp_commenced_mask
)paren
)paren
id|rep_nop
c_func
(paren
)paren
suffix:semicolon
id|local_irq_enable
c_func
(paren
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|cpuid
comma
op_amp
id|cpu_online_map
)paren
suffix:semicolon
id|wmb
c_func
(paren
)paren
suffix:semicolon
r_return
id|cpu_idle
c_func
(paren
)paren
suffix:semicolon
)brace
r_static
r_struct
id|task_struct
op_star
id|__init
DECL|function|fork_by_hand
id|fork_by_hand
c_func
(paren
r_void
)paren
(brace
r_struct
id|pt_regs
id|regs
suffix:semicolon
multiline_comment|/* don&squot;t care about the eip and regs settings since we&squot;ll&n;&t; * never reschedule the forked task. */
r_return
id|copy_process
c_func
(paren
id|CLONE_VM
op_or
id|CLONE_IDLETASK
comma
l_int|0
comma
op_amp
id|regs
comma
l_int|0
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
)brace
multiline_comment|/* Routine to kick start the given CPU and wait for it to report ready&n; * (or timeout in startup).  When this routine returns, the requested&n; * CPU is either fully running and configured or known to be dead.&n; *&n; * We call this routine sequentially 1 CPU at a time, so no need for&n; * locking */
r_static
r_void
id|__init
DECL|function|do_boot_cpu
id|do_boot_cpu
c_func
(paren
id|__u8
id|cpu
)paren
(brace
r_struct
id|task_struct
op_star
id|idle
suffix:semicolon
r_int
id|timeout
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
r_int
id|quad_boot
op_assign
(paren
l_int|1
op_lshift
id|cpu
)paren
op_amp
id|voyager_quad_processors
op_amp
op_complement
(paren
id|voyager_extended_vic_processors
op_amp
id|voyager_allowed_boot_processors
)paren
suffix:semicolon
multiline_comment|/* For the 486, we can&squot;t use the 4Mb page table trick, so&n;&t; * must map a region of memory */
macro_line|#ifdef CONFIG_M486
r_int
id|i
suffix:semicolon
r_int
r_int
op_star
id|page_table_copies
op_assign
(paren
r_int
r_int
op_star
)paren
id|__get_free_page
c_func
(paren
id|GFP_KERNEL
)paren
suffix:semicolon
macro_line|#endif
id|pgd_t
id|orig_swapper_pg_dir0
suffix:semicolon
multiline_comment|/* This is an area in head.S which was used to set up the&n;&t; * initial kernel stack.  We need to alter this to give the&n;&t; * booting CPU a new stack (taken from its idle process) */
r_extern
r_struct
(brace
id|__u8
op_star
id|esp
suffix:semicolon
r_int
r_int
id|ss
suffix:semicolon
)brace
id|stack_start
suffix:semicolon
multiline_comment|/* This is the format of the CPI IDT gate (in real mode) which&n;&t; * we&squot;re hijacking to boot the CPU */
r_union
id|IDTFormat
(brace
r_struct
id|seg
(brace
id|__u16
id|Offset
suffix:semicolon
id|__u16
id|Segment
suffix:semicolon
)brace
id|idt
suffix:semicolon
id|__u32
id|val
suffix:semicolon
)brace
id|hijack_source
suffix:semicolon
id|__u32
op_star
id|hijack_vector
suffix:semicolon
id|__u32
id|start_phys_address
op_assign
id|setup_trampoline
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* There&squot;s a clever trick to this: The linux trampoline is&n;&t; * compiled to begin at absolute location zero, so make the&n;&t; * address zero but have the data segment selector compensate&n;&t; * for the actual address */
id|hijack_source.idt.Offset
op_assign
id|start_phys_address
op_amp
l_int|0x000F
suffix:semicolon
id|hijack_source.idt.Segment
op_assign
(paren
id|start_phys_address
op_rshift
l_int|4
)paren
op_amp
l_int|0xFFFF
suffix:semicolon
id|cpucount
op_increment
suffix:semicolon
id|idle
op_assign
id|fork_by_hand
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|IS_ERR
c_func
(paren
id|idle
)paren
)paren
(brace
id|panic
c_func
(paren
l_string|&quot;failed fork for CPU%d&quot;
comma
id|cpu
)paren
suffix:semicolon
)brace
id|wake_up_forked_process
c_func
(paren
id|idle
)paren
suffix:semicolon
id|init_idle
c_func
(paren
id|idle
comma
id|cpu
)paren
suffix:semicolon
id|idle-&gt;thread.eip
op_assign
(paren
r_int
r_int
)paren
id|start_secondary
suffix:semicolon
id|unhash_process
c_func
(paren
id|idle
)paren
suffix:semicolon
multiline_comment|/* init_tasks (in sched.c) is indexed logically */
macro_line|#if 0
singleline_comment|// for AC kernels
id|stack_start.esp
op_assign
(paren
id|THREAD_SIZE
op_plus
(paren
id|__u8
op_star
)paren
id|TSK_TO_KSTACK
c_func
(paren
id|idle
)paren
)paren
suffix:semicolon
macro_line|#else
id|stack_start.esp
op_assign
(paren
r_void
op_star
)paren
(paren
l_int|1024
op_plus
id|PAGE_SIZE
op_plus
(paren
r_char
op_star
)paren
id|idle-&gt;thread_info
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/* Note: Don&squot;t modify initial ss override */
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: Booting CPU%d at 0x%lx[%x:%x], stack %p&bslash;n&quot;
comma
id|cpu
comma
(paren
r_int
r_int
)paren
id|hijack_source.val
comma
id|hijack_source.idt.Segment
comma
id|hijack_source.idt.Offset
comma
id|stack_start.esp
)paren
)paren
suffix:semicolon
multiline_comment|/* set the original swapper_pg_dir[0] to map 0 to 4Mb transparently&n;&t; * (so that the booting CPU can find start_32 */
id|orig_swapper_pg_dir0
op_assign
id|swapper_pg_dir
(braket
l_int|0
)braket
suffix:semicolon
macro_line|#ifdef CONFIG_M486
r_if
c_cond
(paren
id|page_table_copies
op_eq
l_int|NULL
)paren
(brace
id|panic
c_func
(paren
l_string|&quot;No free memory for 486 page tables&bslash;n&quot;
)paren
suffix:semicolon
)brace
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|PAGE_SIZE
op_div
r_sizeof
(paren
r_int
r_int
)paren
suffix:semicolon
id|i
op_increment
)paren
(brace
id|page_table_copies
(braket
id|i
)braket
op_assign
(paren
id|i
op_star
id|PAGE_SIZE
)paren
op_or
id|_PAGE_RW
op_or
id|_PAGE_USER
op_or
id|_PAGE_PRESENT
suffix:semicolon
)brace
(paren
(paren
r_int
r_int
op_star
)paren
id|swapper_pg_dir
)paren
(braket
l_int|0
)braket
op_assign
(paren
(paren
id|virt_to_phys
c_func
(paren
id|page_table_copies
)paren
)paren
op_amp
id|PAGE_MASK
)paren
op_or
id|_PAGE_RW
op_or
id|_PAGE_USER
op_or
id|_PAGE_PRESENT
suffix:semicolon
macro_line|#else
(paren
(paren
r_int
r_int
op_star
)paren
id|swapper_pg_dir
)paren
(braket
l_int|0
)braket
op_assign
l_int|0x102007
suffix:semicolon
macro_line|#endif
r_if
c_cond
(paren
id|quad_boot
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;CPU %d: non extended Quad boot&bslash;n&quot;
comma
id|cpu
)paren
suffix:semicolon
id|hijack_vector
op_assign
(paren
id|__u32
op_star
)paren
id|phys_to_virt
c_func
(paren
(paren
id|VIC_CPU_BOOT_CPI
op_plus
id|QIC_DEFAULT_CPI_BASE
)paren
op_star
l_int|4
)paren
suffix:semicolon
op_star
id|hijack_vector
op_assign
id|hijack_source.val
suffix:semicolon
)brace
r_else
(brace
id|printk
c_func
(paren
l_string|&quot;CPU%d: extended VIC boot&bslash;n&quot;
comma
id|cpu
)paren
suffix:semicolon
id|hijack_vector
op_assign
(paren
id|__u32
op_star
)paren
id|phys_to_virt
c_func
(paren
(paren
id|VIC_CPU_BOOT_CPI
op_plus
id|VIC_DEFAULT_CPI_BASE
)paren
op_star
l_int|4
)paren
suffix:semicolon
op_star
id|hijack_vector
op_assign
id|hijack_source.val
suffix:semicolon
multiline_comment|/* VIC errata, may also receive interrupt at this address */
id|hijack_vector
op_assign
(paren
id|__u32
op_star
)paren
id|phys_to_virt
c_func
(paren
(paren
id|VIC_CPU_BOOT_ERRATA_CPI
op_plus
id|VIC_DEFAULT_CPI_BASE
)paren
op_star
l_int|4
)paren
suffix:semicolon
op_star
id|hijack_vector
op_assign
id|hijack_source.val
suffix:semicolon
)brace
multiline_comment|/* All non-boot CPUs start with interrupts fully masked.  Need&n;&t; * to lower the mask of the CPI we&squot;re about to send.  We do&n;&t; * this in the VIC by masquerading as the processor we&squot;re&n;&t; * about to boot and lowering its interrupt mask */
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|quad_boot
)paren
(brace
id|send_one_QIC_CPI
c_func
(paren
id|cpu
comma
id|VIC_CPU_BOOT_CPI
)paren
suffix:semicolon
)brace
r_else
(brace
id|outb
c_func
(paren
id|VIC_CPU_MASQUERADE_ENABLE
op_or
id|cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
multiline_comment|/* here we&squot;re altering registers belonging to `cpu&squot; */
id|outb
c_func
(paren
id|VIC_BOOT_INTERRUPT_MASK
comma
l_int|0x21
)paren
suffix:semicolon
multiline_comment|/* now go back to our original identity */
id|outb
c_func
(paren
id|boot_cpu_id
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
multiline_comment|/* and boot the CPU */
id|send_CPI
c_func
(paren
(paren
l_int|1
op_lshift
id|cpu
)paren
comma
id|VIC_CPU_BOOT_CPI
)paren
suffix:semicolon
)brace
id|cpu_booted_map
op_assign
l_int|0
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/* now wait for it to become ready (or timeout) */
r_for
c_loop
(paren
id|timeout
op_assign
l_int|0
suffix:semicolon
id|timeout
OL
l_int|50000
suffix:semicolon
id|timeout
op_increment
)paren
(brace
r_if
c_cond
(paren
id|cpu_booted_map
)paren
(brace
r_break
suffix:semicolon
)brace
id|udelay
c_func
(paren
l_int|100
)paren
suffix:semicolon
)brace
multiline_comment|/* reset the page table */
id|swapper_pg_dir
(braket
l_int|0
)braket
op_assign
id|orig_swapper_pg_dir0
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
macro_line|#ifdef CONFIG_M486
id|free_page
c_func
(paren
(paren
r_int
r_int
)paren
id|page_table_copies
)paren
suffix:semicolon
macro_line|#endif
r_if
c_cond
(paren
id|cpu_booted_map
)paren
(brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;CPU%d: Booted successfully, back in CPU %d&bslash;n&quot;
comma
id|cpu
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;CPU%d: &quot;
comma
id|cpu
)paren
suffix:semicolon
id|print_cpu_info
c_func
(paren
op_amp
id|cpu_data
(braket
id|cpu
)braket
)paren
suffix:semicolon
id|wmb
c_func
(paren
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|cpu
comma
op_amp
id|cpu_callout_map
)paren
suffix:semicolon
)brace
r_else
(brace
id|printk
c_func
(paren
l_string|&quot;CPU%d FAILED TO BOOT: &quot;
comma
id|cpu
)paren
suffix:semicolon
r_if
c_cond
(paren
op_star
(paren
(paren
r_volatile
r_int
r_char
op_star
)paren
id|phys_to_virt
c_func
(paren
id|start_phys_address
)paren
)paren
op_eq
l_int|0xA5
)paren
id|printk
c_func
(paren
l_string|&quot;Stuck.&bslash;n&quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;Not responding.&bslash;n&quot;
)paren
suffix:semicolon
id|cpucount
op_decrement
suffix:semicolon
)brace
)brace
r_void
id|__init
DECL|function|smp_boot_cpus
id|smp_boot_cpus
c_func
(paren
r_void
)paren
(brace
r_int
id|i
suffix:semicolon
multiline_comment|/* CAT BUS initialisation must be done after the memory */
multiline_comment|/* FIXME: The L4 has a catbus too, it just needs to be&n;&t; * accessed in a totally different way */
r_if
c_cond
(paren
id|voyager_level
op_eq
l_int|5
)paren
(brace
id|voyager_cat_init
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* now that the cat has probed the Voyager System Bus, sanity&n;&t;&t; * check the cpu map */
r_if
c_cond
(paren
(paren
(paren
id|voyager_quad_processors
op_or
id|voyager_extended_vic_processors
)paren
op_amp
id|phys_cpu_present_map
)paren
op_ne
id|phys_cpu_present_map
)paren
(brace
multiline_comment|/* should panic */
id|printk
c_func
(paren
l_string|&quot;&bslash;n&bslash;n***WARNING*** Sanity check of CPU present map FAILED&bslash;n&quot;
)paren
suffix:semicolon
)brace
)brace
r_else
r_if
c_cond
(paren
id|voyager_level
op_eq
l_int|4
)paren
(brace
id|voyager_extended_vic_processors
op_assign
id|phys_cpu_present_map
suffix:semicolon
)brace
multiline_comment|/* this sets up the idle task to run on the current cpu */
id|voyager_extended_cpus
op_assign
l_int|1
suffix:semicolon
multiline_comment|/* Remove the global_irq_holder setting, it triggers a BUG() on&n;&t; * schedule at the moment */
singleline_comment|//global_irq_holder = boot_cpu_id;
multiline_comment|/* FIXME: Need to do something about this but currently only works&n;&t; * on CPUs with a tsc which none of mine have. &n;&t;smp_tune_scheduling();&n;&t; */
id|smp_store_cpu_info
c_func
(paren
id|boot_cpu_id
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;CPU%d: &quot;
comma
id|boot_cpu_id
)paren
suffix:semicolon
id|print_cpu_info
c_func
(paren
op_amp
id|cpu_data
(braket
id|boot_cpu_id
)braket
)paren
suffix:semicolon
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
)paren
(brace
multiline_comment|/* booting on a Quad CPU */
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: Boot CPU is Quad&bslash;n&quot;
)paren
suffix:semicolon
id|qic_setup
c_func
(paren
)paren
suffix:semicolon
id|do_quad_bootstrap
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/* enable our own CPIs */
id|vic_enable_cpi
c_func
(paren
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|boot_cpu_id
comma
op_amp
id|cpu_online_map
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|boot_cpu_id
comma
op_amp
id|cpu_callout_map
)paren
suffix:semicolon
multiline_comment|/* loop over all the extended VIC CPUs and boot them.  The &n;&t; * Quad CPUs must be bootstrapped by their extended VIC cpu */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
id|i
op_eq
id|boot_cpu_id
op_logical_or
(paren
(paren
l_int|1
op_lshift
id|i
)paren
op_amp
(paren
id|phys_cpu_present_map
)paren
)paren
op_eq
l_int|0
)paren
(brace
r_continue
suffix:semicolon
)brace
id|do_boot_cpu
c_func
(paren
id|i
)paren
suffix:semicolon
multiline_comment|/* This udelay seems to be needed for the Quad boots&n;&t;&t; * don&squot;t remove unless you know what you&squot;re doing */
id|udelay
c_func
(paren
l_int|1000
)paren
suffix:semicolon
)brace
multiline_comment|/* we could compute the total bogomips here, but why bother?,&n;&t; * Code added from smpboot.c */
(brace
r_int
r_int
id|bogosum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
r_if
c_cond
(paren
id|cpu_online_map
op_amp
(paren
l_int|1
op_lshift
id|i
)paren
)paren
id|bogosum
op_add_assign
id|cpu_data
(braket
id|i
)braket
dot
id|loops_per_jiffy
suffix:semicolon
id|printk
c_func
(paren
id|KERN_INFO
l_string|&quot;Total of %d processors activated (%lu.%02lu BogoMIPS).&bslash;n&quot;
comma
id|cpucount
op_plus
l_int|1
comma
id|bogosum
op_div
(paren
l_int|500000
op_div
id|HZ
)paren
comma
(paren
id|bogosum
op_div
(paren
l_int|5000
op_div
id|HZ
)paren
)paren
op_mod
l_int|100
)paren
suffix:semicolon
)brace
id|voyager_extended_cpus
op_assign
id|hweight32
c_func
(paren
id|voyager_extended_vic_processors
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;VOYAGER: Extended (interrupt handling CPUs): %d, non-extended: %d&bslash;n&quot;
comma
id|voyager_extended_cpus
comma
id|num_booting_cpus
c_func
(paren
)paren
op_minus
id|voyager_extended_cpus
)paren
suffix:semicolon
multiline_comment|/* that&squot;s it, switch to symmetric mode */
id|outb
c_func
(paren
l_int|0
comma
id|VIC_PRIORITY_REGISTER
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0
comma
id|VIC_CLAIM_REGISTER_0
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0
comma
id|VIC_CLAIM_REGISTER_1
)paren
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: Booted with %d CPUs&bslash;n&quot;
comma
id|num_booting_cpus
c_func
(paren
)paren
)paren
)paren
suffix:semicolon
)brace
multiline_comment|/* Reload the secondary CPUs task structure (this function does not&n; * return ) */
r_void
id|__init
DECL|function|initialize_secondary
id|initialize_secondary
c_func
(paren
r_void
)paren
(brace
macro_line|#if 0
singleline_comment|// AC kernels only
id|set_current
c_func
(paren
id|hard_get_current
c_func
(paren
)paren
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/*&n;&t; * We don&squot;t actually need to load the full TSS,&n;&t; * basically just the stack pointer and the eip.&n;&t; */
id|asm
r_volatile
(paren
l_string|&quot;movl %0,%%esp&bslash;n&bslash;t&quot;
l_string|&quot;jmp *%1&quot;
suffix:colon
suffix:colon
l_string|&quot;r&quot;
(paren
id|current-&gt;thread.esp
)paren
comma
l_string|&quot;r&quot;
(paren
id|current-&gt;thread.eip
)paren
)paren
suffix:semicolon
)brace
multiline_comment|/* handle a Voyager SYS_INT -- If we don&squot;t, the base board will&n; * panic the system.&n; *&n; * System interrupts occur because some problem was detected on the&n; * various busses.  To find out what you have to probe all the&n; * hardware via the CAT bus.  FIXME: At the moment we do nothing. */
id|asmlinkage
r_void
DECL|function|smp_vic_sys_interrupt
id|smp_vic_sys_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_CPI
c_func
(paren
id|VIC_SYS_INT
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;Voyager SYSTEM INTERRUPT&bslash;n&quot;
)paren
suffix:semicolon
)brace
multiline_comment|/* Handle a voyager CMN_INT; These interrupts occur either because of&n; * a system status change or because a single bit memory error&n; * occurred.  FIXME: At the moment, ignore all this. */
id|asmlinkage
r_void
DECL|function|smp_vic_cmn_interrupt
id|smp_vic_cmn_interrupt
c_func
(paren
r_void
)paren
(brace
r_static
id|__u8
id|in_cmn_int
op_assign
l_int|0
suffix:semicolon
r_static
id|spinlock_t
id|cmn_int_lock
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
multiline_comment|/* common ints are broadcast, so make sure we only do this once */
id|_raw_spin_lock
c_func
(paren
op_amp
id|cmn_int_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|in_cmn_int
)paren
(brace
r_goto
id|unlock_end
suffix:semicolon
)brace
id|in_cmn_int
op_increment
suffix:semicolon
id|_raw_spin_unlock
c_func
(paren
op_amp
id|cmn_int_lock
)paren
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;Voyager COMMON INTERRUPT&bslash;n&quot;
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|voyager_level
op_eq
l_int|5
)paren
(brace
id|voyager_cat_do_common_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
id|_raw_spin_lock
c_func
(paren
op_amp
id|cmn_int_lock
)paren
suffix:semicolon
id|in_cmn_int
op_assign
l_int|0
suffix:semicolon
id|unlock_end
suffix:colon
id|_raw_spin_unlock
c_func
(paren
op_amp
id|cmn_int_lock
)paren
suffix:semicolon
id|ack_CPI
c_func
(paren
id|VIC_CMN_INT
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Reschedule call back. Nothing to do, all the work is done&n; * automatically when we return from the interrupt.  */
id|asmlinkage
r_void
DECL|function|smp_reschedule_interrupt
id|smp_reschedule_interrupt
c_func
(paren
r_void
)paren
(brace
multiline_comment|/* do nothing */
)brace
DECL|variable|flush_mm
r_static
r_struct
id|mm_struct
op_star
id|flush_mm
suffix:semicolon
DECL|variable|flush_va
r_static
r_int
r_int
id|flush_va
suffix:semicolon
DECL|variable|tlbstate_lock
r_static
id|spinlock_t
id|tlbstate_lock
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
DECL|macro|FLUSH_ALL
mdefine_line|#define FLUSH_ALL&t;0xffffffff
multiline_comment|/*&n; * We cannot call mmdrop() because we are in interrupt context, &n; * instead update mm-&gt;cpu_vm_mask.&n; *&n; * We need to reload %cr3 since the page tables may be going&n; * away from under us..&n; */
r_static
r_inline
r_void
DECL|function|leave_mm
id|leave_mm
(paren
r_int
r_int
id|cpu
)paren
(brace
r_if
c_cond
(paren
id|cpu_tlbstate
(braket
id|cpu
)braket
dot
id|state
op_eq
id|TLBSTATE_OK
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|cpu_tlbstate
(braket
id|cpu
)braket
dot
id|active_mm-&gt;cpu_vm_mask
)paren
suffix:semicolon
id|load_cr3
c_func
(paren
id|swapper_pg_dir
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Invalidate call-back&n; */
id|asmlinkage
r_void
DECL|function|smp_invalidate_interrupt
id|smp_invalidate_interrupt
c_func
(paren
r_void
)paren
(brace
id|__u8
id|cpu
op_assign
id|get_cpu
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_invalidate_needed
)paren
)paren
(brace
r_goto
id|out
suffix:semicolon
)brace
multiline_comment|/* This will flood messages.  Don&squot;t uncomment unless you see&n;&t; * Problems with cross cpu invalidation&n;&t;VDEBUG((&quot;VOYAGER SMP: CPU%d received INVALIDATE_CPI&bslash;n&quot;,&n;&t;&t;smp_processor_id()));&n;&t;*/
r_if
c_cond
(paren
id|flush_mm
op_eq
id|cpu_tlbstate
(braket
id|cpu
)braket
dot
id|active_mm
)paren
(brace
r_if
c_cond
(paren
id|cpu_tlbstate
(braket
id|cpu
)braket
dot
id|state
op_eq
id|TLBSTATE_OK
)paren
(brace
r_if
c_cond
(paren
id|flush_va
op_eq
id|FLUSH_ALL
)paren
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
r_else
id|__flush_tlb_one
c_func
(paren
id|flush_va
)paren
suffix:semicolon
)brace
r_else
id|leave_mm
c_func
(paren
id|cpu
)paren
suffix:semicolon
)brace
id|clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_invalidate_needed
)paren
suffix:semicolon
id|out
suffix:colon
id|put_cpu_no_resched
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/* All the new flush operations for 2.4 */
multiline_comment|/* This routine is called with a physical cpu mask */
r_static
r_void
DECL|function|flush_tlb_others
id|flush_tlb_others
(paren
r_int
r_int
id|cpumask
comma
r_struct
id|mm_struct
op_star
id|mm
comma
r_int
r_int
id|va
)paren
(brace
r_int
id|stuck
op_assign
l_int|50000
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|cpumask
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|cpumask
op_amp
id|cpu_online_map
)paren
op_ne
id|cpumask
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpumask
op_amp
(paren
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|mm
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|tlbstate_lock
)paren
suffix:semicolon
id|flush_mm
op_assign
id|mm
suffix:semicolon
id|flush_va
op_assign
id|va
suffix:semicolon
id|atomic_set_mask
c_func
(paren
id|cpumask
comma
op_amp
id|smp_invalidate_needed
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We have to send the CPI only to&n;&t; * CPUs affected.&n;&t; */
id|send_CPI
c_func
(paren
id|cpumask
comma
id|VIC_INVALIDATE_CPI
)paren
suffix:semicolon
r_while
c_loop
(paren
id|smp_invalidate_needed
)paren
(brace
r_if
c_cond
(paren
op_decrement
id|stuck
op_eq
l_int|0
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;***WARNING*** Stuck doing invalidate CPI (CPU%d)&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
)brace
multiline_comment|/* Uncomment only to debug invalidation problems&n;&t;VDEBUG((&quot;VOYAGER SMP: Completed invalidate CPI (CPU%d)&bslash;n&quot;, cpu));&n;&t;*/
id|flush_mm
op_assign
l_int|NULL
suffix:semicolon
id|flush_va
op_assign
l_int|0
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|tlbstate_lock
)paren
suffix:semicolon
)brace
r_void
DECL|function|flush_tlb_current_task
id|flush_tlb_current_task
c_func
(paren
r_void
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|current-&gt;mm
suffix:semicolon
r_int
r_int
id|cpu_mask
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
(paren
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_mask
)paren
id|flush_tlb_others
c_func
(paren
id|cpu_mask
comma
id|mm
comma
id|FLUSH_ALL
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
r_void
DECL|function|flush_tlb_mm
id|flush_tlb_mm
(paren
r_struct
id|mm_struct
op_star
id|mm
)paren
(brace
r_int
r_int
id|cpu_mask
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
(paren
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;active_mm
op_eq
id|mm
)paren
(brace
r_if
c_cond
(paren
id|current-&gt;mm
)paren
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
r_else
id|leave_mm
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|cpu_mask
)paren
id|flush_tlb_others
c_func
(paren
id|cpu_mask
comma
id|mm
comma
id|FLUSH_ALL
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|function|flush_tlb_page
r_void
id|flush_tlb_page
c_func
(paren
r_struct
id|vm_area_struct
op_star
id|vma
comma
r_int
r_int
id|va
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|vma-&gt;vm_mm
suffix:semicolon
r_int
r_int
id|cpu_mask
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
(paren
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;active_mm
op_eq
id|mm
)paren
(brace
r_if
c_cond
(paren
id|current-&gt;mm
)paren
(brace
id|__flush_tlb_one
c_func
(paren
id|va
)paren
suffix:semicolon
)brace
r_else
id|leave_mm
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|cpu_mask
)paren
id|flush_tlb_others
c_func
(paren
id|cpu_mask
comma
id|mm
comma
id|va
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/* enable the requested IRQs */
id|asmlinkage
r_void
DECL|function|smp_enable_irq_interrupt
id|smp_enable_irq_interrupt
c_func
(paren
r_void
)paren
(brace
id|__u8
id|irq
suffix:semicolon
id|__u8
id|cpu
op_assign
id|get_cpu
c_func
(paren
)paren
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: CPU%d enabling irq mask 0x%x&bslash;n&quot;
comma
id|cpu
comma
id|vic_irq_enable_mask
(braket
id|cpu
)braket
)paren
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
r_for
c_loop
(paren
id|irq
op_assign
l_int|0
suffix:semicolon
id|irq
OL
l_int|16
suffix:semicolon
id|irq
op_increment
)paren
(brace
r_if
c_cond
(paren
id|vic_irq_enable_mask
(braket
id|cpu
)braket
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
)paren
(brace
id|enable_local_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
)brace
)brace
id|vic_irq_enable_mask
(braket
id|cpu
)braket
op_assign
l_int|0
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
id|put_cpu_no_resched
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; *&t;CPU halt call-back&n; */
r_static
r_void
DECL|function|smp_stop_cpu_function
id|smp_stop_cpu_function
c_func
(paren
r_void
op_star
id|dummy
)paren
(brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: CPU%d is STOPPING&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
suffix:semicolon
id|clear_bit
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
comma
op_amp
id|cpu_online_map
)paren
suffix:semicolon
id|local_irq_disable
c_func
(paren
)paren
suffix:semicolon
r_for
c_loop
(paren
suffix:semicolon
suffix:semicolon
)paren
(brace
id|__asm__
c_func
(paren
l_string|&quot;hlt&quot;
)paren
suffix:semicolon
)brace
)brace
DECL|variable|call_lock
r_static
id|spinlock_t
id|call_lock
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
DECL|struct|call_data_struct
r_struct
id|call_data_struct
(brace
DECL|member|func
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
suffix:semicolon
DECL|member|info
r_void
op_star
id|info
suffix:semicolon
DECL|member|started
r_volatile
r_int
r_int
id|started
suffix:semicolon
DECL|member|finished
r_volatile
r_int
r_int
id|finished
suffix:semicolon
DECL|member|wait
r_int
id|wait
suffix:semicolon
)brace
suffix:semicolon
DECL|variable|call_data
r_static
r_struct
id|call_data_struct
op_star
id|call_data
suffix:semicolon
multiline_comment|/* execute a thread on a new CPU.  The function to be called must be&n; * previously set up.  This is used to schedule a function for&n; * execution on all CPU&squot;s - set up the function then broadcast a&n; * function_interrupt CPI to come here on each CPU */
id|asmlinkage
r_void
DECL|function|smp_call_function_interrupt
id|smp_call_function_interrupt
c_func
(paren
r_void
)paren
(brace
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
op_assign
id|call_data-&gt;func
suffix:semicolon
r_void
op_star
id|info
op_assign
id|call_data-&gt;info
suffix:semicolon
multiline_comment|/* must take copy of wait because call_data may be replaced&n;&t; * unless the function is waiting for us to finish */
r_int
id|wait
op_assign
id|call_data-&gt;wait
suffix:semicolon
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Notify initiating CPU that I&squot;ve grabbed the data and am&n;&t; * about to execute the function&n;&t; */
id|mb
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_and_clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|call_data-&gt;started
)paren
)paren
(brace
multiline_comment|/* If the bit wasn&squot;t set, this could be a replay */
id|printk
c_func
(paren
id|KERN_WARNING
l_string|&quot;VOYAGER SMP: CPU %d received call funtion with no call pending&bslash;n&quot;
comma
id|cpu
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * At this point the info structure may be out of scope unless wait==1&n;&t; */
id|irq_enter
c_func
(paren
)paren
suffix:semicolon
(paren
op_star
id|func
)paren
(paren
id|info
)paren
suffix:semicolon
id|irq_exit
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
(brace
id|mb
c_func
(paren
)paren
suffix:semicolon
id|clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|call_data-&gt;finished
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* Call this function on all CPUs using the function_interrupt above &n;    &lt;func&gt; The function to run. This must be fast and non-blocking.&n;    &lt;info&gt; An arbitrary pointer to pass to the function.&n;    &lt;retry&gt; If true, keep retrying until ready.&n;    &lt;wait&gt; If true, wait until function has completed on other CPUs.&n;    [RETURNS] 0 on success, else a negative status code. Does not return until&n;    remote CPUs are nearly ready to execute &lt;&lt;func&gt;&gt; or are or have executed.&n;*/
r_int
DECL|function|smp_call_function
id|smp_call_function
(paren
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
comma
r_void
op_star
id|info
comma
r_int
id|retry
comma
r_int
id|wait
)paren
(brace
r_struct
id|call_data_struct
id|data
suffix:semicolon
id|__u32
id|mask
op_assign
id|cpu_online_map
suffix:semicolon
id|mask
op_and_assign
op_complement
(paren
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|mask
)paren
r_return
l_int|0
suffix:semicolon
id|data.func
op_assign
id|func
suffix:semicolon
id|data.info
op_assign
id|info
suffix:semicolon
id|data.started
op_assign
id|mask
suffix:semicolon
id|data.wait
op_assign
id|wait
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
id|data.finished
op_assign
id|mask
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|call_lock
)paren
suffix:semicolon
id|call_data
op_assign
op_amp
id|data
suffix:semicolon
id|wmb
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Send a message to all other CPUs and wait for them to respond */
id|send_CPI_allbutself
c_func
(paren
id|VIC_CALL_FUNCTION_CPI
)paren
suffix:semicolon
multiline_comment|/* Wait for response */
r_while
c_loop
(paren
id|data.started
)paren
id|barrier
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
r_while
c_loop
(paren
id|data.finished
)paren
id|barrier
c_func
(paren
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|call_lock
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/* Sorry about the name.  In an APIC based system, the APICs&n; * themselves are programmed to send a timer interrupt.  This is used&n; * by linux to reschedule the processor.  Voyager doesn&squot;t have this,&n; * so we use the system clock to interrupt one processor, which in&n; * turn, broadcasts a timer CPI to all the others --- we receive that&n; * CPI here.  We don&squot;t use this actually for counting so losing&n; * ticks doesn&squot;t matter &n; *&n; * FIXME: For those CPU&squot;s which actually have a local APIC, we could&n; * try to use it to trigger this interrupt instead of having to&n; * broadcast the timer tick.  Unfortunately, all my pentium DYADs have&n; * no local APIC, so I can&squot;t do this&n; *&n; * This function is currently a placeholder and is unused in the code */
id|asmlinkage
r_void
DECL|function|smp_apic_timer_interrupt
id|smp_apic_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
id|regs
)paren
(brace
id|wrapper_smp_local_timer_interrupt
c_func
(paren
op_amp
id|regs
)paren
suffix:semicolon
)brace
multiline_comment|/* All of the QUAD interrupt GATES */
id|asmlinkage
r_void
DECL|function|smp_qic_timer_interrupt
id|smp_qic_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
id|regs
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|QIC_TIMER_CPI
)paren
suffix:semicolon
id|wrapper_smp_local_timer_interrupt
c_func
(paren
op_amp
id|regs
)paren
suffix:semicolon
)brace
id|asmlinkage
r_void
DECL|function|smp_qic_invalidate_interrupt
id|smp_qic_invalidate_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|QIC_INVALIDATE_CPI
)paren
suffix:semicolon
id|smp_invalidate_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
id|asmlinkage
r_void
DECL|function|smp_qic_reschedule_interrupt
id|smp_qic_reschedule_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|QIC_RESCHEDULE_CPI
)paren
suffix:semicolon
id|smp_reschedule_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
id|asmlinkage
r_void
DECL|function|smp_qic_enable_irq_interrupt
id|smp_qic_enable_irq_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|QIC_ENABLE_IRQ_CPI
)paren
suffix:semicolon
id|smp_enable_irq_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
id|asmlinkage
r_void
DECL|function|smp_qic_call_function_interrupt
id|smp_qic_call_function_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|QIC_CALL_FUNCTION_CPI
)paren
suffix:semicolon
id|smp_call_function_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
id|asmlinkage
r_void
DECL|function|smp_vic_cpi_interrupt
id|smp_vic_cpi_interrupt
c_func
(paren
r_struct
id|pt_regs
id|regs
)paren
(brace
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
)paren
(brace
id|ack_QIC_CPI
c_func
(paren
id|VIC_CPI_LEVEL0
)paren
suffix:semicolon
)brace
r_else
id|ack_VIC_CPI
c_func
(paren
id|VIC_CPI_LEVEL0
)paren
suffix:semicolon
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|VIC_TIMER_CPI
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
)paren
(brace
id|wrapper_smp_local_timer_interrupt
c_func
(paren
op_amp
id|regs
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|VIC_INVALIDATE_CPI
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
)paren
(brace
id|smp_invalidate_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|VIC_RESCHEDULE_CPI
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
)paren
(brace
id|smp_reschedule_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|VIC_ENABLE_IRQ_CPI
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
)paren
(brace
id|smp_enable_irq_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|VIC_CALL_FUNCTION_CPI
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
)paren
(brace
id|smp_call_function_interrupt
c_func
(paren
)paren
suffix:semicolon
)brace
)brace
r_static
r_void
DECL|function|do_flush_tlb_all
id|do_flush_tlb_all
c_func
(paren
r_void
op_star
id|info
)paren
(brace
r_int
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|__flush_tlb_all
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_tlbstate
(braket
id|cpu
)braket
dot
id|state
op_eq
id|TLBSTATE_LAZY
)paren
id|leave_mm
c_func
(paren
id|cpu
)paren
suffix:semicolon
)brace
multiline_comment|/* flush the TLB of every active CPU in the system */
r_void
DECL|function|flush_tlb_all
id|flush_tlb_all
c_func
(paren
r_void
)paren
(brace
id|on_each_cpu
c_func
(paren
id|do_flush_tlb_all
comma
l_int|0
comma
l_int|1
comma
l_int|1
)paren
suffix:semicolon
)brace
multiline_comment|/* used to set up the trampoline for other CPUs when the memory manager&n; * is sorted out */
r_void
id|__init
DECL|function|smp_alloc_memory
id|smp_alloc_memory
c_func
(paren
r_void
)paren
(brace
id|trampoline_base
op_assign
(paren
id|__u32
)paren
id|alloc_bootmem_low_pages
c_func
(paren
id|PAGE_SIZE
)paren
suffix:semicolon
r_if
c_cond
(paren
id|__pa
c_func
(paren
id|trampoline_base
)paren
op_ge
l_int|0x93000
)paren
(brace
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* send a reschedule CPI to one CPU by physical CPU number*/
r_void
DECL|function|smp_send_reschedule
id|smp_send_reschedule
c_func
(paren
r_int
id|cpu
)paren
(brace
id|send_one_CPI
c_func
(paren
id|cpu
comma
id|VIC_RESCHEDULE_CPI
)paren
suffix:semicolon
)brace
r_int
DECL|function|hard_smp_processor_id
id|hard_smp_processor_id
c_func
(paren
r_void
)paren
(brace
id|__u8
id|i
suffix:semicolon
id|__u8
id|cpumask
op_assign
id|inb
c_func
(paren
id|VIC_PROC_WHO_AM_I
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|cpumask
op_amp
id|QUAD_IDENTIFIER
)paren
op_eq
id|QUAD_IDENTIFIER
)paren
(brace
r_return
id|cpumask
op_amp
l_int|0x1F
suffix:semicolon
)brace
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
l_int|8
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
id|cpumask
op_amp
(paren
l_int|1
op_lshift
id|i
)paren
)paren
(brace
r_return
id|i
suffix:semicolon
)brace
)brace
id|printk
c_func
(paren
l_string|&quot;** WARNING ** Illegal cpuid returned by VIC: %d&quot;
comma
id|cpumask
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/* broadcast a halt to all other CPUs */
r_void
DECL|function|smp_send_stop
id|smp_send_stop
c_func
(paren
r_void
)paren
(brace
id|smp_call_function
c_func
(paren
id|smp_stop_cpu_function
comma
l_int|NULL
comma
l_int|1
comma
l_int|1
)paren
suffix:semicolon
)brace
multiline_comment|/* this function is triggered in time.c when a clock tick fires&n; * we need to re-broadcast the tick to all CPUs */
r_void
DECL|function|smp_vic_timer_interrupt
id|smp_vic_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
id|send_CPI_allbutself
c_func
(paren
id|VIC_TIMER_CPI
)paren
suffix:semicolon
id|smp_local_timer_interrupt
c_func
(paren
id|regs
)paren
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|wrapper_smp_local_timer_interrupt
id|wrapper_smp_local_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
id|irq_enter
c_func
(paren
)paren
suffix:semicolon
id|smp_local_timer_interrupt
c_func
(paren
id|regs
)paren
suffix:semicolon
id|irq_exit
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/* local (per CPU) timer interrupt.  It does both profiling and&n; * process statistics/rescheduling.&n; *&n; * We do profiling in every local tick, statistics/rescheduling&n; * happen only every &squot;profiling multiplier&squot; ticks. The default&n; * multiplier is 1 and it can be changed by writing the new multiplier&n; * value into /proc/profile.&n; */
r_void
DECL|function|smp_local_timer_interrupt
id|smp_local_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
r_int
id|weight
suffix:semicolon
id|x86_do_profile
c_func
(paren
id|regs
)paren
suffix:semicolon
r_if
c_cond
(paren
op_decrement
id|per_cpu
c_func
(paren
id|prof_counter
comma
id|cpu
)paren
op_le
l_int|0
)paren
(brace
multiline_comment|/*&n;&t;&t; * The multiplier may have changed since the last time we got&n;&t;&t; * to this point as a result of the user writing to&n;&t;&t; * /proc/profile. In this case we need to adjust the APIC&n;&t;&t; * timer accordingly.&n;&t;&t; *&n;&t;&t; * Interrupts are already masked off at this point.&n;&t;&t; */
id|per_cpu
c_func
(paren
id|prof_counter
comma
id|cpu
)paren
op_assign
id|per_cpu
c_func
(paren
id|prof_multiplier
comma
id|cpu
)paren
suffix:semicolon
r_if
c_cond
(paren
id|per_cpu
c_func
(paren
id|prof_counter
comma
id|cpu
)paren
op_ne
id|per_cpu
c_func
(paren
id|prof_old_multiplier
comma
id|cpu
)paren
)paren
(brace
multiline_comment|/* FIXME: need to update the vic timer tick here */
id|per_cpu
c_func
(paren
id|prof_old_multiplier
comma
id|cpu
)paren
op_assign
id|per_cpu
c_func
(paren
id|prof_counter
comma
id|cpu
)paren
suffix:semicolon
)brace
id|update_process_times
c_func
(paren
id|user_mode
c_func
(paren
id|regs
)paren
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
(paren
(paren
l_int|1
op_lshift
id|cpu
)paren
op_amp
id|voyager_extended_vic_processors
)paren
op_eq
l_int|0
)paren
(brace
multiline_comment|/* only extended VIC processors participate in&n;&t;&t; * interrupt distribution */
r_return
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * We take the &squot;long&squot; return path, and there every subsystem&n;&t; * grabs the apropriate locks (kernel lock/ irq lock).&n;&t; *&n;&t; * we might want to decouple profiling from the &squot;long path&squot;,&n;&t; * and do the profiling totally in assembly.&n;&t; *&n;&t; * Currently this isn&squot;t too much of an issue (performance wise),&n;&t; * we can take more than 100K local irqs per second on a 100 MHz P5.&n;&t; */
r_if
c_cond
(paren
(paren
op_increment
id|vic_tick
(braket
id|cpu
)braket
op_amp
l_int|0x7
)paren
op_ne
l_int|0
)paren
(brace
r_return
suffix:semicolon
)brace
multiline_comment|/* get here every 16 ticks (about every 1/6 of a second) */
multiline_comment|/* Change our priority to give someone else a chance at getting&n;         * the IRQ. The algorithm goes like this:&n;&t; *&n;&t; * In the VIC, the dynamically routed interrupt is always&n;&t; * handled by the lowest priority eligible (i.e. receiving&n;&t; * interrupts) CPU.  If &gt;1 eligible CPUs are equal lowest, the&n;&t; * lowest processor number gets it.&n;&t; *&n;&t; * The priority of a CPU is controlled by a special per-CPU&n;&t; * VIC priority register which is 3 bits wide 0 being lowest&n;&t; * and 7 highest priority..&n;&t; *&n;&t; * Therefore we subtract the average number of interrupts from&n;&t; * the number we&squot;ve fielded.  If this number is negative, we&n;&t; * lower the activity count and if it is positive, we raise&n;&t; * it.&n;&t; *&n;&t; * I&squot;m afraid this still leads to odd looking interrupt counts:&n;&t; * the totals are all roughly equal, but the individual ones&n;&t; * look rather skewed.&n;&t; *&n;&t; * FIXME: This algorithm is total crap when mixed with SMP&n;&t; * affinity code since we now try to even up the interrupt&n;&t; * counts when an affinity binding is keeping them on a&n;&t; * particular CPU*/
id|weight
op_assign
(paren
id|vic_intr_count
(braket
id|cpu
)braket
op_star
id|voyager_extended_cpus
op_minus
id|vic_intr_total
)paren
op_rshift
l_int|4
suffix:semicolon
id|weight
op_add_assign
l_int|4
suffix:semicolon
r_if
c_cond
(paren
id|weight
OG
l_int|7
)paren
(brace
id|weight
op_assign
l_int|7
suffix:semicolon
)brace
r_if
c_cond
(paren
id|weight
OL
l_int|0
)paren
(brace
id|weight
op_assign
l_int|0
suffix:semicolon
)brace
id|outb
c_func
(paren
(paren
id|__u8
)paren
id|weight
comma
id|VIC_PRIORITY_REGISTER
)paren
suffix:semicolon
macro_line|#ifdef VOYAGER_DEBUG
r_if
c_cond
(paren
(paren
id|vic_tick
(braket
id|cpu
)braket
op_amp
l_int|0xFFF
)paren
op_eq
l_int|0
)paren
(brace
multiline_comment|/* print this message roughly every 25 secs */
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: vic_tick[%d] = %lu, weight = %ld&bslash;n&quot;
comma
id|cpu
comma
id|vic_tick
(braket
id|cpu
)braket
comma
id|weight
)paren
suffix:semicolon
)brace
macro_line|#endif
)brace
multiline_comment|/* setup the profiling timer */
r_int
DECL|function|setup_profiling_timer
id|setup_profiling_timer
c_func
(paren
r_int
r_int
id|multiplier
)paren
(brace
r_int
id|i
suffix:semicolon
r_if
c_cond
(paren
(paren
op_logical_neg
id|multiplier
)paren
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
multiline_comment|/* &n;&t; * Set the new multiplier for each CPU. CPUs don&squot;t start using the&n;&t; * new values until the next timer interrupt in which they do process&n;&t; * accounting.&n;&t; */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
op_increment
id|i
)paren
id|per_cpu
c_func
(paren
id|prof_multiplier
comma
id|i
)paren
op_assign
id|multiplier
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*  The CPIs are handled in the per cpu 8259s, so they must be&n; *  enabled to be received: FIX: enabling the CPIs in the early&n; *  boot sequence interferes with bug checking; enable them later&n; *  on in smp_init */
DECL|macro|VIC_SET_GATE
mdefine_line|#define VIC_SET_GATE(cpi, vector) &bslash;&n;&t;set_intr_gate((cpi) + VIC_DEFAULT_CPI_BASE, (vector))
DECL|macro|QIC_SET_GATE
mdefine_line|#define QIC_SET_GATE(cpi, vector) &bslash;&n;&t;set_intr_gate((cpi) + QIC_DEFAULT_CPI_BASE, (vector))
r_void
id|__init
DECL|function|smp_intr_init
id|smp_intr_init
c_func
(paren
r_void
)paren
(brace
r_int
id|i
suffix:semicolon
multiline_comment|/* initialize the per cpu irq mask to all disabled */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
id|vic_irq_mask
(braket
id|i
)braket
op_assign
l_int|0xFFFF
suffix:semicolon
)brace
id|VIC_SET_GATE
c_func
(paren
id|VIC_CPI_LEVEL0
comma
id|vic_cpi_interrupt
)paren
suffix:semicolon
id|VIC_SET_GATE
c_func
(paren
id|VIC_SYS_INT
comma
id|vic_sys_interrupt
)paren
suffix:semicolon
id|VIC_SET_GATE
c_func
(paren
id|VIC_CMN_INT
comma
id|vic_cmn_interrupt
)paren
suffix:semicolon
id|QIC_SET_GATE
c_func
(paren
id|QIC_TIMER_CPI
comma
id|qic_timer_interrupt
)paren
suffix:semicolon
id|QIC_SET_GATE
c_func
(paren
id|QIC_INVALIDATE_CPI
comma
id|qic_invalidate_interrupt
)paren
suffix:semicolon
id|QIC_SET_GATE
c_func
(paren
id|QIC_RESCHEDULE_CPI
comma
id|qic_reschedule_interrupt
)paren
suffix:semicolon
id|QIC_SET_GATE
c_func
(paren
id|QIC_ENABLE_IRQ_CPI
comma
id|qic_enable_irq_interrupt
)paren
suffix:semicolon
id|QIC_SET_GATE
c_func
(paren
id|QIC_CALL_FUNCTION_CPI
comma
id|qic_call_function_interrupt
)paren
suffix:semicolon
multiline_comment|/* now put the VIC descriptor into the first 48 IRQs &n;&t; *&n;&t; * This is for later: first 16 correspond to PC IRQs; next 16&n;&t; * are Primary MC IRQs and final 16 are Secondary MC IRQs */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
l_int|48
suffix:semicolon
id|i
op_increment
)paren
(brace
id|irq_desc
(braket
id|i
)braket
dot
id|handler
op_assign
op_amp
id|vic_irq_type
suffix:semicolon
)brace
)brace
multiline_comment|/* send a CPI at level cpi to a set of cpus in cpuset (set 1 bit per&n; * processor to receive CPI */
r_static
r_void
DECL|function|send_CPI
id|send_CPI
c_func
(paren
id|__u32
id|cpuset
comma
id|__u8
id|cpi
)paren
(brace
r_int
id|mask
suffix:semicolon
id|__u8
id|cpu
suffix:semicolon
id|__u32
id|quad_cpuset
op_assign
(paren
id|cpuset
op_amp
id|voyager_quad_processors
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpi
OL
id|VIC_START_FAKE_CPI
)paren
(brace
multiline_comment|/* fake CPI are only used for booting, so send to the &n;&t;&t; * extended quads as well---Quads must be VIC booted */
id|outb
c_func
(paren
(paren
id|__u8
)paren
(paren
id|cpuset
)paren
comma
id|VIC_CPI_Registers
(braket
id|cpi
)braket
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
r_if
c_cond
(paren
id|quad_cpuset
)paren
(brace
id|send_QIC_CPI
c_func
(paren
id|quad_cpuset
comma
id|cpi
)paren
suffix:semicolon
)brace
id|cpuset
op_and_assign
op_complement
id|quad_cpuset
suffix:semicolon
id|cpuset
op_and_assign
l_int|0xff
suffix:semicolon
multiline_comment|/* only first 8 CPUs vaild for VIC CPI */
r_if
c_cond
(paren
id|cpuset
op_eq
l_int|0
)paren
(brace
r_return
suffix:semicolon
)brace
id|for_each_cpu
c_func
(paren
id|cpu
comma
id|mask
)paren
(brace
r_if
c_cond
(paren
id|cpuset
op_amp
(paren
l_int|1
op_lshift
id|cpu
)paren
)paren
(brace
id|set_bit
c_func
(paren
id|cpi
comma
op_amp
id|vic_cpi_mailbox
(braket
id|cpu
)braket
)paren
suffix:semicolon
)brace
)brace
r_if
c_cond
(paren
id|cpuset
)paren
(brace
id|outb
c_func
(paren
(paren
id|__u8
)paren
id|cpuset
comma
id|VIC_CPI_Registers
(braket
id|VIC_CPI_LEVEL0
)braket
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* Acknowledge receipt of CPI in the QIC, clear in QIC hardware and&n; * set the cache line to shared by reading it.&n; *&n; * DON&squot;T make this inline otherwise the cache line read will be&n; * optimised away&n; * */
r_static
r_int
DECL|function|ack_QIC_CPI
id|ack_QIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
(brace
id|__u8
id|cpu
op_assign
id|hard_smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|cpi
op_and_assign
l_int|7
suffix:semicolon
id|outb
c_func
(paren
l_int|1
op_lshift
id|cpi
comma
id|QIC_INTERRUPT_CLEAR1
)paren
suffix:semicolon
r_return
id|voyager_quad_cpi_addr
(braket
id|cpu
)braket
op_member_access_from_pointer
id|qic_cpi
(braket
id|cpi
)braket
dot
id|cpi
suffix:semicolon
)brace
r_static
r_void
DECL|function|ack_special_QIC_CPI
id|ack_special_QIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
(brace
r_switch
c_cond
(paren
id|cpi
)paren
(brace
r_case
id|VIC_CMN_INT
suffix:colon
id|outb
c_func
(paren
id|QIC_CMN_INT
comma
id|QIC_INTERRUPT_CLEAR0
)paren
suffix:semicolon
r_break
suffix:semicolon
r_case
id|VIC_SYS_INT
suffix:colon
id|outb
c_func
(paren
id|QIC_SYS_INT
comma
id|QIC_INTERRUPT_CLEAR0
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
multiline_comment|/* also clear at the VIC, just in case (nop for non-extended proc) */
id|ack_VIC_CPI
c_func
(paren
id|cpi
)paren
suffix:semicolon
)brace
multiline_comment|/* Acknowledge receipt of CPI in the VIC (essentially an EOI) */
r_static
r_void
DECL|function|ack_VIC_CPI
id|ack_VIC_CPI
c_func
(paren
id|__u8
id|cpi
)paren
(brace
macro_line|#ifdef VOYAGER_DEBUG
r_int
r_int
id|flags
suffix:semicolon
id|__u16
id|isr
suffix:semicolon
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|isr
op_assign
id|vic_read_isr
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|isr
op_amp
(paren
l_int|1
op_lshift
(paren
id|cpi
op_amp
l_int|7
)paren
)paren
)paren
op_eq
l_int|0
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: CPU%d lost CPI%d&bslash;n&quot;
comma
id|cpu
comma
id|cpi
)paren
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/* send specific EOI; the two system interrupts have&n;&t; * bit 4 set for a separate vector but behave as the&n;&t; * corresponding 3 bit intr */
id|outb_p
c_func
(paren
l_int|0x60
op_or
(paren
id|cpi
op_amp
l_int|7
)paren
comma
l_int|0x20
)paren
suffix:semicolon
macro_line|#ifdef VOYAGER_DEBUG
r_if
c_cond
(paren
(paren
id|vic_read_isr
c_func
(paren
)paren
op_amp
(paren
l_int|1
op_lshift
(paren
id|cpi
op_amp
l_int|7
)paren
)paren
)paren
op_ne
l_int|0
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: CPU%d still asserting CPI%d&bslash;n&quot;
comma
id|cpu
comma
id|cpi
)paren
suffix:semicolon
)brace
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
macro_line|#endif
)brace
multiline_comment|/* cribbed with thanks from irq.c */
DECL|macro|__byte
mdefine_line|#define __byte(x,y) &t;(((unsigned char *)&amp;(y))[x])
DECL|macro|cached_21
mdefine_line|#define cached_21(cpu)&t;(__byte(0,vic_irq_mask[cpu]))
DECL|macro|cached_A1
mdefine_line|#define cached_A1(cpu)&t;(__byte(1,vic_irq_mask[cpu]))
r_static
r_int
r_int
DECL|function|startup_vic_irq
id|startup_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
id|enable_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/* The enable and disable routines.  This is where we run into&n; * conflicting architectural philosophy.  Fundamentally, the voyager&n; * architecture does not expect to have to disable interrupts globally&n; * (the IRQ controllers belong to each CPU).  The processor masquerade&n; * which is used to start the system shouldn&squot;t be used in a running OS&n; * since it will cause great confusion if two separate CPUs drive to&n; * the same IRQ controller (I know, I&squot;ve tried it).&n; *&n; * The solution is a variant on the NCR lazy SPL design:&n; *&n; * 1) To disable an interrupt, do nothing (other than set the&n; *    IRQ_DISABLED flag).  This dares the interrupt actually to arrive.&n; *&n; * 2) If the interrupt dares to come in, raise the local mask against&n; *    it (this will result in all the CPU masks being raised&n; *    eventually).&n; *&n; * 3) To enable the interrupt, lower the mask on the local CPU and&n; *    broadcast an Interrupt enable CPI which causes all other CPUs to&n; *    adjust their masks accordingly.  */
r_static
r_void
DECL|function|enable_vic_irq
id|enable_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
r_int
id|tmpmask
suffix:semicolon
multiline_comment|/* linux doesn&squot;t to processor-irq affinity, so enable on&n;&t; * all CPUs we know about */
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
comma
id|real_cpu
suffix:semicolon
id|__u16
id|mask
op_assign
(paren
l_int|1
op_lshift
id|irq
)paren
suffix:semicolon
id|__u32
id|processorList
op_assign
l_int|0
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER: enable_vic_irq(%d) CPU%d affinity 0x%lx&bslash;n&quot;
comma
id|irq
comma
id|cpu
comma
id|cpu_irq_affinity
(braket
id|cpu
)braket
)paren
)paren
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|vic_irq_lock
comma
id|flags
)paren
suffix:semicolon
id|for_each_cpu
c_func
(paren
id|real_cpu
comma
id|tmpmask
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|voyager_extended_vic_processors
op_amp
(paren
l_int|1
op_lshift
id|real_cpu
)paren
)paren
)paren
(brace
r_continue
suffix:semicolon
)brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|cpu_irq_affinity
(braket
id|real_cpu
)braket
op_amp
id|mask
)paren
)paren
(brace
multiline_comment|/* irq has no affinity for this CPU, ignore */
r_continue
suffix:semicolon
)brace
r_if
c_cond
(paren
id|real_cpu
op_eq
id|cpu
)paren
(brace
id|enable_local_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|vic_irq_mask
(braket
id|real_cpu
)braket
op_amp
id|mask
)paren
(brace
id|vic_irq_enable_mask
(braket
id|real_cpu
)braket
op_or_assign
id|mask
suffix:semicolon
id|processorList
op_or_assign
(paren
l_int|1
op_lshift
id|real_cpu
)paren
suffix:semicolon
)brace
)brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|vic_irq_lock
comma
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|processorList
)paren
(brace
id|send_CPI
c_func
(paren
id|processorList
comma
id|VIC_ENABLE_IRQ_CPI
)paren
suffix:semicolon
)brace
)brace
r_static
r_void
DECL|function|disable_vic_irq
id|disable_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
multiline_comment|/* lazy disable, do nothing */
)brace
r_static
r_void
DECL|function|enable_local_vic_irq
id|enable_local_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|__u16
id|mask
op_assign
op_complement
(paren
l_int|1
op_lshift
id|irq
)paren
suffix:semicolon
id|__u16
id|old_mask
op_assign
id|vic_irq_mask
(braket
id|cpu
)braket
suffix:semicolon
id|vic_irq_mask
(braket
id|cpu
)braket
op_and_assign
id|mask
suffix:semicolon
r_if
c_cond
(paren
id|vic_irq_mask
(braket
id|cpu
)braket
op_eq
id|old_mask
)paren
(brace
r_return
suffix:semicolon
)brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER DEBUG: Enabling irq %d in hardware on CPU %d&bslash;n&quot;
comma
id|irq
comma
id|cpu
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|irq
op_amp
l_int|8
)paren
(brace
id|outb_p
c_func
(paren
id|cached_A1
c_func
(paren
id|cpu
)paren
comma
l_int|0xA1
)paren
suffix:semicolon
(paren
r_void
)paren
id|inb_p
c_func
(paren
l_int|0xA1
)paren
suffix:semicolon
)brace
r_else
(brace
id|outb_p
c_func
(paren
id|cached_21
c_func
(paren
id|cpu
)paren
comma
l_int|0x21
)paren
suffix:semicolon
(paren
r_void
)paren
id|inb_p
c_func
(paren
l_int|0x21
)paren
suffix:semicolon
)brace
)brace
r_static
r_void
DECL|function|disable_local_vic_irq
id|disable_local_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|__u16
id|mask
op_assign
(paren
l_int|1
op_lshift
id|irq
)paren
suffix:semicolon
id|__u16
id|old_mask
op_assign
id|vic_irq_mask
(braket
id|cpu
)braket
suffix:semicolon
r_if
c_cond
(paren
id|irq
op_eq
l_int|7
)paren
(brace
r_return
suffix:semicolon
)brace
id|vic_irq_mask
(braket
id|cpu
)braket
op_or_assign
id|mask
suffix:semicolon
r_if
c_cond
(paren
id|old_mask
op_eq
id|vic_irq_mask
(braket
id|cpu
)braket
)paren
(brace
r_return
suffix:semicolon
)brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER DEBUG: Disabling irq %d in hardware on CPU %d&bslash;n&quot;
comma
id|irq
comma
id|cpu
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|irq
op_amp
l_int|8
)paren
(brace
id|outb_p
c_func
(paren
id|cached_A1
c_func
(paren
id|cpu
)paren
comma
l_int|0xA1
)paren
suffix:semicolon
(paren
r_void
)paren
id|inb_p
c_func
(paren
l_int|0xA1
)paren
suffix:semicolon
)brace
r_else
(brace
id|outb_p
c_func
(paren
id|cached_21
c_func
(paren
id|cpu
)paren
comma
l_int|0x21
)paren
suffix:semicolon
(paren
r_void
)paren
id|inb_p
c_func
(paren
l_int|0x21
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* The VIC is level triggered, so the ack can only be issued after the&n; * interrupt completes.  However, we do Voyager lazy interrupt&n; * handling here: It is an extremely expensive operation to mask an&n; * interrupt in the vic, so we merely set a flag (IRQ_DISABLED).  If&n; * this interrupt actually comes in, then we mask and ack here to push&n; * the interrupt off to another CPU */
r_static
r_void
DECL|function|before_handle_vic_irq
id|before_handle_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
id|irq_desc_t
op_star
id|desc
op_assign
id|irq_desc
op_plus
id|irq
suffix:semicolon
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|_raw_spin_lock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
id|vic_intr_total
op_increment
suffix:semicolon
id|vic_intr_count
(braket
id|cpu
)braket
op_increment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
(paren
id|cpu_irq_affinity
(braket
id|cpu
)braket
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
)paren
)paren
(brace
multiline_comment|/* The irq is not in our affinity mask, push it off&n;&t;&t; * onto another CPU */
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER DEBUG: affinity triggered disable of irq %d on cpu %d&bslash;n&quot;
comma
id|irq
comma
id|cpu
)paren
)paren
suffix:semicolon
id|disable_local_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
multiline_comment|/* set IRQ_INPROGRESS to prevent the handler in irq.c from&n;&t;&t; * actually calling the interrupt routine */
id|desc-&gt;status
op_or_assign
id|IRQ_REPLAY
op_or
id|IRQ_INPROGRESS
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|desc-&gt;status
op_amp
id|IRQ_DISABLED
)paren
(brace
multiline_comment|/* Damn, the interrupt actually arrived, do the lazy&n;&t;&t; * disable thing. The interrupt routine in irq.c will&n;&t;&t; * not handle a IRQ_DISABLED interrupt, so nothing more&n;&t;&t; * need be done here */
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER DEBUG: lazy disable of irq %d on CPU %d&bslash;n&quot;
comma
id|irq
comma
id|cpu
)paren
)paren
suffix:semicolon
id|disable_local_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
id|desc-&gt;status
op_or_assign
id|IRQ_REPLAY
suffix:semicolon
)brace
r_else
(brace
id|desc-&gt;status
op_and_assign
op_complement
id|IRQ_REPLAY
suffix:semicolon
)brace
id|_raw_spin_unlock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
)brace
multiline_comment|/* Finish the VIC interrupt: basically mask */
r_static
r_void
DECL|function|after_handle_vic_irq
id|after_handle_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
id|irq_desc_t
op_star
id|desc
op_assign
id|irq_desc
op_plus
id|irq
suffix:semicolon
id|_raw_spin_lock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
(brace
r_int
r_int
id|status
op_assign
id|desc-&gt;status
op_amp
op_complement
id|IRQ_INPROGRESS
suffix:semicolon
macro_line|#ifdef VOYAGER_DEBUG
id|__u16
id|isr
suffix:semicolon
macro_line|#endif
id|desc-&gt;status
op_assign
id|status
suffix:semicolon
r_if
c_cond
(paren
(paren
id|status
op_amp
id|IRQ_DISABLED
)paren
)paren
id|disable_local_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
macro_line|#ifdef VOYAGER_DEBUG
multiline_comment|/* DEBUG: before we ack, check what&squot;s in progress */
id|isr
op_assign
id|vic_read_isr
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|isr
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
op_logical_and
op_logical_neg
(paren
id|status
op_amp
id|IRQ_REPLAY
)paren
)paren
op_eq
l_int|0
)paren
(brace
r_int
id|i
suffix:semicolon
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|__u8
id|real_cpu
suffix:semicolon
r_int
id|mask
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: CPU%d lost interrupt %d&bslash;n&quot;
comma
id|cpu
comma
id|irq
)paren
suffix:semicolon
id|for_each_cpu
c_func
(paren
id|real_cpu
comma
id|mask
)paren
(brace
id|outb
c_func
(paren
id|VIC_CPU_MASQUERADE_ENABLE
op_or
id|real_cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
id|isr
op_assign
id|vic_read_isr
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|isr
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: CPU%d ack irq %d&bslash;n&quot;
comma
id|real_cpu
comma
id|irq
)paren
suffix:semicolon
id|ack_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
)brace
id|outb
c_func
(paren
id|cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
)brace
)brace
macro_line|#endif /* VOYAGER_DEBUG */
multiline_comment|/* as soon as we ack, the interrupt is eligible for&n;&t;&t; * receipt by another CPU so everything must be in&n;&t;&t; * order here  */
id|ack_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|status
op_amp
id|IRQ_REPLAY
)paren
(brace
multiline_comment|/* replay is set if we disable the interrupt&n;&t;&t;&t; * in the before_handle_vic_irq() routine, so&n;&t;&t;&t; * clear the in progress bit here to allow the&n;&t;&t;&t; * next CPU to handle this correctly */
id|desc-&gt;status
op_and_assign
op_complement
(paren
id|IRQ_REPLAY
op_or
id|IRQ_INPROGRESS
)paren
suffix:semicolon
)brace
macro_line|#ifdef VOYAGER_DEBUG
id|isr
op_assign
id|vic_read_isr
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|isr
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
)paren
op_ne
l_int|0
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;VOYAGER SMP: after_handle_vic_irq() after ack irq=%d, isr=0x%x&bslash;n&quot;
comma
id|irq
comma
id|isr
)paren
suffix:semicolon
)brace
macro_line|#endif /* VOYAGER_DEBUG */
)brace
id|_raw_spin_unlock
c_func
(paren
op_amp
id|vic_irq_lock
)paren
suffix:semicolon
multiline_comment|/* All code after this point is out of the main path - the IRQ&n;&t; * may be intercepted by another CPU if reasserted */
)brace
multiline_comment|/* Linux processor - interrupt affinity manipulations.&n; *&n; * For each processor, we maintain a 32 bit irq affinity mask.&n; * Initially it is set to all 1&squot;s so every processor accepts every&n; * interrupt.  In this call, we change the processor&squot;s affinity mask:&n; *&n; * Change from enable to disable:&n; *&n; * If the interrupt ever comes in to the processor, we will disable it&n; * and ack it to push it off to another CPU, so just accept the mask here.&n; *&n; * Change from disable to enable:&n; *&n; * change the mask and then do an interrupt enable CPI to re-enable on&n; * the selected processors */
r_void
DECL|function|set_vic_irq_affinity
id|set_vic_irq_affinity
c_func
(paren
r_int
r_int
id|irq
comma
r_int
r_int
id|mask
)paren
(brace
multiline_comment|/* Only extended processors handle interrupts */
r_int
r_int
id|real_mask
op_assign
id|mask
op_amp
id|voyager_extended_vic_processors
suffix:semicolon
r_int
r_int
id|irq_mask
op_assign
(paren
l_int|1
op_lshift
id|irq
)paren
suffix:semicolon
r_int
id|tmpmask
suffix:semicolon
id|__u8
id|cpu
suffix:semicolon
r_if
c_cond
(paren
id|mask
op_eq
l_int|0
)paren
(brace
multiline_comment|/* can&squot;t have no cpu&squot;s to accept the interrupt -- extremely&n;&t;&t; * bad things will happen */
r_return
suffix:semicolon
)brace
r_if
c_cond
(paren
id|irq
op_eq
l_int|0
)paren
(brace
multiline_comment|/* can&squot;t change the affinity of the timer IRQ.  This&n;&t;&t; * is due to the constraint in the voyager&n;&t;&t; * architecture that the CPI also comes in on and IRQ&n;&t;&t; * line and we have chosen IRQ0 for this.  If you&n;&t;&t; * raise the mask on this interrupt, the processor&n;&t;&t; * will no-longer be able to accept VIC CPIs */
r_return
suffix:semicolon
)brace
r_if
c_cond
(paren
id|irq
op_ge
l_int|32
)paren
(brace
multiline_comment|/* You can only have 32 interrupts in a voyager system&n;&t;&t; * (and 32 only if you have a secondary microchannel&n;&t;&t; * bus) */
r_return
suffix:semicolon
)brace
id|for_each_cpu
c_func
(paren
id|cpu
comma
id|tmpmask
)paren
(brace
r_int
r_int
id|cpu_mask
op_assign
(paren
l_int|1
op_lshift
id|cpu
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_mask
op_amp
id|real_mask
)paren
(brace
multiline_comment|/* enable the interrupt for this cpu */
id|cpu_irq_affinity
(braket
id|cpu
)braket
op_or_assign
id|irq_mask
suffix:semicolon
)brace
r_else
(brace
multiline_comment|/* disable the interrupt for this cpu */
id|cpu_irq_affinity
(braket
id|cpu
)braket
op_and_assign
op_complement
id|irq_mask
suffix:semicolon
)brace
)brace
multiline_comment|/* this is magic, we now have the correct affinity maps, so&n;&t; * enable the interrupt.  This will send an enable CPI to&n;&t; * those cpu&squot;s who need to enable it in their local masks,&n;&t; * causing them to correct for the new affinity . If the&n;&t; * interrupt is currently globally disabled, it will simply be&n;&t; * disabled again as it comes in (voyager lazy disable).  If&n;&t; * the affinity map is tightened to disable the interrupt on a&n;&t; * cpu, it will be pushed off when it comes in */
id|enable_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
)brace
r_static
r_void
DECL|function|ack_vic_irq
id|ack_vic_irq
c_func
(paren
r_int
r_int
id|irq
)paren
(brace
r_if
c_cond
(paren
id|irq
op_amp
l_int|8
)paren
(brace
id|outb
c_func
(paren
l_int|0x62
comma
l_int|0x20
)paren
suffix:semicolon
multiline_comment|/* Specific EOI to cascade */
id|outb
c_func
(paren
l_int|0x60
op_or
(paren
id|irq
op_amp
l_int|7
)paren
comma
l_int|0xA0
)paren
suffix:semicolon
)brace
r_else
(brace
id|outb
c_func
(paren
l_int|0x60
op_or
(paren
id|irq
op_amp
l_int|7
)paren
comma
l_int|0x20
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/* enable the CPIs.  In the VIC, the CPIs are delivered by the 8259&n; * but are not vectored by it.  This means that the 8259 mask must be&n; * lowered to receive them */
r_static
id|__init
r_void
DECL|function|vic_enable_cpi
id|vic_enable_cpi
c_func
(paren
r_void
)paren
(brace
id|__u8
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* just take a copy of the current mask (nop for boot cpu) */
id|vic_irq_mask
(braket
id|cpu
)braket
op_assign
id|vic_irq_mask
(braket
id|boot_cpu_id
)braket
suffix:semicolon
id|enable_local_vic_irq
c_func
(paren
id|VIC_CPI_LEVEL0
)paren
suffix:semicolon
id|enable_local_vic_irq
c_func
(paren
id|VIC_CPI_LEVEL1
)paren
suffix:semicolon
multiline_comment|/* for sys int and cmn int */
id|enable_local_vic_irq
c_func
(paren
l_int|7
)paren
suffix:semicolon
r_if
c_cond
(paren
id|is_cpu_quad
c_func
(paren
)paren
)paren
(brace
id|outb
c_func
(paren
id|QIC_DEFAULT_MASK0
comma
id|QIC_MASK_REGISTER0
)paren
suffix:semicolon
id|outb
c_func
(paren
id|QIC_CPI_ENABLE
comma
id|QIC_MASK_REGISTER1
)paren
suffix:semicolon
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: QIC ENABLE CPI: CPU%d: MASK 0x%x&bslash;n&quot;
comma
id|cpu
comma
id|QIC_CPI_ENABLE
)paren
)paren
suffix:semicolon
)brace
id|VDEBUG
c_func
(paren
(paren
l_string|&quot;VOYAGER SMP: ENABLE CPI: CPU%d: MASK 0x%x&bslash;n&quot;
comma
id|cpu
comma
id|vic_irq_mask
(braket
id|cpu
)braket
)paren
)paren
suffix:semicolon
)brace
r_void
DECL|function|voyager_smp_dump
id|voyager_smp_dump
c_func
(paren
)paren
(brace
r_int
id|mask
suffix:semicolon
id|__u8
id|old_cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
comma
id|cpu
suffix:semicolon
multiline_comment|/* dump the interrupt masks of each processor */
id|for_each_cpu
c_func
(paren
id|cpu
comma
id|mask
)paren
(brace
id|__u16
id|imr
comma
id|isr
comma
id|irr
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|outb
c_func
(paren
id|VIC_CPU_MASQUERADE_ENABLE
op_or
id|cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
id|imr
op_assign
(paren
id|inb
c_func
(paren
l_int|0xa1
)paren
op_lshift
l_int|8
)paren
op_or
id|inb
c_func
(paren
l_int|0x21
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0a
comma
l_int|0xa0
)paren
suffix:semicolon
id|irr
op_assign
id|inb
c_func
(paren
l_int|0xa0
)paren
op_lshift
l_int|8
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0a
comma
l_int|0x20
)paren
suffix:semicolon
id|irr
op_or_assign
id|inb
c_func
(paren
l_int|0x20
)paren
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0b
comma
l_int|0xa0
)paren
suffix:semicolon
id|isr
op_assign
id|inb
c_func
(paren
l_int|0xa0
)paren
op_lshift
l_int|8
suffix:semicolon
id|outb
c_func
(paren
l_int|0x0b
comma
l_int|0x20
)paren
suffix:semicolon
id|isr
op_or_assign
id|inb
c_func
(paren
l_int|0x20
)paren
suffix:semicolon
id|outb
c_func
(paren
id|old_cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;&bslash;tCPU%d: mask=0x%x, IMR=0x%x, IRR=0x%x, ISR=0x%x&bslash;n&quot;
comma
id|cpu
comma
id|vic_irq_mask
(braket
id|cpu
)braket
comma
id|imr
comma
id|irr
comma
id|isr
)paren
suffix:semicolon
macro_line|#if 0
multiline_comment|/* These lines are put in to try to unstick an un ack&squot;d irq */
r_if
c_cond
(paren
id|isr
op_ne
l_int|0
)paren
(brace
r_int
id|irq
suffix:semicolon
r_for
c_loop
(paren
id|irq
op_assign
l_int|0
suffix:semicolon
id|irq
OL
l_int|16
suffix:semicolon
id|irq
op_increment
)paren
(brace
r_if
c_cond
(paren
id|isr
op_amp
(paren
l_int|1
op_lshift
id|irq
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;&bslash;tCPU%d: ack irq %d&bslash;n&quot;
comma
id|cpu
comma
id|irq
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|outb
c_func
(paren
id|VIC_CPU_MASQUERADE_ENABLE
op_or
id|cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
id|ack_vic_irq
c_func
(paren
id|irq
)paren
suffix:semicolon
id|outb
c_func
(paren
id|old_cpu
comma
id|VIC_PROCESSOR_ID
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
)brace
)brace
macro_line|#endif
)brace
)brace
r_void
DECL|function|smp_voyager_power_off
id|smp_voyager_power_off
c_func
(paren
r_void
op_star
id|dummy
)paren
(brace
r_if
c_cond
(paren
id|smp_processor_id
c_func
(paren
)paren
op_eq
id|boot_cpu_id
)paren
(brace
id|voyager_power_off
c_func
(paren
)paren
suffix:semicolon
)brace
r_else
id|smp_stop_cpu_function
c_func
(paren
l_int|NULL
)paren
suffix:semicolon
)brace
r_void
id|__init
DECL|function|smp_prepare_cpus
id|smp_prepare_cpus
c_func
(paren
r_int
r_int
id|max_cpus
)paren
(brace
multiline_comment|/* FIXME: ignore max_cpus for now */
id|smp_boot_cpus
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|function|smp_prepare_boot_cpu
r_void
id|__devinit
id|smp_prepare_boot_cpu
c_func
(paren
r_void
)paren
(brace
id|set_bit
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
comma
op_amp
id|cpu_online_map
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
comma
op_amp
id|cpu_callout_map
)paren
suffix:semicolon
)brace
r_int
id|__devinit
DECL|function|__cpu_up
id|__cpu_up
c_func
(paren
r_int
r_int
id|cpu
)paren
(brace
multiline_comment|/* This only works at boot for x86.  See &quot;rewrite&quot; above. */
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_commenced_mask
)paren
)paren
r_return
op_minus
id|ENOSYS
suffix:semicolon
multiline_comment|/* In case one didn&squot;t come up */
r_if
c_cond
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|cpu
comma
op_amp
id|cpu_callin_map
)paren
)paren
r_return
op_minus
id|EIO
suffix:semicolon
multiline_comment|/* Unleash the CPU! */
id|set_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_commenced_mask
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|cpu
comma
op_amp
id|cpu_online_map
)paren
)paren
id|mb
c_func
(paren
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_void
id|__init
DECL|function|smp_cpus_done
id|smp_cpus_done
c_func
(paren
r_int
r_int
id|max_cpus
)paren
(brace
id|zap_low_mappings
c_func
(paren
)paren
suffix:semicolon
)brace
eof
