macro_line|#ifndef ASMARM_DMA_MAPPING_H
DECL|macro|ASMARM_DMA_MAPPING_H
mdefine_line|#define ASMARM_DMA_MAPPING_H
macro_line|#ifdef __KERNEL__
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/mm.h&gt; /* need struct page */
macro_line|#include &lt;asm/scatterlist.h&gt;
multiline_comment|/*&n; * DMA-consistent mapping functions.  These allocate/free a region of&n; * uncached, unwrite-buffered mapped memory space for use with DMA&n; * devices.  This is the &quot;generic&quot; version.  The PCI specific version&n; * is in pci.h&n; */
r_extern
r_void
id|consistent_sync
c_func
(paren
r_void
op_star
id|kaddr
comma
r_int
id|size
comma
r_int
id|rw
)paren
suffix:semicolon
multiline_comment|/*&n; * Return whether the given device DMA address mask can be supported&n; * properly.  For example, if your device can only drive the low 24-bits&n; * during bus mastering, then you would pass 0x00ffffff as the mask&n; * to this function.&n; */
DECL|function|dma_supported
r_static
r_inline
r_int
id|dma_supported
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|u64
id|mask
)paren
(brace
r_return
id|dev-&gt;dma_mask
op_logical_and
op_star
id|dev-&gt;dma_mask
op_ne
l_int|0
suffix:semicolon
)brace
DECL|function|dma_set_mask
r_static
r_inline
r_int
id|dma_set_mask
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|u64
id|dma_mask
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|dev-&gt;dma_mask
op_logical_or
op_logical_neg
id|dma_supported
c_func
(paren
id|dev
comma
id|dma_mask
)paren
)paren
r_return
op_minus
id|EIO
suffix:semicolon
op_star
id|dev-&gt;dma_mask
op_assign
id|dma_mask
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|dma_get_cache_alignment
r_static
r_inline
r_int
id|dma_get_cache_alignment
c_func
(paren
r_void
)paren
(brace
r_return
l_int|32
suffix:semicolon
)brace
DECL|function|dma_is_consistent
r_static
r_inline
r_int
id|dma_is_consistent
c_func
(paren
id|dma_addr_t
id|handle
)paren
(brace
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * DMA errors are defined by all-bits-set in the DMA address.&n; */
DECL|function|dma_mapping_error
r_static
r_inline
r_int
id|dma_mapping_error
c_func
(paren
id|dma_addr_t
id|dma_addr
)paren
(brace
r_return
id|dma_addr
op_eq
op_complement
l_int|0
suffix:semicolon
)brace
multiline_comment|/**&n; * dma_alloc_coherent - allocate consistent memory for DMA&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @size: required memory size&n; * @handle: bus-specific DMA address&n; *&n; * Allocate some uncached, unbuffered memory for a device for&n; * performing DMA.  This function allocates pages, and will&n; * return the CPU-viewed address, and sets @handle to be the&n; * device-viewed address.&n; */
r_extern
r_void
op_star
id|dma_alloc_coherent
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_int
id|size
comma
id|dma_addr_t
op_star
id|handle
comma
r_int
id|gfp
)paren
suffix:semicolon
multiline_comment|/**&n; * dma_free_coherent - free memory allocated by dma_alloc_coherent&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @size: size of memory originally requested in dma_alloc_coherent&n; * @cpu_addr: CPU-view address returned from dma_alloc_coherent&n; * @handle: device-view address returned from dma_alloc_coherent&n; *&n; * Free (and unmap) a DMA buffer previously allocated by&n; * dma_alloc_coherent().&n; *&n; * References to memory and mappings associated with cpu_addr/handle&n; * during and after this call executing are illegal.&n; */
r_extern
r_void
id|dma_free_coherent
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_int
id|size
comma
r_void
op_star
id|cpu_addr
comma
id|dma_addr_t
id|handle
)paren
suffix:semicolon
multiline_comment|/**&n; * dma_mmap_coherent - map a coherent DMA allocation into user space&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @vma: vm_area_struct describing requested user mapping&n; * @cpu_addr: kernel CPU-view address returned from dma_alloc_coherent&n; * @handle: device-view address returned from dma_alloc_coherent&n; * @size: size of memory originally requested in dma_alloc_coherent&n; *&n; * Map a coherent DMA buffer previously allocated by dma_alloc_coherent&n; * into user space.  The coherent DMA buffer must not be freed by the&n; * driver until the user space mapping has been released.&n; */
r_int
id|dma_mmap_coherent
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|vm_area_struct
op_star
id|vma
comma
r_void
op_star
id|cpu_addr
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
)paren
suffix:semicolon
multiline_comment|/**&n; * dma_alloc_writecombine - allocate writecombining memory for DMA&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @size: required memory size&n; * @handle: bus-specific DMA address&n; *&n; * Allocate some uncached, buffered memory for a device for&n; * performing DMA.  This function allocates pages, and will&n; * return the CPU-viewed address, and sets @handle to be the&n; * device-viewed address.&n; */
r_extern
r_void
op_star
id|dma_alloc_writecombine
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_int
id|size
comma
id|dma_addr_t
op_star
id|handle
comma
r_int
id|gfp
)paren
suffix:semicolon
DECL|macro|dma_free_writecombine
mdefine_line|#define dma_free_writecombine(dev,size,cpu_addr,handle) &bslash;&n;&t;dma_free_coherent(dev,size,cpu_addr,handle)
r_int
id|dma_mmap_writecombine
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|vm_area_struct
op_star
id|vma
comma
r_void
op_star
id|cpu_addr
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
)paren
suffix:semicolon
multiline_comment|/**&n; * dma_map_single - map a single buffer for streaming DMA&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @cpu_addr: CPU direct mapped address of buffer&n; * @size: size of buffer to map&n; * @dir: DMA transfer direction&n; *&n; * Ensure that any data held in the cache is appropriately discarded&n; * or written back.&n; *&n; * The device owns this memory once this call has completed.  The CPU&n; * can regain ownership by calling dma_unmap_single() or&n; * dma_sync_single_for_cpu().&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
id|dma_addr_t
DECL|function|dma_map_single
id|dma_map_single
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_void
op_star
id|cpu_addr
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
id|consistent_sync
c_func
(paren
id|cpu_addr
comma
id|size
comma
id|dir
)paren
suffix:semicolon
r_return
id|virt_to_dma
c_func
(paren
id|dev
comma
(paren
r_int
r_int
)paren
id|cpu_addr
)paren
suffix:semicolon
)brace
macro_line|#else
r_extern
id|dma_addr_t
id|dma_map_single
c_func
(paren
r_struct
id|device
op_star
comma
r_void
op_star
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/**&n; * dma_map_page - map a portion of a page for streaming DMA&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @page: page that buffer resides in&n; * @offset: offset into page for start of buffer&n; * @size: size of buffer to map&n; * @dir: DMA transfer direction&n; *&n; * Ensure that any data held in the cache is appropriately discarded&n; * or written back.&n; *&n; * The device owns this memory once this call has completed.  The CPU&n; * can regain ownership by calling dma_unmap_page() or&n; * dma_sync_single_for_cpu().&n; */
r_static
r_inline
id|dma_addr_t
DECL|function|dma_map_page
id|dma_map_page
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|page
op_star
id|page
comma
r_int
r_int
id|offset
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
r_return
id|dma_map_single
c_func
(paren
id|dev
comma
id|page_address
c_func
(paren
id|page
)paren
op_plus
id|offset
comma
id|size
comma
(paren
r_int
)paren
id|dir
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * dma_unmap_single - unmap a single buffer previously mapped&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @handle: DMA address of buffer&n; * @size: size of buffer to map&n; * @dir: DMA transfer direction&n; *&n; * Unmap a single streaming mode DMA translation.  The handle and size&n; * must match what was provided in the previous dma_map_single() call.&n; * All other usages are undefined.&n; *&n; * After this call, reads by the CPU to the buffer are guaranteed to see&n; * whatever the device wrote there.&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
r_void
DECL|function|dma_unmap_single
id|dma_unmap_single
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
multiline_comment|/* nothing to do */
)brace
macro_line|#else
r_extern
r_void
id|dma_unmap_single
c_func
(paren
r_struct
id|device
op_star
comma
id|dma_addr_t
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/**&n; * dma_unmap_page - unmap a buffer previously mapped through dma_map_page()&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @handle: DMA address of buffer&n; * @size: size of buffer to map&n; * @dir: DMA transfer direction&n; *&n; * Unmap a single streaming mode DMA translation.  The handle and size&n; * must match what was provided in the previous dma_map_single() call.&n; * All other usages are undefined.&n; *&n; * After this call, reads by the CPU to the buffer are guaranteed to see&n; * whatever the device wrote there.&n; */
r_static
r_inline
r_void
DECL|function|dma_unmap_page
id|dma_unmap_page
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
id|dma_unmap_single
c_func
(paren
id|dev
comma
id|handle
comma
id|size
comma
(paren
r_int
)paren
id|dir
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * dma_map_sg - map a set of SG buffers for streaming mode DMA&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @sg: list of buffers&n; * @nents: number of buffers to map&n; * @dir: DMA transfer direction&n; *&n; * Map a set of buffers described by scatterlist in streaming&n; * mode for DMA.  This is the scatter-gather version of the&n; * above dma_map_single interface.  Here the scatter gather list&n; * elements are each tagged with the appropriate dma address&n; * and length.  They are obtained via sg_dma_{address,length}(SG).&n; *&n; * NOTE: An implementation may be able to use a smaller number of&n; *       DMA address/length pairs than there are SG table elements.&n; *       (for example via virtual mapping capabilities)&n; *       The routine returns the number of addr/length pairs actually&n; *       used, at most nents.&n; *&n; * Device ownership issues as mentioned above for dma_map_single are&n; * the same here.&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
r_int
DECL|function|dma_map_sg
id|dma_map_sg
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
r_int
id|i
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nents
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
(brace
r_char
op_star
id|virt
suffix:semicolon
id|sg-&gt;dma_address
op_assign
id|page_to_dma
c_func
(paren
id|dev
comma
id|sg-&gt;page
)paren
op_plus
id|sg-&gt;offset
suffix:semicolon
id|virt
op_assign
id|page_address
c_func
(paren
id|sg-&gt;page
)paren
op_plus
id|sg-&gt;offset
suffix:semicolon
id|consistent_sync
c_func
(paren
id|virt
comma
id|sg-&gt;length
comma
id|dir
)paren
suffix:semicolon
)brace
r_return
id|nents
suffix:semicolon
)brace
macro_line|#else
r_extern
r_int
id|dma_map_sg
c_func
(paren
r_struct
id|device
op_star
comma
r_struct
id|scatterlist
op_star
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/**&n; * dma_unmap_sg - unmap a set of SG buffers mapped by dma_map_sg&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @sg: list of buffers&n; * @nents: number of buffers to map&n; * @dir: DMA transfer direction&n; *&n; * Unmap a set of streaming mode DMA translations.&n; * Again, CPU read rules concerning calls here are the same as for&n; * dma_unmap_single() above.&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
r_void
DECL|function|dma_unmap_sg
id|dma_unmap_sg
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
multiline_comment|/* nothing to do */
)brace
macro_line|#else
r_extern
r_void
id|dma_unmap_sg
c_func
(paren
r_struct
id|device
op_star
comma
r_struct
id|scatterlist
op_star
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/**&n; * dma_sync_single_for_cpu&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @handle: DMA address of buffer&n; * @size: size of buffer to map&n; * @dir: DMA transfer direction&n; *&n; * Make physical memory consistent for a single streaming mode DMA&n; * translation after a transfer.&n; *&n; * If you perform a dma_map_single() but wish to interrogate the&n; * buffer using the cpu, yet do not wish to teardown the PCI dma&n; * mapping, you must call this function before doing so.  At the&n; * next point you give the PCI dma address back to the card, you&n; * must first the perform a dma_sync_for_device, and then the&n; * device again owns the buffer.&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
r_void
DECL|function|dma_sync_single_for_cpu
id|dma_sync_single_for_cpu
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
id|consistent_sync
c_func
(paren
(paren
r_void
op_star
)paren
id|dma_to_virt
c_func
(paren
id|dev
comma
id|handle
)paren
comma
id|size
comma
id|dir
)paren
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|dma_sync_single_for_device
id|dma_sync_single_for_device
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
id|dma_addr_t
id|handle
comma
r_int
id|size
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
id|consistent_sync
c_func
(paren
(paren
r_void
op_star
)paren
id|dma_to_virt
c_func
(paren
id|dev
comma
id|handle
)paren
comma
id|size
comma
id|dir
)paren
suffix:semicolon
)brace
macro_line|#else
r_extern
r_void
id|dma_sync_single_for_cpu
c_func
(paren
r_struct
id|device
op_star
comma
id|dma_addr_t
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
r_extern
r_void
id|dma_sync_single_for_device
c_func
(paren
r_struct
id|device
op_star
comma
id|dma_addr_t
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/**&n; * dma_sync_sg_for_cpu&n; * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices&n; * @sg: list of buffers&n; * @nents: number of buffers to map&n; * @dir: DMA transfer direction&n; *&n; * Make physical memory consistent for a set of streaming&n; * mode DMA translations after a transfer.&n; *&n; * The same as dma_sync_single_for_* but for a scatter-gather list,&n; * same rules and usage.&n; */
macro_line|#ifndef CONFIG_DMABOUNCE
r_static
r_inline
r_void
DECL|function|dma_sync_sg_for_cpu
id|dma_sync_sg_for_cpu
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
r_int
id|i
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nents
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
(brace
r_char
op_star
id|virt
op_assign
id|page_address
c_func
(paren
id|sg-&gt;page
)paren
op_plus
id|sg-&gt;offset
suffix:semicolon
id|consistent_sync
c_func
(paren
id|virt
comma
id|sg-&gt;length
comma
id|dir
)paren
suffix:semicolon
)brace
)brace
r_static
r_inline
r_void
DECL|function|dma_sync_sg_for_device
id|dma_sync_sg_for_device
c_func
(paren
r_struct
id|device
op_star
id|dev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_enum
id|dma_data_direction
id|dir
)paren
(brace
r_int
id|i
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nents
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
(brace
r_char
op_star
id|virt
op_assign
id|page_address
c_func
(paren
id|sg-&gt;page
)paren
op_plus
id|sg-&gt;offset
suffix:semicolon
id|consistent_sync
c_func
(paren
id|virt
comma
id|sg-&gt;length
comma
id|dir
)paren
suffix:semicolon
)brace
)brace
macro_line|#else
r_extern
r_void
id|dma_sync_sg_for_cpu
c_func
(paren
r_struct
id|device
op_star
comma
r_struct
id|scatterlist
op_star
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
r_extern
r_void
id|dma_sync_sg_for_device
c_func
(paren
r_struct
id|device
op_star
comma
r_struct
id|scatterlist
op_star
comma
r_int
comma
r_enum
id|dma_data_direction
)paren
suffix:semicolon
macro_line|#endif
macro_line|#ifdef CONFIG_DMABOUNCE
multiline_comment|/*&n; * For SA-1111, IXP425, and ADI systems  the dma-mapping functions are &quot;magic&quot;&n; * and utilize bounce buffers as needed to work around limited DMA windows.&n; *&n; * On the SA-1111, a bug limits DMA to only certain regions of RAM.&n; * On the IXP425, the PCI inbound window is 64MB (256MB total RAM)&n; * On some ADI engineering sytems, PCI inbound window is 32MB (12MB total RAM)&n; *&n; * The following are helper functions used by the dmabounce subystem&n; *&n; */
multiline_comment|/**&n; * dmabounce_register_dev&n; *&n; * @dev: valid struct device pointer&n; * @small_buf_size: size of buffers to use with small buffer pool&n; * @large_buf_size: size of buffers to use with large buffer pool (can be 0)&n; *&n; * This function should be called by low-level platform code to register&n; * a device as requireing DMA buffer bouncing. The function will allocate&n; * appropriate DMA pools for the device.&n; *&n; */
r_extern
r_int
id|dmabounce_register_dev
c_func
(paren
r_struct
id|device
op_star
comma
r_int
r_int
comma
r_int
r_int
)paren
suffix:semicolon
multiline_comment|/**&n; * dmabounce_unregister_dev&n; *&n; * @dev: valid struct device pointer&n; *&n; * This function should be called by low-level platform code when device&n; * that was previously registered with dmabounce_register_dev is removed&n; * from the system.&n; *&n; */
r_extern
r_void
id|dmabounce_unregister_dev
c_func
(paren
r_struct
id|device
op_star
)paren
suffix:semicolon
multiline_comment|/**&n; * dma_needs_bounce&n; *&n; * @dev: valid struct device pointer&n; * @dma_handle: dma_handle of unbounced buffer&n; * @size: size of region being mapped&n; *&n; * Platforms that utilize the dmabounce mechanism must implement&n; * this function.&n; *&n; * The dmabounce routines call this function whenever a dma-mapping&n; * is requested to determine whether a given buffer needs to be bounced&n; * or not. The function must return 0 if the the buffer is OK for&n; * DMA access and 1 if the buffer needs to be bounced.&n; *&n; */
r_extern
r_int
id|dma_needs_bounce
c_func
(paren
r_struct
id|device
op_star
comma
id|dma_addr_t
comma
r_int
)paren
suffix:semicolon
macro_line|#endif /* CONFIG_DMABOUNCE */
macro_line|#endif /* __KERNEL__ */
macro_line|#endif
eof
