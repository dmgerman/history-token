multiline_comment|/*&n; *  linux/kernel/sched.c&n; *&n; *  Kernel scheduler and related syscalls&n; *&n; *  Copyright (C) 1991, 1992  Linus Torvalds&n; *&n; *  1996-12-23  Modified by Dave Grothe to fix bugs in semaphores and&n; *              make semaphores SMP safe&n; *  1998-11-19&t;Implemented schedule_timeout() and related stuff&n; *&t;&t;by Andrea Arcangeli&n; *  1998-12-28  Implemented better SMP scheduling by Ingo Molnar&n; */
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/nmi.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;asm/uaccess.h&gt;
macro_line|#include &lt;linux/highmem.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;asm/mmu_context.h&gt;
macro_line|#include &lt;linux/interrupt.h&gt;
macro_line|#include &lt;linux/completion.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
multiline_comment|/*&n; * Priority of a process goes from 0 to 139. The 0-99&n; * priority range is allocated to RT tasks, the 100-139&n; * range is for SCHED_OTHER tasks. Priority values are&n; * inverted: lower p-&gt;prio value means higher priority.&n; */
DECL|macro|MAX_RT_PRIO
mdefine_line|#define MAX_RT_PRIO&t;&t;100
DECL|macro|MAX_PRIO
mdefine_line|#define MAX_PRIO&t;&t;(MAX_RT_PRIO + 40)
multiline_comment|/*&n; * Convert user-nice values [ -20 ... 0 ... 19 ]&n; * to static priority [ 100 ... 139 (MAX_PRIO-1) ],&n; * and back.&n; */
DECL|macro|NICE_TO_PRIO
mdefine_line|#define NICE_TO_PRIO(nice)&t;(MAX_RT_PRIO + (nice) + 20)
DECL|macro|PRIO_TO_NICE
mdefine_line|#define PRIO_TO_NICE(prio)&t;((prio) - MAX_RT_PRIO - 20)
DECL|macro|TASK_NICE
mdefine_line|#define TASK_NICE(p)&t;&t;PRIO_TO_NICE((p)-&gt;static_prio)
multiline_comment|/*&n; * &squot;User priority&squot; is the nice value converted to something we&n; * can work with better when scaling various scheduler parameters,&n; * it&squot;s a [ 0 ... 39 ] range.&n; */
DECL|macro|USER_PRIO
mdefine_line|#define USER_PRIO(p)&t;&t;((p)-MAX_RT_PRIO)
DECL|macro|TASK_USER_PRIO
mdefine_line|#define TASK_USER_PRIO(p)&t;USER_PRIO((p)-&gt;static_prio)
DECL|macro|MAX_USER_PRIO
mdefine_line|#define MAX_USER_PRIO&t;&t;(USER_PRIO(MAX_PRIO))
multiline_comment|/*&n; * These are the &squot;tuning knobs&squot; of the scheduler:&n; *&n; * Minimum timeslice is 10 msecs, default timeslice is 150 msecs,&n; * maximum timeslice is 300 msecs. Timeslices get refilled after&n; * they expire.&n; */
DECL|macro|MIN_TIMESLICE
mdefine_line|#define MIN_TIMESLICE&t;&t;( 10 * HZ / 1000)
DECL|macro|MAX_TIMESLICE
mdefine_line|#define MAX_TIMESLICE&t;&t;(300 * HZ / 1000)
DECL|macro|CHILD_PENALTY
mdefine_line|#define CHILD_PENALTY&t;&t;95
DECL|macro|PARENT_PENALTY
mdefine_line|#define PARENT_PENALTY&t;&t;100
DECL|macro|EXIT_WEIGHT
mdefine_line|#define EXIT_WEIGHT&t;&t;3
DECL|macro|PRIO_BONUS_RATIO
mdefine_line|#define PRIO_BONUS_RATIO&t;25
DECL|macro|INTERACTIVE_DELTA
mdefine_line|#define INTERACTIVE_DELTA&t;2
DECL|macro|MAX_SLEEP_AVG
mdefine_line|#define MAX_SLEEP_AVG&t;&t;(2*HZ)
DECL|macro|STARVATION_LIMIT
mdefine_line|#define STARVATION_LIMIT&t;(2*HZ)
multiline_comment|/*&n; * If a task is &squot;interactive&squot; then we reinsert it in the active&n; * array after it has expired its current timeslice. (it will not&n; * continue to run immediately, it will still roundrobin with&n; * other interactive tasks.)&n; *&n; * This part scales the interactivity limit depending on niceness.&n; *&n; * We scale it linearly, offset by the INTERACTIVE_DELTA delta.&n; * Here are a few examples of different nice levels:&n; *&n; *  TASK_INTERACTIVE(-20): [1,1,1,1,1,1,1,1,1,0,0]&n; *  TASK_INTERACTIVE(-10): [1,1,1,1,1,1,1,0,0,0,0]&n; *  TASK_INTERACTIVE(  0): [1,1,1,1,0,0,0,0,0,0,0]&n; *  TASK_INTERACTIVE( 10): [1,1,0,0,0,0,0,0,0,0,0]&n; *  TASK_INTERACTIVE( 19): [0,0,0,0,0,0,0,0,0,0,0]&n; *&n; * (the X axis represents the possible -5 ... 0 ... +5 dynamic&n; *  priority range a task can explore, a value of &squot;1&squot; means the&n; *  task is rated interactive.)&n; *&n; * Ie. nice +19 tasks can never get &squot;interactive&squot; enough to be&n; * reinserted into the active array. And only heavily CPU-hog nice -20&n; * tasks will be expired. Default nice 0 tasks are somewhere between,&n; * it takes some effort for them to get interactive, but it&squot;s not&n; * too hard.&n; */
DECL|macro|SCALE
mdefine_line|#define SCALE(v1,v1_max,v2_max) &bslash;&n;&t;(v1) * (v2_max) / (v1_max)
DECL|macro|DELTA
mdefine_line|#define DELTA(p) &bslash;&n;&t;(SCALE(TASK_NICE(p), 40, MAX_USER_PRIO*PRIO_BONUS_RATIO/100) + &bslash;&n;&t;&t;INTERACTIVE_DELTA)
DECL|macro|TASK_INTERACTIVE
mdefine_line|#define TASK_INTERACTIVE(p) &bslash;&n;&t;((p)-&gt;prio &lt;= (p)-&gt;static_prio - DELTA(p))
multiline_comment|/*&n; * TASK_TIMESLICE scales user-nice values [ -20 ... 19 ]&n; * to time slice values.&n; *&n; * The higher a process&squot;s priority, the bigger timeslices&n; * it gets during one round of execution. But even the lowest&n; * priority process gets MIN_TIMESLICE worth of execution time.&n; */
DECL|macro|TASK_TIMESLICE
mdefine_line|#define TASK_TIMESLICE(p) (MIN_TIMESLICE + &bslash;&n;&t;((MAX_TIMESLICE - MIN_TIMESLICE) * (MAX_PRIO-1-(p)-&gt;static_prio)/39))
multiline_comment|/*&n; * These are the runqueue data structures:&n; */
DECL|macro|BITMAP_SIZE
mdefine_line|#define BITMAP_SIZE ((((MAX_PRIO+1+7)/8)+sizeof(long)-1)/sizeof(long))
DECL|typedef|runqueue_t
r_typedef
r_struct
id|runqueue
id|runqueue_t
suffix:semicolon
DECL|struct|prio_array
r_struct
id|prio_array
(brace
DECL|member|nr_active
r_int
id|nr_active
suffix:semicolon
DECL|member|bitmap
r_int
r_int
id|bitmap
(braket
id|BITMAP_SIZE
)braket
suffix:semicolon
DECL|member|queue
id|list_t
id|queue
(braket
id|MAX_PRIO
)braket
suffix:semicolon
)brace
suffix:semicolon
multiline_comment|/*&n; * This is the main, per-CPU runqueue data structure.&n; *&n; * Locking rule: those places that want to lock multiple runqueues&n; * (such as the load balancing or the process migration code), lock&n; * acquire operations must be ordered by ascending &amp;runqueue.&n; */
DECL|struct|runqueue
r_struct
id|runqueue
(brace
DECL|member|lock
id|spinlock_t
id|lock
suffix:semicolon
DECL|member|frozen
id|spinlock_t
id|frozen
suffix:semicolon
DECL|member|nr_running
DECL|member|nr_switches
DECL|member|expired_timestamp
r_int
r_int
id|nr_running
comma
id|nr_switches
comma
id|expired_timestamp
suffix:semicolon
DECL|member|curr
DECL|member|idle
id|task_t
op_star
id|curr
comma
op_star
id|idle
suffix:semicolon
DECL|member|active
DECL|member|expired
DECL|member|arrays
id|prio_array_t
op_star
id|active
comma
op_star
id|expired
comma
id|arrays
(braket
l_int|2
)braket
suffix:semicolon
DECL|member|prev_nr_running
r_int
id|prev_nr_running
(braket
id|NR_CPUS
)braket
suffix:semicolon
DECL|member|migration_thread
id|task_t
op_star
id|migration_thread
suffix:semicolon
DECL|member|migration_queue
id|list_t
id|migration_queue
suffix:semicolon
DECL|variable|____cacheline_aligned
)brace
id|____cacheline_aligned
suffix:semicolon
DECL|variable|__cacheline_aligned
r_static
r_struct
id|runqueue
id|runqueues
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
DECL|macro|cpu_rq
mdefine_line|#define cpu_rq(cpu)&t;&t;(runqueues + (cpu))
DECL|macro|this_rq
mdefine_line|#define this_rq()&t;&t;cpu_rq(smp_processor_id())
DECL|macro|task_rq
mdefine_line|#define task_rq(p)&t;&t;cpu_rq((p)-&gt;thread_info-&gt;cpu)
DECL|macro|cpu_curr
mdefine_line|#define cpu_curr(cpu)&t;&t;(cpu_rq(cpu)-&gt;curr)
DECL|macro|rt_task
mdefine_line|#define rt_task(p)&t;&t;((p)-&gt;prio &lt; MAX_RT_PRIO)
DECL|function|task_rq_lock
r_static
r_inline
id|runqueue_t
op_star
id|task_rq_lock
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
op_star
id|flags
)paren
(brace
r_struct
id|runqueue
op_star
id|rq
suffix:semicolon
id|repeat_lock_task
suffix:colon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|task_rq
c_func
(paren
id|p
)paren
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|rq-&gt;lock
comma
op_star
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|rq
op_ne
id|task_rq
c_func
(paren
id|p
)paren
)paren
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
op_star
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_goto
id|repeat_lock_task
suffix:semicolon
)brace
r_return
id|rq
suffix:semicolon
)brace
DECL|function|task_rq_unlock
r_static
r_inline
r_void
id|task_rq_unlock
c_func
(paren
id|runqueue_t
op_star
id|rq
comma
r_int
r_int
op_star
id|flags
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
op_star
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Adding/removing a task to/from a priority array:&n; */
DECL|function|dequeue_task
r_static
r_inline
r_void
id|dequeue_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|prio_array_t
op_star
id|array
)paren
(brace
id|array-&gt;nr_active
op_decrement
suffix:semicolon
id|list_del
c_func
(paren
op_amp
id|p-&gt;run_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|list_empty
c_func
(paren
id|array-&gt;queue
op_plus
id|p-&gt;prio
)paren
)paren
id|__clear_bit
c_func
(paren
id|p-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
DECL|function|enqueue_task
r_static
r_inline
r_void
id|enqueue_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|prio_array_t
op_star
id|array
)paren
(brace
id|list_add_tail
c_func
(paren
op_amp
id|p-&gt;run_list
comma
id|array-&gt;queue
op_plus
id|p-&gt;prio
)paren
suffix:semicolon
id|__set_bit
c_func
(paren
id|p-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
id|array-&gt;nr_active
op_increment
suffix:semicolon
id|p-&gt;array
op_assign
id|array
suffix:semicolon
)brace
DECL|function|effective_prio
r_static
r_inline
r_int
id|effective_prio
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
id|bonus
comma
id|prio
suffix:semicolon
multiline_comment|/*&n;&t; * Here we scale the actual sleep average [0 .... MAX_SLEEP_AVG]&n;&t; * into the -5 ... 0 ... +5 bonus/penalty range.&n;&t; *&n;&t; * We use 25% of the full 0...39 priority range so that:&n;&t; *&n;&t; * 1) nice +19 interactive tasks do not preempt nice 0 CPU hogs.&n;&t; * 2) nice -20 CPU hogs do not get preempted by nice 0 tasks.&n;&t; *&n;&t; * Both properties are important to certain workloads.&n;&t; */
id|bonus
op_assign
id|MAX_USER_PRIO
op_star
id|PRIO_BONUS_RATIO
op_star
id|p-&gt;sleep_avg
op_div
id|MAX_SLEEP_AVG
op_div
l_int|100
op_minus
id|MAX_USER_PRIO
op_star
id|PRIO_BONUS_RATIO
op_div
l_int|100
op_div
l_int|2
suffix:semicolon
id|prio
op_assign
id|p-&gt;static_prio
op_minus
id|bonus
suffix:semicolon
r_if
c_cond
(paren
id|prio
OL
id|MAX_RT_PRIO
)paren
id|prio
op_assign
id|MAX_RT_PRIO
suffix:semicolon
r_if
c_cond
(paren
id|prio
OG
id|MAX_PRIO
op_minus
l_int|1
)paren
id|prio
op_assign
id|MAX_PRIO
op_minus
l_int|1
suffix:semicolon
r_return
id|prio
suffix:semicolon
)brace
DECL|function|activate_task
r_static
r_inline
r_void
id|activate_task
c_func
(paren
id|task_t
op_star
id|p
comma
id|runqueue_t
op_star
id|rq
)paren
(brace
r_int
r_int
id|sleep_time
op_assign
id|jiffies
op_minus
id|p-&gt;sleep_timestamp
suffix:semicolon
id|prio_array_t
op_star
id|array
op_assign
id|rq-&gt;active
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rt_task
c_func
(paren
id|p
)paren
op_logical_and
id|sleep_time
)paren
(brace
multiline_comment|/*&n;&t;&t; * This code gives a bonus to interactive tasks. We update&n;&t;&t; * an &squot;average sleep time&squot; value here, based on&n;&t;&t; * sleep_timestamp. The more time a task spends sleeping,&n;&t;&t; * the higher the average gets - and the higher the priority&n;&t;&t; * boost gets as well.&n;&t;&t; */
id|p-&gt;sleep_avg
op_add_assign
id|sleep_time
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;sleep_avg
OG
id|MAX_SLEEP_AVG
)paren
id|p-&gt;sleep_avg
op_assign
id|MAX_SLEEP_AVG
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
id|enqueue_task
c_func
(paren
id|p
comma
id|array
)paren
suffix:semicolon
id|rq-&gt;nr_running
op_increment
suffix:semicolon
)brace
DECL|function|deactivate_task
r_static
r_inline
r_void
id|deactivate_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|runqueue_t
op_star
id|rq
)paren
(brace
id|rq-&gt;nr_running
op_decrement
suffix:semicolon
id|dequeue_task
c_func
(paren
id|p
comma
id|p-&gt;array
)paren
suffix:semicolon
id|p-&gt;array
op_assign
l_int|NULL
suffix:semicolon
)brace
DECL|function|resched_task
r_static
r_inline
r_void
id|resched_task
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
macro_line|#ifdef CONFIG_SMP
r_int
id|need_resched
comma
id|nrpolling
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* minimise the chance of sending an interrupt to poll_idle() */
id|nrpolling
op_assign
id|test_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_POLLING_NRFLAG
)paren
suffix:semicolon
id|need_resched
op_assign
id|test_and_set_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_NEED_RESCHED
)paren
suffix:semicolon
id|nrpolling
op_or_assign
id|test_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_POLLING_NRFLAG
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|need_resched
op_logical_and
op_logical_neg
id|nrpolling
op_logical_and
(paren
id|p-&gt;thread_info-&gt;cpu
op_ne
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
id|smp_send_reschedule
c_func
(paren
id|p-&gt;thread_info-&gt;cpu
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
macro_line|#else
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
macro_line|#endif
)brace
macro_line|#ifdef CONFIG_SMP
multiline_comment|/*&n; * Wait for a process to unschedule. This is used by the exit() and&n; * ptrace() code.&n; */
DECL|function|wait_task_inactive
r_void
id|wait_task_inactive
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|repeat
suffix:colon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|task_rq
c_func
(paren
id|p
)paren
suffix:semicolon
r_while
c_loop
(paren
id|unlikely
c_func
(paren
id|rq-&gt;curr
op_eq
id|p
)paren
)paren
(brace
id|cpu_relax
c_func
(paren
)paren
suffix:semicolon
id|barrier
c_func
(paren
)paren
suffix:semicolon
)brace
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|rq-&gt;curr
op_eq
id|p
)paren
)paren
(brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_goto
id|repeat
suffix:semicolon
)brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Kick the remote CPU if the task is running currently,&n; * this code is used by the signal code to signal tasks&n; * which are in user-mode as quickly as possible.&n; *&n; * (Note that we do this lockless - if the task does anything&n; * while the message is in flight then it will notice the&n; * sigpending condition anyway.)&n; */
DECL|function|kick_if_running
r_void
id|kick_if_running
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_if
c_cond
(paren
id|p
op_eq
id|task_rq
c_func
(paren
id|p
)paren
op_member_access_from_pointer
id|curr
)paren
id|resched_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/*&n; * Wake up a process. Put it on the run-queue if it&squot;s not&n; * already there.  The &quot;current&quot; process is always on the&n; * run-queue (except when the actual re-schedule is in&n; * progress), and as such you&squot;re allowed to do the simpler&n; * &quot;current-&gt;state = TASK_RUNNING&quot; to mark yourself runnable&n; * without the overhead of this.&n; */
DECL|function|try_to_wake_up
r_static
r_int
id|try_to_wake_up
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_int
id|success
op_assign
l_int|0
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
id|p-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p-&gt;array
)paren
(brace
id|activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;prio
OL
id|rq-&gt;curr-&gt;prio
)paren
id|resched_task
c_func
(paren
id|rq-&gt;curr
)paren
suffix:semicolon
id|success
op_assign
l_int|1
suffix:semicolon
)brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
r_return
id|success
suffix:semicolon
)brace
DECL|function|wake_up_process
r_int
id|wake_up_process
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|try_to_wake_up
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
DECL|function|wake_up_forked_process
r_void
id|wake_up_forked_process
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|p-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rt_task
c_func
(paren
id|p
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * We decrease the sleep average of forking parents&n;&t;&t; * and children as well, to keep max-interactive tasks&n;&t;&t; * from forking tasks that are max-interactive.&n;&t;&t; */
id|current-&gt;sleep_avg
op_assign
id|current-&gt;sleep_avg
op_star
id|PARENT_PENALTY
op_div
l_int|100
suffix:semicolon
id|p-&gt;sleep_avg
op_assign
id|p-&gt;sleep_avg
op_star
id|CHILD_PENALTY
op_div
l_int|100
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
id|p-&gt;thread_info-&gt;cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Potentially available exiting-child timeslices are&n; * retrieved here - this way the parent does not get&n; * penalized for creating too many processes.&n; *&n; * (this cannot be used to &squot;generate&squot; timeslices&n; * artificially, because any timeslice recovered here&n; * was given away by the parent in the first place.)&n; */
DECL|function|sched_exit
r_void
id|sched_exit
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
id|__cli
c_func
(paren
)paren
suffix:semicolon
id|current-&gt;time_slice
op_add_assign
id|p-&gt;time_slice
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|current-&gt;time_slice
OG
id|MAX_TIMESLICE
)paren
)paren
id|current-&gt;time_slice
op_assign
id|MAX_TIMESLICE
suffix:semicolon
id|__sti
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * If the child was a (relative-) CPU hog then decrease&n;&t; * the sleep_avg of the parent as well.&n;&t; */
r_if
c_cond
(paren
id|p-&gt;sleep_avg
OL
id|current-&gt;sleep_avg
)paren
id|current-&gt;sleep_avg
op_assign
(paren
id|current-&gt;sleep_avg
op_star
id|EXIT_WEIGHT
op_plus
id|p-&gt;sleep_avg
)paren
op_div
(paren
id|EXIT_WEIGHT
op_plus
l_int|1
)paren
suffix:semicolon
)brace
macro_line|#if CONFIG_SMP || CONFIG_PREEMPT
DECL|function|schedule_tail
id|asmlinkage
r_void
id|schedule_tail
c_func
(paren
r_void
)paren
(brace
id|spin_unlock_irq
c_func
(paren
op_amp
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|frozen
)paren
suffix:semicolon
)brace
macro_line|#endif
DECL|function|context_switch
r_static
r_inline
r_void
id|context_switch
c_func
(paren
id|task_t
op_star
id|prev
comma
id|task_t
op_star
id|next
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|next-&gt;mm
suffix:semicolon
r_struct
id|mm_struct
op_star
id|oldmm
op_assign
id|prev-&gt;active_mm
suffix:semicolon
id|prepare_to_switch
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|mm
)paren
)paren
(brace
id|next-&gt;active_mm
op_assign
id|oldmm
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|oldmm-&gt;mm_count
)paren
suffix:semicolon
id|enter_lazy_tlb
c_func
(paren
id|oldmm
comma
id|next
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
r_else
id|switch_mm
c_func
(paren
id|oldmm
comma
id|mm
comma
id|next
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|prev-&gt;mm
)paren
)paren
(brace
id|prev-&gt;active_mm
op_assign
l_int|NULL
suffix:semicolon
id|mmdrop
c_func
(paren
id|oldmm
)paren
suffix:semicolon
)brace
multiline_comment|/* Here we just switch the register state and the stack. */
id|switch_to
c_func
(paren
id|prev
comma
id|next
)paren
suffix:semicolon
)brace
DECL|function|nr_running
r_int
r_int
id|nr_running
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|smp_num_cpus
suffix:semicolon
id|i
op_increment
)paren
id|sum
op_add_assign
id|cpu_rq
c_func
(paren
id|cpu_logical_map
c_func
(paren
id|i
)paren
)paren
op_member_access_from_pointer
id|nr_running
suffix:semicolon
r_return
id|sum
suffix:semicolon
)brace
DECL|function|nr_context_switches
r_int
r_int
id|nr_context_switches
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|smp_num_cpus
suffix:semicolon
id|i
op_increment
)paren
id|sum
op_add_assign
id|cpu_rq
c_func
(paren
id|cpu_logical_map
c_func
(paren
id|i
)paren
)paren
op_member_access_from_pointer
id|nr_switches
suffix:semicolon
r_return
id|sum
suffix:semicolon
)brace
macro_line|#if CONFIG_SMP
multiline_comment|/*&n; * Lock the busiest runqueue as well, this_rq is locked already.&n; * Recalculate nr_running if we have to drop the runqueue lock.&n; */
DECL|function|double_lock_balance
r_static
r_inline
r_int
r_int
id|double_lock_balance
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
id|runqueue_t
op_star
id|busiest
comma
r_int
id|this_cpu
comma
r_int
id|idle
comma
r_int
r_int
id|nr_running
)paren
(brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|spin_trylock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
)paren
)paren
(brace
r_if
c_cond
(paren
id|busiest
OL
id|this_rq
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
multiline_comment|/* Need to recalculate nr_running */
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|this_rq-&gt;nr_running
OG
id|this_rq-&gt;prev_nr_running
(braket
id|this_cpu
)braket
)paren
)paren
id|nr_running
op_assign
id|this_rq-&gt;nr_running
suffix:semicolon
r_else
id|nr_running
op_assign
id|this_rq-&gt;prev_nr_running
(braket
id|this_cpu
)braket
suffix:semicolon
)brace
r_else
id|spin_lock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
)brace
r_return
id|nr_running
suffix:semicolon
)brace
multiline_comment|/*&n; * Current runqueue is empty, or rebalance tick: if there is an&n; * inbalance (current runqueue is too short) then pull from&n; * busiest runqueue(s).&n; *&n; * We call this with the current runqueue locked,&n; * irqs disabled.&n; */
DECL|function|load_balance
r_static
r_void
id|load_balance
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|idle
)paren
(brace
r_int
id|imbalance
comma
id|nr_running
comma
id|load
comma
id|max_load
comma
id|idx
comma
id|i
comma
id|this_cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|task_t
op_star
id|next
op_assign
id|this_rq-&gt;idle
comma
op_star
id|tmp
suffix:semicolon
id|runqueue_t
op_star
id|busiest
comma
op_star
id|rq_src
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|list_t
op_star
id|head
comma
op_star
id|curr
suffix:semicolon
multiline_comment|/*&n;&t; * We search all runqueues to find the most busy one.&n;&t; * We do this lockless to reduce cache-bouncing overhead,&n;&t; * we re-check the &squot;best&squot; source CPU later on again, with&n;&t; * the lock held.&n;&t; *&n;&t; * We fend off statistical fluctuations in runqueue lengths by&n;&t; * saving the runqueue length during the previous load-balancing&n;&t; * operation and using the smaller one the current and saved lengths.&n;&t; * If a runqueue is long enough for a longer amount of time then&n;&t; * we recognize it and pull tasks from it.&n;&t; *&n;&t; * The &squot;current runqueue length&squot; is a statistical maximum variable,&n;&t; * for that one we take the longer one - to avoid fluctuations in&n;&t; * the other direction. So for a load-balance to happen it needs&n;&t; * stable long runqueue on the target CPU and stable short runqueue&n;&t; * on the local runqueue.&n;&t; *&n;&t; * We make an exception if this CPU is about to become idle - in&n;&t; * that case we are less picky about moving a task across CPUs and&n;&t; * take what can be taken.&n;&t; */
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|this_rq-&gt;nr_running
OG
id|this_rq-&gt;prev_nr_running
(braket
id|this_cpu
)braket
)paren
)paren
id|nr_running
op_assign
id|this_rq-&gt;nr_running
suffix:semicolon
r_else
id|nr_running
op_assign
id|this_rq-&gt;prev_nr_running
(braket
id|this_cpu
)braket
suffix:semicolon
id|busiest
op_assign
l_int|NULL
suffix:semicolon
id|max_load
op_assign
l_int|1
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|smp_num_cpus
suffix:semicolon
id|i
op_increment
)paren
(brace
r_int
id|logical
op_assign
id|cpu_logical_map
c_func
(paren
id|i
)paren
suffix:semicolon
id|rq_src
op_assign
id|cpu_rq
c_func
(paren
id|logical
)paren
suffix:semicolon
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|rq_src-&gt;nr_running
OL
id|this_rq-&gt;prev_nr_running
(braket
id|logical
)braket
)paren
)paren
id|load
op_assign
id|rq_src-&gt;nr_running
suffix:semicolon
r_else
id|load
op_assign
id|this_rq-&gt;prev_nr_running
(braket
id|logical
)braket
suffix:semicolon
id|this_rq-&gt;prev_nr_running
(braket
id|logical
)braket
op_assign
id|rq_src-&gt;nr_running
suffix:semicolon
r_if
c_cond
(paren
(paren
id|load
OG
id|max_load
)paren
op_logical_and
(paren
id|rq_src
op_ne
id|this_rq
)paren
)paren
(brace
id|busiest
op_assign
id|rq_src
suffix:semicolon
id|max_load
op_assign
id|load
suffix:semicolon
)brace
)brace
r_if
c_cond
(paren
id|likely
c_func
(paren
op_logical_neg
id|busiest
)paren
)paren
r_return
suffix:semicolon
id|imbalance
op_assign
(paren
id|max_load
op_minus
id|nr_running
)paren
op_div
l_int|2
suffix:semicolon
multiline_comment|/* It needs an at least ~25% imbalance to trigger balancing. */
r_if
c_cond
(paren
op_logical_neg
id|idle
op_logical_and
(paren
id|imbalance
OL
(paren
id|max_load
op_plus
l_int|3
)paren
op_div
l_int|4
)paren
)paren
r_return
suffix:semicolon
id|nr_running
op_assign
id|double_lock_balance
c_func
(paren
id|this_rq
comma
id|busiest
comma
id|this_cpu
comma
id|idle
comma
id|nr_running
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Make sure nothing changed since we checked the&n;&t; * runqueue length.&n;&t; */
r_if
c_cond
(paren
id|busiest-&gt;nr_running
op_le
id|nr_running
op_plus
l_int|1
)paren
r_goto
id|out_unlock
suffix:semicolon
multiline_comment|/*&n;&t; * We first consider expired tasks. Those will likely not be&n;&t; * executed in the near future, and they are most likely to&n;&t; * be cache-cold, thus switching CPUs has the least effect&n;&t; * on them.&n;&t; */
r_if
c_cond
(paren
id|busiest-&gt;expired-&gt;nr_active
)paren
id|array
op_assign
id|busiest-&gt;expired
suffix:semicolon
r_else
id|array
op_assign
id|busiest-&gt;active
suffix:semicolon
id|new_array
suffix:colon
multiline_comment|/* Start searching at priority 0: */
id|idx
op_assign
l_int|0
suffix:semicolon
id|skip_bitmap
suffix:colon
r_if
c_cond
(paren
op_logical_neg
id|idx
)paren
id|idx
op_assign
id|sched_find_first_bit
c_func
(paren
id|array-&gt;bitmap
)paren
suffix:semicolon
r_else
id|idx
op_assign
id|find_next_bit
c_func
(paren
id|array-&gt;bitmap
comma
id|MAX_PRIO
comma
id|idx
)paren
suffix:semicolon
r_if
c_cond
(paren
id|idx
op_eq
id|MAX_PRIO
)paren
(brace
r_if
c_cond
(paren
id|array
op_eq
id|busiest-&gt;expired
)paren
(brace
id|array
op_assign
id|busiest-&gt;active
suffix:semicolon
r_goto
id|new_array
suffix:semicolon
)brace
r_goto
id|out_unlock
suffix:semicolon
)brace
id|head
op_assign
id|array-&gt;queue
op_plus
id|idx
suffix:semicolon
id|curr
op_assign
id|head-&gt;prev
suffix:semicolon
id|skip_queue
suffix:colon
id|tmp
op_assign
id|list_entry
c_func
(paren
id|curr
comma
id|task_t
comma
id|run_list
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We do not migrate tasks that are:&n;&t; * 1) running (obviously), or&n;&t; * 2) cannot be migrated to this CPU due to cpus_allowed, or&n;&t; * 3) are cache-hot on their current CPU.&n;&t; */
DECL|macro|CAN_MIGRATE_TASK
mdefine_line|#define CAN_MIGRATE_TASK(p,rq,this_cpu)&t;&t;&t;&t;&t;&bslash;&n;&t;((jiffies - (p)-&gt;sleep_timestamp &gt; cache_decay_ticks) &amp;&amp;&t;&bslash;&n;&t;&t;((p) != (rq)-&gt;curr) &amp;&amp;&t;&t;&t;&t;&t;&bslash;&n;&t;&t;&t;((p)-&gt;cpus_allowed &amp; (1 &lt;&lt; (this_cpu))))
r_if
c_cond
(paren
op_logical_neg
id|CAN_MIGRATE_TASK
c_func
(paren
id|tmp
comma
id|busiest
comma
id|this_cpu
)paren
)paren
(brace
id|curr
op_assign
id|curr-&gt;next
suffix:semicolon
r_if
c_cond
(paren
id|curr
op_ne
id|head
)paren
r_goto
id|skip_queue
suffix:semicolon
id|idx
op_increment
suffix:semicolon
r_goto
id|skip_bitmap
suffix:semicolon
)brace
id|next
op_assign
id|tmp
suffix:semicolon
multiline_comment|/*&n;&t; * take the task out of the other runqueue and&n;&t; * put it into this one:&n;&t; */
id|dequeue_task
c_func
(paren
id|next
comma
id|array
)paren
suffix:semicolon
id|busiest-&gt;nr_running
op_decrement
suffix:semicolon
id|next-&gt;thread_info-&gt;cpu
op_assign
id|this_cpu
suffix:semicolon
id|this_rq-&gt;nr_running
op_increment
suffix:semicolon
id|enqueue_task
c_func
(paren
id|next
comma
id|this_rq-&gt;active
)paren
suffix:semicolon
r_if
c_cond
(paren
id|next-&gt;prio
OL
id|current-&gt;prio
)paren
id|set_need_resched
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|idle
op_logical_and
op_decrement
id|imbalance
)paren
(brace
r_if
c_cond
(paren
id|array
op_eq
id|busiest-&gt;expired
)paren
(brace
id|array
op_assign
id|busiest-&gt;active
suffix:semicolon
r_goto
id|new_array
suffix:semicolon
)brace
)brace
id|out_unlock
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * One of the idle_cpu_tick() or the busy_cpu_tick() function will&n; * gets called every timer tick, on every CPU. Our balancing action&n; * frequency and balancing agressivity depends on whether the CPU is&n; * idle or not.&n; *&n; * busy-rebalance every 250 msecs. idle-rebalance every 1 msec. (or on&n; * systems with HZ=100, every 10 msecs.)&n; */
DECL|macro|BUSY_REBALANCE_TICK
mdefine_line|#define BUSY_REBALANCE_TICK (HZ/4 ?: 1)
DECL|macro|IDLE_REBALANCE_TICK
mdefine_line|#define IDLE_REBALANCE_TICK (HZ/1000 ?: 1)
DECL|function|idle_tick
r_static
r_inline
r_void
id|idle_tick
c_func
(paren
r_void
)paren
(brace
r_if
c_cond
(paren
id|jiffies
op_mod
id|IDLE_REBALANCE_TICK
)paren
r_return
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|lock
)paren
suffix:semicolon
id|load_balance
c_func
(paren
id|this_rq
c_func
(paren
)paren
comma
l_int|1
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|lock
)paren
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/*&n; * We place interactive tasks back into the active array, if possible.&n; *&n; * To guarantee that this does not starve expired tasks we ignore the&n; * interactivity of a task if the first expired task had to wait more&n; * than a &squot;reasonable&squot; amount of time. This deadline timeout is&n; * load-dependent, as the frequency of array switched decreases with&n; * increasing number of running tasks:&n; */
DECL|macro|EXPIRED_STARVING
mdefine_line|#define EXPIRED_STARVING(rq) &bslash;&n;&t;&t;((rq)-&gt;expired_timestamp &amp;&amp; &bslash;&n;&t;&t;(jiffies - (rq)-&gt;expired_timestamp &gt;= &bslash;&n;&t;&t;&t;STARVATION_LIMIT * ((rq)-&gt;nr_running) + 1))
multiline_comment|/*&n; * This function gets called by the timer code, with HZ frequency.&n; * We call it with interrupts disabled.&n; */
DECL|function|scheduler_tick
r_void
id|scheduler_tick
c_func
(paren
r_int
id|user_tick
comma
r_int
id|system
)paren
(brace
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|runqueue_t
op_star
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|task_t
op_star
id|p
op_assign
id|current
suffix:semicolon
r_if
c_cond
(paren
id|p
op_eq
id|rq-&gt;idle
)paren
(brace
r_if
c_cond
(paren
id|local_bh_count
c_func
(paren
id|cpu
)paren
op_logical_or
id|local_irq_count
c_func
(paren
id|cpu
)paren
OG
l_int|1
)paren
id|kstat.per_cpu_system
(braket
id|cpu
)braket
op_add_assign
id|system
suffix:semicolon
macro_line|#if CONFIG_SMP
id|idle_tick
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
r_return
suffix:semicolon
)brace
r_if
c_cond
(paren
id|TASK_NICE
c_func
(paren
id|p
)paren
OG
l_int|0
)paren
id|kstat.per_cpu_nice
(braket
id|cpu
)braket
op_add_assign
id|user_tick
suffix:semicolon
r_else
id|kstat.per_cpu_user
(braket
id|cpu
)braket
op_add_assign
id|user_tick
suffix:semicolon
id|kstat.per_cpu_system
(braket
id|cpu
)braket
op_add_assign
id|system
suffix:semicolon
multiline_comment|/* Task might have expired already, but not scheduled off yet */
r_if
c_cond
(paren
id|p-&gt;array
op_ne
id|rq-&gt;active
)paren
(brace
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|spin_lock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|rt_task
c_func
(paren
id|p
)paren
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * RR tasks need a special form of timeslice management.&n;&t;&t; * FIFO tasks have no timeslices.&n;&t;&t; */
r_if
c_cond
(paren
(paren
id|p-&gt;policy
op_eq
id|SCHED_RR
)paren
op_logical_and
op_logical_neg
op_decrement
id|p-&gt;time_slice
)paren
(brace
id|p-&gt;time_slice
op_assign
id|TASK_TIMESLICE
c_func
(paren
id|p
)paren
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
multiline_comment|/* put it at the end of the queue: */
id|dequeue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
)brace
r_goto
id|out
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * The task was running during this tick - update the&n;&t; * time slice counter and the sleep average. Note: we&n;&t; * do not update a process&squot;s priority until it either&n;&t; * goes to sleep or uses up its timeslice. This makes&n;&t; * it possible for interactive tasks to use up their&n;&t; * timeslices at their highest priority levels.&n;&t; */
r_if
c_cond
(paren
id|p-&gt;sleep_avg
)paren
id|p-&gt;sleep_avg
op_decrement
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
op_decrement
id|p-&gt;time_slice
)paren
(brace
id|dequeue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;time_slice
op_assign
id|TASK_TIMESLICE
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|TASK_INTERACTIVE
c_func
(paren
id|p
)paren
op_logical_or
id|EXPIRED_STARVING
c_func
(paren
id|rq
)paren
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;expired_timestamp
)paren
id|rq-&gt;expired_timestamp
op_assign
id|jiffies
suffix:semicolon
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;expired
)paren
suffix:semicolon
)brace
r_else
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
)brace
id|out
suffix:colon
macro_line|#if CONFIG_SMP
r_if
c_cond
(paren
op_logical_neg
(paren
id|jiffies
op_mod
id|BUSY_REBALANCE_TICK
)paren
)paren
id|load_balance
c_func
(paren
id|rq
comma
l_int|0
)paren
suffix:semicolon
macro_line|#endif
id|spin_unlock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
)brace
DECL|function|scheduling_functions_start_here
r_void
id|scheduling_functions_start_here
c_func
(paren
r_void
)paren
(brace
)brace
multiline_comment|/*&n; * &squot;schedule()&squot; is the main scheduler function.&n; */
DECL|function|schedule
id|asmlinkage
r_void
id|schedule
c_func
(paren
r_void
)paren
(brace
id|task_t
op_star
id|prev
comma
op_star
id|next
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|list_t
op_star
id|queue
suffix:semicolon
r_int
id|idx
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|in_interrupt
c_func
(paren
)paren
)paren
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
macro_line|#if CONFIG_DEBUG_HIGHMEM
id|check_highmem_ptes
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
id|need_resched
suffix:colon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|prev
op_assign
id|current
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|release_kernel_lock
c_func
(paren
id|prev
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|prev-&gt;sleep_timestamp
op_assign
id|jiffies
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * if entering from preempt_schedule, off a kernel preemption,&n;&t; * go straight to picking the next task.&n;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|preempt_get_count
c_func
(paren
)paren
op_amp
id|PREEMPT_ACTIVE
)paren
)paren
r_goto
id|pick_next_task
suffix:semicolon
r_switch
c_cond
(paren
id|prev-&gt;state
)paren
(brace
r_case
id|TASK_INTERRUPTIBLE
suffix:colon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|signal_pending
c_func
(paren
id|prev
)paren
)paren
)paren
(brace
id|prev-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
r_break
suffix:semicolon
)brace
r_default
suffix:colon
id|deactivate_task
c_func
(paren
id|prev
comma
id|rq
)paren
suffix:semicolon
r_case
id|TASK_RUNNING
suffix:colon
suffix:semicolon
)brace
id|pick_next_task
suffix:colon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|rq-&gt;nr_running
)paren
)paren
(brace
macro_line|#if CONFIG_SMP
id|load_balance
c_func
(paren
id|rq
comma
l_int|1
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;nr_running
)paren
r_goto
id|pick_next_task
suffix:semicolon
macro_line|#endif
id|next
op_assign
id|rq-&gt;idle
suffix:semicolon
id|rq-&gt;expired_timestamp
op_assign
l_int|0
suffix:semicolon
r_goto
id|switch_tasks
suffix:semicolon
)brace
id|array
op_assign
id|rq-&gt;active
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|array-&gt;nr_active
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * Switch the active and expired arrays.&n;&t;&t; */
id|rq-&gt;active
op_assign
id|rq-&gt;expired
suffix:semicolon
id|rq-&gt;expired
op_assign
id|array
suffix:semicolon
id|array
op_assign
id|rq-&gt;active
suffix:semicolon
id|rq-&gt;expired_timestamp
op_assign
l_int|0
suffix:semicolon
)brace
id|idx
op_assign
id|sched_find_first_bit
c_func
(paren
id|array-&gt;bitmap
)paren
suffix:semicolon
id|queue
op_assign
id|array-&gt;queue
op_plus
id|idx
suffix:semicolon
id|next
op_assign
id|list_entry
c_func
(paren
id|queue-&gt;next
comma
id|task_t
comma
id|run_list
)paren
suffix:semicolon
id|switch_tasks
suffix:colon
id|prefetch
c_func
(paren
id|next
)paren
suffix:semicolon
id|clear_tsk_need_resched
c_func
(paren
id|prev
)paren
suffix:semicolon
r_if
c_cond
(paren
id|likely
c_func
(paren
id|prev
op_ne
id|next
)paren
)paren
(brace
id|rq-&gt;nr_switches
op_increment
suffix:semicolon
id|rq-&gt;curr
op_assign
id|next
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq-&gt;frozen
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|context_switch
c_func
(paren
id|prev
comma
id|next
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * The runqueue pointer might be from another CPU&n;&t;&t; * if the new task was last running on a different&n;&t;&t; * CPU - thus re-load it.&n;&t;&t; */
id|mb
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|rq-&gt;frozen
)paren
suffix:semicolon
)brace
r_else
(brace
id|spin_unlock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
)brace
id|reacquire_kernel_lock
c_func
(paren
id|current
)paren
suffix:semicolon
id|preempt_enable_no_resched
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|test_thread_flag
c_func
(paren
id|TIF_NEED_RESCHED
)paren
)paren
r_goto
id|need_resched
suffix:semicolon
r_return
suffix:semicolon
)brace
macro_line|#ifdef CONFIG_PREEMPT
multiline_comment|/*&n; * this is is the entry point to schedule() from in-kernel preemption.&n; */
DECL|function|preempt_schedule
id|asmlinkage
r_void
id|preempt_schedule
c_func
(paren
r_void
)paren
(brace
r_struct
id|thread_info
op_star
id|ti
op_assign
id|current_thread_info
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|ti-&gt;preempt_count
)paren
)paren
r_return
suffix:semicolon
id|ti-&gt;preempt_count
op_assign
id|PREEMPT_ACTIVE
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|ti-&gt;preempt_count
op_assign
l_int|0
suffix:semicolon
id|barrier
c_func
(paren
)paren
suffix:semicolon
)brace
macro_line|#endif /* CONFIG_PREEMPT */
multiline_comment|/*&n; * The core wakeup function.  Non-exclusive wakeups (nr_exclusive == 0) just&n; * wake everything up.  If it&squot;s an exclusive wakeup (nr_exclusive == small +ve&n; * number) then we wake all the non-exclusive tasks and one exclusive task.&n; *&n; * There are circumstances in which we can try to wake a task which has already&n; * started to run but is not in state TASK_RUNNING.  try_to_wake_up() returns&n; * zero in this (rare) case, and we handle it by continuing to scan the queue.&n; */
DECL|function|__wake_up_common
r_static
r_inline
r_void
id|__wake_up_common
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
comma
r_int
id|nr_exclusive
)paren
(brace
r_struct
id|list_head
op_star
id|tmp
suffix:semicolon
r_int
r_int
id|state
suffix:semicolon
id|wait_queue_t
op_star
id|curr
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
id|list_for_each
c_func
(paren
id|tmp
comma
op_amp
id|q-&gt;task_list
)paren
(brace
id|curr
op_assign
id|list_entry
c_func
(paren
id|tmp
comma
id|wait_queue_t
comma
id|task_list
)paren
suffix:semicolon
id|p
op_assign
id|curr-&gt;task
suffix:semicolon
id|state
op_assign
id|p-&gt;state
suffix:semicolon
r_if
c_cond
(paren
(paren
id|state
op_amp
id|mode
)paren
op_logical_and
id|try_to_wake_up
c_func
(paren
id|p
)paren
op_logical_and
(paren
(paren
id|curr-&gt;flags
op_amp
id|WQ_FLAG_EXCLUSIVE
)paren
op_logical_and
op_logical_neg
op_decrement
id|nr_exclusive
)paren
)paren
r_break
suffix:semicolon
)brace
)brace
DECL|function|__wake_up
r_void
id|__wake_up
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
comma
r_int
id|nr_exclusive
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|q
)paren
)paren
r_return
suffix:semicolon
id|wq_read_lock_irqsave
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|__wake_up_common
c_func
(paren
id|q
comma
id|mode
comma
id|nr_exclusive
)paren
suffix:semicolon
id|wq_read_unlock_irqrestore
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|function|complete
r_void
id|complete
c_func
(paren
r_struct
id|completion
op_star
id|x
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
id|x-&gt;done
op_increment
suffix:semicolon
id|__wake_up_common
c_func
(paren
op_amp
id|x-&gt;wait
comma
id|TASK_UNINTERRUPTIBLE
op_or
id|TASK_INTERRUPTIBLE
comma
l_int|1
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|function|wait_for_completion
r_void
id|wait_for_completion
c_func
(paren
r_struct
id|completion
op_star
id|x
)paren
(brace
id|spin_lock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|x-&gt;done
)paren
(brace
id|DECLARE_WAITQUEUE
c_func
(paren
id|wait
comma
id|current
)paren
suffix:semicolon
id|wait.flags
op_or_assign
id|WQ_FLAG_EXCLUSIVE
suffix:semicolon
id|__add_wait_queue_tail
c_func
(paren
op_amp
id|x-&gt;wait
comma
op_amp
id|wait
)paren
suffix:semicolon
r_do
(brace
id|__set_current_state
c_func
(paren
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
op_logical_neg
id|x-&gt;done
)paren
suffix:semicolon
id|__remove_wait_queue
c_func
(paren
op_amp
id|x-&gt;wait
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
id|x-&gt;done
op_decrement
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
)brace
DECL|macro|SLEEP_ON_VAR
mdefine_line|#define&t;SLEEP_ON_VAR&t;&t;&t;&t;&bslash;&n;&t;unsigned long flags;&t;&t;&t;&bslash;&n;&t;wait_queue_t wait;&t;&t;&t;&bslash;&n;&t;init_waitqueue_entry(&amp;wait, current);
DECL|macro|SLEEP_ON_HEAD
mdefine_line|#define&t;SLEEP_ON_HEAD&t;&t;&t;&t;&t;&bslash;&n;&t;wq_write_lock_irqsave(&amp;q-&gt;lock,flags);&t;&t;&bslash;&n;&t;__add_wait_queue(q, &amp;wait);&t;&t;&t;&bslash;&n;&t;wq_write_unlock(&amp;q-&gt;lock);
DECL|macro|SLEEP_ON_TAIL
mdefine_line|#define&t;SLEEP_ON_TAIL&t;&t;&t;&t;&t;&t;&bslash;&n;&t;wq_write_lock_irq(&amp;q-&gt;lock);&t;&t;&t;&t;&bslash;&n;&t;__remove_wait_queue(q, &amp;wait);&t;&t;&t;&t;&bslash;&n;&t;wq_write_unlock_irqrestore(&amp;q-&gt;lock,flags);
DECL|function|interruptible_sleep_on
r_void
id|interruptible_sleep_on
c_func
(paren
id|wait_queue_head_t
op_star
id|q
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
)brace
DECL|function|interruptible_sleep_on_timeout
r_int
id|interruptible_sleep_on_timeout
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
id|timeout
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|timeout
op_assign
id|schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
r_return
id|timeout
suffix:semicolon
)brace
DECL|function|sleep_on
r_void
id|sleep_on
c_func
(paren
id|wait_queue_head_t
op_star
id|q
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_UNINTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
)brace
DECL|function|sleep_on_timeout
r_int
id|sleep_on_timeout
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
id|timeout
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_UNINTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|timeout
op_assign
id|schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
r_return
id|timeout
suffix:semicolon
)brace
DECL|function|scheduling_functions_end_here
r_void
id|scheduling_functions_end_here
c_func
(paren
r_void
)paren
(brace
)brace
DECL|function|set_user_nice
r_void
id|set_user_nice
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
id|nice
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_if
c_cond
(paren
id|TASK_NICE
c_func
(paren
id|p
)paren
op_eq
id|nice
op_logical_or
id|nice
template_param
l_int|19
)paren
r_return
suffix:semicolon
multiline_comment|/*&n;&t; * We have to be careful, if called from sys_setpriority(),&n;&t; * the task might be in the middle of scheduling on another CPU.&n;&t; */
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rt_task
c_func
(paren
id|p
)paren
)paren
(brace
id|p-&gt;static_prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
r_goto
id|out_unlock
suffix:semicolon
)brace
id|array
op_assign
id|p-&gt;array
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|dequeue_task
c_func
(paren
id|p
comma
id|array
)paren
suffix:semicolon
id|p-&gt;static_prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
id|p-&gt;prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
(brace
id|enqueue_task
c_func
(paren
id|p
comma
id|array
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * If the task is running and lowered its priority,&n;&t;&t; * or increased its priority then reschedule its CPU:&n;&t;&t; */
r_if
c_cond
(paren
(paren
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
OL
id|p-&gt;static_prio
)paren
op_logical_or
(paren
id|p
op_eq
id|rq-&gt;curr
)paren
)paren
id|resched_task
c_func
(paren
id|rq-&gt;curr
)paren
suffix:semicolon
)brace
id|out_unlock
suffix:colon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
)brace
macro_line|#ifndef __alpha__
multiline_comment|/*&n; * This has been replaced by sys_setpriority.  Maybe it should be&n; * moved into the arch dependent tree for those ports that require&n; * it for backward compatibility?&n; */
DECL|function|sys_nice
id|asmlinkage
r_int
id|sys_nice
c_func
(paren
r_int
id|increment
)paren
(brace
r_int
id|nice
suffix:semicolon
multiline_comment|/*&n;&t; *&t;Setpriority might change our priority at the same moment.&n;&t; *&t;We don&squot;t have to worry. Conceptually one call occurs first&n;&t; *&t;and we have a single winner.&n;&t; */
r_if
c_cond
(paren
id|increment
OL
l_int|0
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_return
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
id|increment
OL
op_minus
l_int|40
)paren
id|increment
op_assign
op_minus
l_int|40
suffix:semicolon
)brace
r_if
c_cond
(paren
id|increment
OG
l_int|40
)paren
id|increment
op_assign
l_int|40
suffix:semicolon
id|nice
op_assign
id|PRIO_TO_NICE
c_func
(paren
id|current-&gt;static_prio
)paren
op_plus
id|increment
suffix:semicolon
r_if
c_cond
(paren
id|nice
OL
op_minus
l_int|20
)paren
id|nice
op_assign
op_minus
l_int|20
suffix:semicolon
r_if
c_cond
(paren
id|nice
OG
l_int|19
)paren
id|nice
op_assign
l_int|19
suffix:semicolon
id|set_user_nice
c_func
(paren
id|current
comma
id|nice
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/*&n; * This is the priority value as seen by users in /proc&n; *&n; * RT tasks are offset by -200. Normal tasks are centered&n; * around 0, value goes from -16 to +15.&n; */
DECL|function|task_prio
r_int
id|task_prio
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|p-&gt;prio
op_minus
l_int|100
suffix:semicolon
)brace
DECL|function|task_nice
r_int
id|task_nice
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|TASK_NICE
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
DECL|function|idle_cpu
r_int
id|idle_cpu
c_func
(paren
r_int
id|cpu
)paren
(brace
r_return
id|cpu_curr
c_func
(paren
id|cpu
)paren
op_eq
id|cpu_rq
c_func
(paren
id|cpu
)paren
op_member_access_from_pointer
id|idle
suffix:semicolon
)brace
DECL|function|find_process_by_pid
r_static
r_inline
id|task_t
op_star
id|find_process_by_pid
c_func
(paren
id|pid_t
id|pid
)paren
(brace
r_return
id|pid
ques
c_cond
id|find_task_by_pid
c_func
(paren
id|pid
)paren
suffix:colon
id|current
suffix:semicolon
)brace
DECL|function|setscheduler
r_static
r_int
id|setscheduler
c_func
(paren
id|pid_t
id|pid
comma
r_int
id|policy
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_struct
id|sched_param
id|lp
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|param
op_logical_or
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|EFAULT
suffix:semicolon
r_if
c_cond
(paren
id|copy_from_user
c_func
(paren
op_amp
id|lp
comma
id|param
comma
r_sizeof
(paren
r_struct
id|sched_param
)paren
)paren
)paren
r_goto
id|out_nounlock
suffix:semicolon
multiline_comment|/*&n;&t; * We play safe to avoid deadlocks.&n;&t; */
id|read_lock_irq
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock_tasklist
suffix:semicolon
multiline_comment|/*&n;&t; * To be able to change p-&gt;policy safely, the apropriate&n;&t; * runqueue lock must be held.&n;&t; */
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|policy
OL
l_int|0
)paren
id|policy
op_assign
id|p-&gt;policy
suffix:semicolon
r_else
(brace
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|policy
op_ne
id|SCHED_FIFO
op_logical_and
id|policy
op_ne
id|SCHED_RR
op_logical_and
id|policy
op_ne
id|SCHED_OTHER
)paren
r_goto
id|out_unlock
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Valid priorities for SCHED_FIFO and SCHED_RR are 1..99, valid&n;&t; * priority for SCHED_OTHER is 0.&n;&t; */
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|lp.sched_priority
template_param
l_int|99
)paren
r_goto
id|out_unlock
suffix:semicolon
r_if
c_cond
(paren
(paren
id|policy
op_eq
id|SCHED_OTHER
)paren
op_ne
(paren
id|lp.sched_priority
op_eq
l_int|0
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
(paren
id|policy
op_eq
id|SCHED_FIFO
op_logical_or
id|policy
op_eq
id|SCHED_RR
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
r_if
c_cond
(paren
(paren
id|current-&gt;euid
op_ne
id|p-&gt;euid
)paren
op_logical_and
(paren
id|current-&gt;euid
op_ne
id|p-&gt;uid
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|array
op_assign
id|p-&gt;array
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|deactivate_task
c_func
(paren
id|p
comma
id|task_rq
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|p-&gt;policy
op_assign
id|policy
suffix:semicolon
id|p-&gt;rt_priority
op_assign
id|lp.sched_priority
suffix:semicolon
r_if
c_cond
(paren
id|policy
op_ne
id|SCHED_OTHER
)paren
id|p-&gt;prio
op_assign
l_int|99
op_minus
id|p-&gt;rt_priority
suffix:semicolon
r_else
id|p-&gt;prio
op_assign
id|p-&gt;static_prio
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|activate_task
c_func
(paren
id|p
comma
id|task_rq
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
id|out_unlock
suffix:colon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|out_unlock_tasklist
suffix:colon
id|read_unlock_irq
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
)brace
DECL|function|sys_sched_setscheduler
id|asmlinkage
r_int
id|sys_sched_setscheduler
c_func
(paren
id|pid_t
id|pid
comma
r_int
id|policy
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_return
id|setscheduler
c_func
(paren
id|pid
comma
id|policy
comma
id|param
)paren
suffix:semicolon
)brace
DECL|function|sys_sched_setparam
id|asmlinkage
r_int
id|sys_sched_setparam
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_return
id|setscheduler
c_func
(paren
id|pid
comma
op_minus
l_int|1
comma
id|param
)paren
suffix:semicolon
)brace
DECL|function|sys_sched_getscheduler
id|asmlinkage
r_int
id|sys_sched_getscheduler
c_func
(paren
id|pid_t
id|pid
)paren
(brace
id|task_t
op_star
id|p
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p
)paren
id|retval
op_assign
id|p-&gt;policy
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
)brace
DECL|function|sys_sched_getparam
id|asmlinkage
r_int
id|sys_sched_getparam
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
id|task_t
op_star
id|p
suffix:semicolon
r_struct
id|sched_param
id|lp
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|param
op_logical_or
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock
suffix:semicolon
id|lp.sched_priority
op_assign
id|p-&gt;rt_priority
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * This one might sleep, we cannot do it with a spinlock held ...&n;&t; */
id|retval
op_assign
id|copy_to_user
c_func
(paren
id|param
comma
op_amp
id|lp
comma
r_sizeof
(paren
op_star
id|param
)paren
)paren
ques
c_cond
op_minus
id|EFAULT
suffix:colon
l_int|0
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
id|out_unlock
suffix:colon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_setaffinity - set the cpu affinity of a process&n; * @pid: pid of the process&n; * @len: length of the bitmask pointed to by user_mask_ptr&n; * @user_mask_ptr: user-space pointer to the new cpu mask&n; */
DECL|function|sys_sched_setaffinity
id|asmlinkage
r_int
id|sys_sched_setaffinity
c_func
(paren
id|pid_t
id|pid
comma
r_int
r_int
id|len
comma
r_int
r_int
op_star
id|user_mask_ptr
)paren
(brace
r_int
r_int
id|new_mask
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_int
id|retval
suffix:semicolon
r_if
c_cond
(paren
id|len
OL
r_sizeof
(paren
id|new_mask
)paren
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|copy_from_user
c_func
(paren
op_amp
id|new_mask
comma
id|user_mask_ptr
comma
r_sizeof
(paren
id|new_mask
)paren
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
id|new_mask
op_and_assign
id|cpu_online_map
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_mask
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
(brace
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_return
op_minus
id|ESRCH
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * It is not safe to call set_cpus_allowed with the&n;&t; * tasklist_lock held.  We will bump the task_struct&squot;s&n;&t; * usage count and then drop tasklist_lock.&n;&t; */
id|get_task_struct
c_func
(paren
id|p
)paren
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
(paren
id|current-&gt;euid
op_ne
id|p-&gt;euid
)paren
op_logical_and
(paren
id|current-&gt;euid
op_ne
id|p-&gt;uid
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|set_cpus_allowed
c_func
(paren
id|p
comma
id|new_mask
)paren
suffix:semicolon
id|out_unlock
suffix:colon
id|put_task_struct
c_func
(paren
id|p
)paren
suffix:semicolon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_getaffinity - get the cpu affinity of a process&n; * @pid: pid of the process&n; * @len: length of the bitmask pointed to by user_mask_ptr&n; * @user_mask_ptr: user-space pointer to hold the current cpu mask&n; */
DECL|function|sys_sched_getaffinity
id|asmlinkage
r_int
id|sys_sched_getaffinity
c_func
(paren
id|pid_t
id|pid
comma
r_int
r_int
id|len
comma
r_int
r_int
op_star
id|user_mask_ptr
)paren
(brace
r_int
r_int
id|mask
suffix:semicolon
r_int
r_int
id|real_len
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|real_len
op_assign
r_sizeof
(paren
id|mask
)paren
suffix:semicolon
r_if
c_cond
(paren
id|len
OL
id|real_len
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|mask
op_assign
id|p-&gt;cpus_allowed
op_amp
id|cpu_online_map
suffix:semicolon
id|out_unlock
suffix:colon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_return
id|retval
suffix:semicolon
r_if
c_cond
(paren
id|copy_to_user
c_func
(paren
id|user_mask_ptr
comma
op_amp
id|mask
comma
id|real_len
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
r_return
id|real_len
suffix:semicolon
)brace
DECL|function|sys_sched_yield
id|asmlinkage
r_int
id|sys_sched_yield
c_func
(paren
r_void
)paren
(brace
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Decrease the yielding task&squot;s priority by one, to avoid&n;&t; * livelocks. This priority loss is temporary, it&squot;s recovered&n;&t; * once the current timeslice expires.&n;&t; *&n;&t; * If priority is already MAX_PRIO-1 then we still&n;&t; * roundrobin the task within the runlist.&n;&t; */
id|spin_lock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|array
op_assign
id|current-&gt;array
suffix:semicolon
multiline_comment|/*&n;&t; * If the task has reached maximum priority (or is a RT task)&n;&t; * then just requeue the task to the end of the runqueue:&n;&t; */
r_if
c_cond
(paren
id|likely
c_func
(paren
id|current-&gt;prio
op_eq
id|MAX_PRIO
op_minus
l_int|1
op_logical_or
id|rt_task
c_func
(paren
id|current
)paren
)paren
)paren
(brace
id|list_del
c_func
(paren
op_amp
id|current-&gt;run_list
)paren
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|current-&gt;run_list
comma
id|array-&gt;queue
op_plus
id|current-&gt;prio
)paren
suffix:semicolon
)brace
r_else
(brace
id|list_del
c_func
(paren
op_amp
id|current-&gt;run_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|list_empty
c_func
(paren
id|array-&gt;queue
op_plus
id|current-&gt;prio
)paren
)paren
id|__clear_bit
c_func
(paren
id|current-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
id|current-&gt;prio
op_increment
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|current-&gt;run_list
comma
id|array-&gt;queue
op_plus
id|current-&gt;prio
)paren
suffix:semicolon
id|__set_bit
c_func
(paren
id|current-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
id|spin_unlock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|preempt_enable_no_resched
c_func
(paren
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|sys_sched_get_priority_max
id|asmlinkage
r_int
id|sys_sched_get_priority_max
c_func
(paren
r_int
id|policy
)paren
(brace
r_int
id|ret
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_switch
c_cond
(paren
id|policy
)paren
(brace
r_case
id|SCHED_FIFO
suffix:colon
r_case
id|SCHED_RR
suffix:colon
id|ret
op_assign
l_int|99
suffix:semicolon
r_break
suffix:semicolon
r_case
id|SCHED_OTHER
suffix:colon
id|ret
op_assign
l_int|0
suffix:semicolon
r_break
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
DECL|function|sys_sched_get_priority_min
id|asmlinkage
r_int
id|sys_sched_get_priority_min
c_func
(paren
r_int
id|policy
)paren
(brace
r_int
id|ret
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_switch
c_cond
(paren
id|policy
)paren
(brace
r_case
id|SCHED_FIFO
suffix:colon
r_case
id|SCHED_RR
suffix:colon
id|ret
op_assign
l_int|1
suffix:semicolon
r_break
suffix:semicolon
r_case
id|SCHED_OTHER
suffix:colon
id|ret
op_assign
l_int|0
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
DECL|function|sys_sched_rr_get_interval
id|asmlinkage
r_int
id|sys_sched_rr_get_interval
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|timespec
op_star
id|interval
)paren
(brace
r_struct
id|timespec
id|t
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_int
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p
)paren
id|jiffies_to_timespec
c_func
(paren
id|p-&gt;policy
op_amp
id|SCHED_FIFO
ques
c_cond
l_int|0
suffix:colon
id|TASK_TIMESLICE
c_func
(paren
id|p
)paren
comma
op_amp
id|t
)paren
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p
)paren
id|retval
op_assign
id|copy_to_user
c_func
(paren
id|interval
comma
op_amp
id|t
comma
r_sizeof
(paren
id|t
)paren
)paren
ques
c_cond
op_minus
id|EFAULT
suffix:colon
l_int|0
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
)brace
DECL|function|show_task
r_static
r_void
id|show_task
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|free
op_assign
l_int|0
suffix:semicolon
id|task_t
op_star
id|relative
suffix:semicolon
r_int
id|state
suffix:semicolon
r_static
r_const
r_char
op_star
id|stat_nam
(braket
)braket
op_assign
(brace
l_string|&quot;R&quot;
comma
l_string|&quot;S&quot;
comma
l_string|&quot;D&quot;
comma
l_string|&quot;Z&quot;
comma
l_string|&quot;T&quot;
comma
l_string|&quot;W&quot;
)brace
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%-13.13s &quot;
comma
id|p-&gt;comm
)paren
suffix:semicolon
id|state
op_assign
id|p-&gt;state
ques
c_cond
id|__ffs
c_func
(paren
id|p-&gt;state
)paren
op_plus
l_int|1
suffix:colon
l_int|0
suffix:semicolon
r_if
c_cond
(paren
(paren
(paren
r_int
)paren
id|state
)paren
OL
r_sizeof
(paren
id|stat_nam
)paren
op_div
r_sizeof
(paren
r_char
op_star
)paren
)paren
id|printk
c_func
(paren
id|stat_nam
(braket
id|state
)braket
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; &quot;
)paren
suffix:semicolon
macro_line|#if (BITS_PER_LONG == 32)
r_if
c_cond
(paren
id|p
op_eq
id|current
)paren
id|printk
c_func
(paren
l_string|&quot; current  &quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; %08lX &quot;
comma
id|thread_saved_pc
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
macro_line|#else
r_if
c_cond
(paren
id|p
op_eq
id|current
)paren
id|printk
c_func
(paren
l_string|&quot;   current task   &quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; %016lx &quot;
comma
id|thread_saved_pc
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
macro_line|#endif
(brace
r_int
r_int
op_star
id|n
op_assign
(paren
r_int
r_int
op_star
)paren
(paren
id|p
op_plus
l_int|1
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
op_star
id|n
)paren
id|n
op_increment
suffix:semicolon
id|free
op_assign
(paren
r_int
r_int
)paren
id|n
op_minus
(paren
r_int
r_int
)paren
(paren
id|p
op_plus
l_int|1
)paren
suffix:semicolon
)brace
id|printk
c_func
(paren
l_string|&quot;%5lu %5d %6d &quot;
comma
id|free
comma
id|p-&gt;pid
comma
id|p-&gt;parent-&gt;pid
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|eldest_child
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%5d &quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;      &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|younger_sibling
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%7d&quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;       &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|older_sibling
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot; %5d&quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;      &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p-&gt;mm
)paren
id|printk
c_func
(paren
l_string|&quot; (L-TLB)&bslash;n&quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; (NOTLB)&bslash;n&quot;
)paren
suffix:semicolon
(brace
r_extern
r_void
id|show_trace_task
c_func
(paren
id|task_t
op_star
id|tsk
)paren
suffix:semicolon
id|show_trace_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
)brace
DECL|function|render_sigset_t
r_char
op_star
id|render_sigset_t
c_func
(paren
id|sigset_t
op_star
id|set
comma
r_char
op_star
id|buffer
)paren
(brace
r_int
id|i
op_assign
id|_NSIG
comma
id|x
suffix:semicolon
r_do
(brace
id|i
op_sub_assign
l_int|4
comma
id|x
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|sigismember
c_func
(paren
id|set
comma
id|i
op_plus
l_int|1
)paren
)paren
id|x
op_or_assign
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|sigismember
c_func
(paren
id|set
comma
id|i
op_plus
l_int|2
)paren
)paren
id|x
op_or_assign
l_int|2
suffix:semicolon
r_if
c_cond
(paren
id|sigismember
c_func
(paren
id|set
comma
id|i
op_plus
l_int|3
)paren
)paren
id|x
op_or_assign
l_int|4
suffix:semicolon
r_if
c_cond
(paren
id|sigismember
c_func
(paren
id|set
comma
id|i
op_plus
l_int|4
)paren
)paren
id|x
op_or_assign
l_int|8
suffix:semicolon
op_star
id|buffer
op_increment
op_assign
(paren
id|x
OL
l_int|10
ques
c_cond
l_char|&squot;0&squot;
suffix:colon
l_char|&squot;a&squot;
op_minus
l_int|10
)paren
op_plus
id|x
suffix:semicolon
)brace
r_while
c_loop
(paren
id|i
op_ge
l_int|4
)paren
suffix:semicolon
op_star
id|buffer
op_assign
l_int|0
suffix:semicolon
r_return
id|buffer
suffix:semicolon
)brace
DECL|function|show_state
r_void
id|show_state
c_func
(paren
r_void
)paren
(brace
id|task_t
op_star
id|p
suffix:semicolon
macro_line|#if (BITS_PER_LONG == 32)
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
l_string|&quot;                         free                        sibling&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;  task             PC    stack   pid father child younger older&bslash;n&quot;
)paren
suffix:semicolon
macro_line|#else
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
l_string|&quot;                                 free                        sibling&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;  task                 PC        stack   pid father child younger older&bslash;n&quot;
)paren
suffix:semicolon
macro_line|#endif
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|for_each_task
c_func
(paren
id|p
)paren
(brace
multiline_comment|/*&n;&t;&t; * reset the NMI-timeout, listing all files on a slow&n;&t;&t; * console might take alot of time:&n;&t;&t; */
id|touch_nmi_watchdog
c_func
(paren
)paren
suffix:semicolon
id|show_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
)brace
DECL|function|double_rq_lock
r_static
r_inline
r_void
id|double_rq_lock
c_func
(paren
id|runqueue_t
op_star
id|rq1
comma
id|runqueue_t
op_star
id|rq2
)paren
(brace
r_if
c_cond
(paren
id|rq1
op_eq
id|rq2
)paren
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
r_else
(brace
r_if
c_cond
(paren
id|rq1
OL
id|rq2
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
)brace
r_else
(brace
id|spin_lock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
)brace
)brace
)brace
DECL|function|double_rq_unlock
r_static
r_inline
r_void
id|double_rq_unlock
c_func
(paren
id|runqueue_t
op_star
id|rq1
comma
id|runqueue_t
op_star
id|rq2
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq1
op_ne
id|rq2
)paren
id|spin_unlock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
)brace
DECL|function|init_idle
r_void
id|__init
id|init_idle
c_func
(paren
id|task_t
op_star
id|idle
comma
r_int
id|cpu
)paren
(brace
id|runqueue_t
op_star
id|idle_rq
op_assign
id|cpu_rq
c_func
(paren
id|cpu
)paren
comma
op_star
id|rq
op_assign
id|cpu_rq
c_func
(paren
id|idle-&gt;thread_info-&gt;cpu
)paren
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__cli
c_func
(paren
)paren
suffix:semicolon
id|double_rq_lock
c_func
(paren
id|idle_rq
comma
id|rq
)paren
suffix:semicolon
id|idle_rq-&gt;curr
op_assign
id|idle_rq-&gt;idle
op_assign
id|idle
suffix:semicolon
id|deactivate_task
c_func
(paren
id|idle
comma
id|rq
)paren
suffix:semicolon
id|idle-&gt;array
op_assign
l_int|NULL
suffix:semicolon
id|idle-&gt;prio
op_assign
id|MAX_PRIO
suffix:semicolon
id|idle-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
id|idle-&gt;thread_info-&gt;cpu
op_assign
id|cpu
suffix:semicolon
id|double_rq_unlock
c_func
(paren
id|idle_rq
comma
id|rq
)paren
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|idle
)paren
suffix:semicolon
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/* Set the preempt count _outside_ the spinlocks! */
id|idle-&gt;thread_info-&gt;preempt_count
op_assign
(paren
id|idle-&gt;lock_depth
op_ge
l_int|0
)paren
suffix:semicolon
)brace
r_extern
r_void
id|init_timervecs
c_func
(paren
r_void
)paren
suffix:semicolon
r_extern
r_void
id|timer_bh
c_func
(paren
r_void
)paren
suffix:semicolon
r_extern
r_void
id|tqueue_bh
c_func
(paren
r_void
)paren
suffix:semicolon
r_extern
r_void
id|immediate_bh
c_func
(paren
r_void
)paren
suffix:semicolon
DECL|function|sched_init
r_void
id|__init
id|sched_init
c_func
(paren
r_void
)paren
(brace
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_int
id|i
comma
id|j
comma
id|k
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
id|runqueue_t
op_star
id|rq
op_assign
id|cpu_rq
c_func
(paren
id|i
)paren
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|rq-&gt;active
op_assign
id|rq-&gt;arrays
suffix:semicolon
id|rq-&gt;expired
op_assign
id|rq-&gt;arrays
op_plus
l_int|1
suffix:semicolon
id|spin_lock_init
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|spin_lock_init
c_func
(paren
op_amp
id|rq-&gt;frozen
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|rq-&gt;migration_queue
)paren
suffix:semicolon
r_for
c_loop
(paren
id|j
op_assign
l_int|0
suffix:semicolon
id|j
OL
l_int|2
suffix:semicolon
id|j
op_increment
)paren
(brace
id|array
op_assign
id|rq-&gt;arrays
op_plus
id|j
suffix:semicolon
r_for
c_loop
(paren
id|k
op_assign
l_int|0
suffix:semicolon
id|k
OL
id|MAX_PRIO
suffix:semicolon
id|k
op_increment
)paren
(brace
id|INIT_LIST_HEAD
c_func
(paren
id|array-&gt;queue
op_plus
id|k
)paren
suffix:semicolon
id|__clear_bit
c_func
(paren
id|k
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
singleline_comment|// delimiter for bitsearch
id|__set_bit
c_func
(paren
id|MAX_PRIO
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * We have to do a little magic to get the first&n;&t; * process right in SMP mode.&n;&t; */
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|rq-&gt;curr
op_assign
id|current
suffix:semicolon
id|rq-&gt;idle
op_assign
id|current
suffix:semicolon
id|wake_up_process
c_func
(paren
id|current
)paren
suffix:semicolon
id|init_timervecs
c_func
(paren
)paren
suffix:semicolon
id|init_bh
c_func
(paren
id|TIMER_BH
comma
id|timer_bh
)paren
suffix:semicolon
id|init_bh
c_func
(paren
id|TQUEUE_BH
comma
id|tqueue_bh
)paren
suffix:semicolon
id|init_bh
c_func
(paren
id|IMMEDIATE_BH
comma
id|immediate_bh
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The boot idle thread does lazy MMU switching as well:&n;&t; */
id|atomic_inc
c_func
(paren
op_amp
id|init_mm.mm_count
)paren
suffix:semicolon
id|enter_lazy_tlb
c_func
(paren
op_amp
id|init_mm
comma
id|current
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
macro_line|#if CONFIG_SMP
multiline_comment|/*&n; * This is how migration works:&n; *&n; * 1) we queue a migration_req_t structure in the source CPU&squot;s&n; *    runqueue and wake up that CPU&squot;s migration thread.&n; * 2) we down() the locked semaphore =&gt; thread blocks.&n; * 3) migration thread wakes up (implicitly it forces the migrated&n; *    thread off the CPU)&n; * 4) it gets the migration request and checks whether the migrated&n; *    task is still in the wrong runqueue.&n; * 5) if it&squot;s in the wrong runqueue then the migration thread removes&n; *    it and puts it into the right queue.&n; * 6) migration thread up()s the semaphore.&n; * 7) we wake up and the migration is done.&n; */
r_typedef
r_struct
(brace
DECL|member|list
id|list_t
id|list
suffix:semicolon
DECL|member|task
id|task_t
op_star
id|task
suffix:semicolon
DECL|member|sem
r_struct
id|semaphore
id|sem
suffix:semicolon
DECL|typedef|migration_req_t
)brace
id|migration_req_t
suffix:semicolon
multiline_comment|/*&n; * Change a given task&squot;s CPU affinity. Migrate the process to a&n; * proper CPU and schedule it away if the CPU it&squot;s executing on&n; * is removed from the allowed bitmask.&n; *&n; * NOTE: the caller must have a valid reference to the task, the&n; * task must not exit() &amp; deallocate itself prematurely.&n; */
DECL|function|set_cpus_allowed
r_void
id|set_cpus_allowed
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
id|new_mask
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|migration_req_t
id|req
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|new_mask
op_and_assign
id|cpu_online_map
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_mask
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
id|p-&gt;cpus_allowed
op_assign
id|new_mask
suffix:semicolon
multiline_comment|/*&n;&t; * Can the task run on the task&squot;s current CPU? If not then&n;&t; * migrate the process off to a proper CPU.&n;&t; */
r_if
c_cond
(paren
id|new_mask
op_amp
(paren
l_int|1UL
op_lshift
id|p-&gt;thread_info-&gt;cpu
)paren
)paren
(brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
)brace
id|init_MUTEX_LOCKED
c_func
(paren
op_amp
id|req.sem
)paren
suffix:semicolon
id|req.task
op_assign
id|p
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|req.list
comma
op_amp
id|rq-&gt;migration_queue
)paren
suffix:semicolon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|wake_up_process
c_func
(paren
id|rq-&gt;migration_thread
)paren
suffix:semicolon
id|down
c_func
(paren
op_amp
id|req.sem
)paren
suffix:semicolon
id|out
suffix:colon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Treat the bits of migration_mask as lock bits.&n; * If the bit corresponding to the cpu a migration_thread is&n; * running on then we have failed to claim our cpu and must&n; * yield in order to find another.&n; */
DECL|variable|migration_mask
r_static
r_volatile
r_int
r_int
id|migration_mask
suffix:semicolon
DECL|variable|migration_threads_seeking_cpu
r_static
id|atomic_t
id|migration_threads_seeking_cpu
suffix:semicolon
DECL|variable|migration_complete
r_static
r_struct
id|completion
id|migration_complete
op_assign
id|COMPLETION_INITIALIZER
c_func
(paren
id|migration_complete
)paren
suffix:semicolon
DECL|function|migration_thread
r_static
r_int
id|migration_thread
c_func
(paren
r_void
op_star
id|unused
)paren
(brace
r_struct
id|sched_param
id|param
op_assign
(brace
id|sched_priority
suffix:colon
l_int|99
)brace
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_int
id|ret
suffix:semicolon
id|daemonize
c_func
(paren
)paren
suffix:semicolon
id|sigfillset
c_func
(paren
op_amp
id|current-&gt;blocked
)paren
suffix:semicolon
id|set_fs
c_func
(paren
id|KERNEL_DS
)paren
suffix:semicolon
id|ret
op_assign
id|setscheduler
c_func
(paren
l_int|0
comma
id|SCHED_FIFO
comma
op_amp
id|param
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We have to migrate manually - there is no migration thread&n;&t; * to do this for us yet :-)&n;&t; *&n;&t; * We use the following property of the Linux scheduler. At&n;&t; * this point no other task is running, so by keeping all&n;&t; * migration threads running, the load-balancer will distribute&n;&t; * them between all CPUs equally. At that point every migration&n;&t; * task binds itself to the current CPU.&n;&t; */
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Enter the loop with preemption disabled so that&n;&t; * smp_processor_id() remains valid through the check. The&n;&t; * interior of the wait loop re-enables preemption in an&n;&t; * attempt to get scheduled off the current cpu. When the&n;&t; * loop is exited the lock bit in migration_mask is acquired&n;&t; * and preemption is disabled on the way out. This way the&n;&t; * cpu acquired remains valid when -&gt;cpus_allowed is set.&n;&t; */
r_while
c_loop
(paren
id|test_and_set_bit
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
comma
op_amp
id|migration_mask
)paren
)paren
(brace
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
id|yield
c_func
(paren
)paren
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
)brace
id|current-&gt;cpus_allowed
op_assign
l_int|1
op_lshift
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|rq-&gt;migration_thread
op_assign
id|current
suffix:semicolon
multiline_comment|/*&n;&t; * Now that we&squot;ve bound ourselves to a cpu, post to&n;&t; * migration_threads_seeking_cpu and wait for everyone else.&n;&t; * Preemption should remain disabled and the cpu should remain&n;&t; * in busywait. Yielding the cpu will allow the livelock&n;&t; * where where a timing pattern causes an idle task seeking a&n;&t; * migration_thread to always find the unbound migration_thread &n;&t; * running on the cpu&squot;s it tries to steal tasks from.&n;&t; */
id|atomic_dec
c_func
(paren
op_amp
id|migration_threads_seeking_cpu
)paren
suffix:semicolon
r_while
c_loop
(paren
id|atomic_read
c_func
(paren
op_amp
id|migration_threads_seeking_cpu
)paren
)paren
id|cpu_relax
c_func
(paren
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
id|sprintf
c_func
(paren
id|current-&gt;comm
comma
l_string|&quot;migration_CPU%d&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Everyone&squot;s found their cpu, so now wake migration_init().&n;&t; * Multiple wakeups are harmless; removal from the waitqueue&n;&t; * has locking built-in, and waking an empty queue is valid.&n;&t; */
id|complete
c_func
(paren
op_amp
id|migration_complete
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Initiate the event loop.&n;&t; */
r_for
c_loop
(paren
suffix:semicolon
suffix:semicolon
)paren
(brace
id|runqueue_t
op_star
id|rq_src
comma
op_star
id|rq_dest
suffix:semicolon
r_struct
id|list_head
op_star
id|head
suffix:semicolon
r_int
id|cpu_src
comma
id|cpu_dest
suffix:semicolon
id|migration_req_t
op_star
id|req
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|head
op_assign
op_amp
id|rq-&gt;migration_queue
suffix:semicolon
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
r_if
c_cond
(paren
id|list_empty
c_func
(paren
id|head
)paren
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
r_continue
suffix:semicolon
)brace
id|req
op_assign
id|list_entry
c_func
(paren
id|head-&gt;next
comma
id|migration_req_t
comma
id|list
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
id|head-&gt;next
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|p
op_assign
id|req-&gt;task
suffix:semicolon
id|cpu_dest
op_assign
id|__ffs
c_func
(paren
id|p-&gt;cpus_allowed
)paren
suffix:semicolon
id|rq_dest
op_assign
id|cpu_rq
c_func
(paren
id|cpu_dest
)paren
suffix:semicolon
id|repeat
suffix:colon
id|cpu_src
op_assign
id|p-&gt;thread_info-&gt;cpu
suffix:semicolon
id|rq_src
op_assign
id|cpu_rq
c_func
(paren
id|cpu_src
)paren
suffix:semicolon
id|double_rq_lock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;thread_info-&gt;cpu
op_ne
id|cpu_src
)paren
(brace
id|double_rq_unlock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
r_goto
id|repeat
suffix:semicolon
)brace
r_if
c_cond
(paren
id|rq_src
op_eq
id|rq
)paren
(brace
id|p-&gt;thread_info-&gt;cpu
op_assign
id|cpu_dest
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;array
)paren
(brace
id|deactivate_task
c_func
(paren
id|p
comma
id|rq_src
)paren
suffix:semicolon
id|activate_task
c_func
(paren
id|p
comma
id|rq_dest
)paren
suffix:semicolon
)brace
)brace
id|double_rq_unlock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
id|up
c_func
(paren
op_amp
id|req-&gt;sem
)paren
suffix:semicolon
)brace
)brace
DECL|function|migration_init
r_void
id|__init
id|migration_init
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|orig_cache_decay_ticks
suffix:semicolon
r_int
id|cpu
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|migration_threads_seeking_cpu
comma
id|smp_num_cpus
)paren
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|orig_cache_decay_ticks
op_assign
id|cache_decay_ticks
suffix:semicolon
id|cache_decay_ticks
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|cpu
op_assign
l_int|0
suffix:semicolon
id|cpu
OL
id|smp_num_cpus
suffix:semicolon
id|cpu
op_increment
)paren
r_if
c_cond
(paren
id|kernel_thread
c_func
(paren
id|migration_thread
comma
l_int|NULL
comma
id|CLONE_FS
op_or
id|CLONE_FILES
op_or
id|CLONE_SIGNAL
)paren
OL
l_int|0
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We cannot have missed the wakeup for the migration_thread&n;&t; * bound for the cpu migration_init() is running on cannot&n;&t; * acquire this cpu until migration_init() has yielded it by&n;&t; * means of wait_for_completion().&n;&t; */
id|wait_for_completion
c_func
(paren
op_amp
id|migration_complete
)paren
suffix:semicolon
id|cache_decay_ticks
op_assign
id|orig_cache_decay_ticks
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
macro_line|#endif
eof
