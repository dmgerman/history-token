multiline_comment|/*&n; *  kernel/sched.c&n; *&n; *  Kernel scheduler and related syscalls&n; *&n; *  Copyright (C) 1991-2002  Linus Torvalds&n; *&n; *  1996-12-23  Modified by Dave Grothe to fix bugs in semaphores and&n; *&t;&t;make semaphores SMP safe&n; *  1998-11-19&t;Implemented schedule_timeout() and related stuff&n; *&t;&t;by Andrea Arcangeli&n; *  2002-01-04&t;New ultra-scalable O(1) scheduler by Ingo Molnar:&n; *&t;&t;hybrid priority-list and round-robin design with&n; *&t;&t;an array-switch method of distributing timeslices&n; *&t;&t;and per-CPU runqueues.  Cleanups and useful suggestions&n; *&t;&t;by Davide Libenzi, preemptible kernel bits by Robert Love.&n; */
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/nmi.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;asm/uaccess.h&gt;
macro_line|#include &lt;linux/highmem.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;asm/mmu_context.h&gt;
macro_line|#include &lt;linux/interrupt.h&gt;
macro_line|#include &lt;linux/completion.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/security.h&gt;
macro_line|#include &lt;linux/notifier.h&gt;
macro_line|#include &lt;linux/blkdev.h&gt;
macro_line|#include &lt;linux/delay.h&gt;
macro_line|#include &lt;linux/timer.h&gt;
macro_line|#include &lt;linux/rcupdate.h&gt;
macro_line|#ifdef CONFIG_NUMA
DECL|macro|cpu_to_node_mask
mdefine_line|#define cpu_to_node_mask(cpu) node_to_cpumask(cpu_to_node(cpu))
macro_line|#else
DECL|macro|cpu_to_node_mask
mdefine_line|#define cpu_to_node_mask(cpu) (cpu_online_map)
macro_line|#endif
multiline_comment|/*&n; * Convert user-nice values [ -20 ... 0 ... 19 ]&n; * to static priority [ MAX_RT_PRIO..MAX_PRIO-1 ],&n; * and back.&n; */
DECL|macro|NICE_TO_PRIO
mdefine_line|#define NICE_TO_PRIO(nice)&t;(MAX_RT_PRIO + (nice) + 20)
DECL|macro|PRIO_TO_NICE
mdefine_line|#define PRIO_TO_NICE(prio)&t;((prio) - MAX_RT_PRIO - 20)
DECL|macro|TASK_NICE
mdefine_line|#define TASK_NICE(p)&t;&t;PRIO_TO_NICE((p)-&gt;static_prio)
multiline_comment|/*&n; * &squot;User priority&squot; is the nice value converted to something we&n; * can work with better when scaling various scheduler parameters,&n; * it&squot;s a [ 0 ... 39 ] range.&n; */
DECL|macro|USER_PRIO
mdefine_line|#define USER_PRIO(p)&t;&t;((p)-MAX_RT_PRIO)
DECL|macro|TASK_USER_PRIO
mdefine_line|#define TASK_USER_PRIO(p)&t;USER_PRIO((p)-&gt;static_prio)
DECL|macro|MAX_USER_PRIO
mdefine_line|#define MAX_USER_PRIO&t;&t;(USER_PRIO(MAX_PRIO))
multiline_comment|/*&n; * These are the &squot;tuning knobs&squot; of the scheduler:&n; *&n; * Minimum timeslice is 10 msecs, default timeslice is 100 msecs,&n; * maximum timeslice is 200 msecs. Timeslices get refilled after&n; * they expire.&n; */
DECL|macro|MIN_TIMESLICE
mdefine_line|#define MIN_TIMESLICE&t;&t;( 10 * HZ / 1000)
DECL|macro|MAX_TIMESLICE
mdefine_line|#define MAX_TIMESLICE&t;&t;(200 * HZ / 1000)
DECL|macro|CHILD_PENALTY
mdefine_line|#define CHILD_PENALTY&t;&t;50
DECL|macro|PARENT_PENALTY
mdefine_line|#define PARENT_PENALTY&t;&t;100
DECL|macro|EXIT_WEIGHT
mdefine_line|#define EXIT_WEIGHT&t;&t;3
DECL|macro|PRIO_BONUS_RATIO
mdefine_line|#define PRIO_BONUS_RATIO&t;25
DECL|macro|INTERACTIVE_DELTA
mdefine_line|#define INTERACTIVE_DELTA&t;2
DECL|macro|MAX_SLEEP_AVG
mdefine_line|#define MAX_SLEEP_AVG&t;&t;(10*HZ)
DECL|macro|STARVATION_LIMIT
mdefine_line|#define STARVATION_LIMIT&t;(10*HZ)
DECL|macro|NODE_THRESHOLD
mdefine_line|#define NODE_THRESHOLD&t;&t;125
multiline_comment|/*&n; * If a task is &squot;interactive&squot; then we reinsert it in the active&n; * array after it has expired its current timeslice. (it will not&n; * continue to run immediately, it will still roundrobin with&n; * other interactive tasks.)&n; *&n; * This part scales the interactivity limit depending on niceness.&n; *&n; * We scale it linearly, offset by the INTERACTIVE_DELTA delta.&n; * Here are a few examples of different nice levels:&n; *&n; *  TASK_INTERACTIVE(-20): [1,1,1,1,1,1,1,1,1,0,0]&n; *  TASK_INTERACTIVE(-10): [1,1,1,1,1,1,1,0,0,0,0]&n; *  TASK_INTERACTIVE(  0): [1,1,1,1,0,0,0,0,0,0,0]&n; *  TASK_INTERACTIVE( 10): [1,1,0,0,0,0,0,0,0,0,0]&n; *  TASK_INTERACTIVE( 19): [0,0,0,0,0,0,0,0,0,0,0]&n; *&n; * (the X axis represents the possible -5 ... 0 ... +5 dynamic&n; *  priority range a task can explore, a value of &squot;1&squot; means the&n; *  task is rated interactive.)&n; *&n; * Ie. nice +19 tasks can never get &squot;interactive&squot; enough to be&n; * reinserted into the active array. And only heavily CPU-hog nice -20&n; * tasks will be expired. Default nice 0 tasks are somewhere between,&n; * it takes some effort for them to get interactive, but it&squot;s not&n; * too hard.&n; */
DECL|macro|SCALE
mdefine_line|#define SCALE(v1,v1_max,v2_max) &bslash;&n;&t;(v1) * (v2_max) / (v1_max)
DECL|macro|DELTA
mdefine_line|#define DELTA(p) &bslash;&n;&t;(SCALE(TASK_NICE(p), 40, MAX_USER_PRIO*PRIO_BONUS_RATIO/100) + &bslash;&n;&t;&t;INTERACTIVE_DELTA)
DECL|macro|TASK_INTERACTIVE
mdefine_line|#define TASK_INTERACTIVE(p) &bslash;&n;&t;((p)-&gt;prio &lt;= (p)-&gt;static_prio - DELTA(p))
multiline_comment|/*&n; * BASE_TIMESLICE scales user-nice values [ -20 ... 19 ]&n; * to time slice values.&n; *&n; * The higher a thread&squot;s priority, the bigger timeslices&n; * it gets during one round of execution. But even the lowest&n; * priority thread gets MIN_TIMESLICE worth of execution time.&n; *&n; * task_timeslice() is the interface that is used by the scheduler.&n; */
DECL|macro|BASE_TIMESLICE
mdefine_line|#define BASE_TIMESLICE(p) (MIN_TIMESLICE + &bslash;&n;&t;((MAX_TIMESLICE - MIN_TIMESLICE) * (MAX_PRIO-1-(p)-&gt;static_prio)/(MAX_USER_PRIO - 1)))
DECL|function|task_timeslice
r_static
r_inline
r_int
r_int
id|task_timeslice
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|BASE_TIMESLICE
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * These are the runqueue data structures:&n; */
DECL|macro|BITMAP_SIZE
mdefine_line|#define BITMAP_SIZE ((((MAX_PRIO+1+7)/8)+sizeof(long)-1)/sizeof(long))
DECL|typedef|runqueue_t
r_typedef
r_struct
id|runqueue
id|runqueue_t
suffix:semicolon
DECL|struct|prio_array
r_struct
id|prio_array
(brace
DECL|member|nr_active
r_int
id|nr_active
suffix:semicolon
DECL|member|bitmap
r_int
r_int
id|bitmap
(braket
id|BITMAP_SIZE
)braket
suffix:semicolon
DECL|member|queue
r_struct
id|list_head
id|queue
(braket
id|MAX_PRIO
)braket
suffix:semicolon
)brace
suffix:semicolon
multiline_comment|/*&n; * This is the main, per-CPU runqueue data structure.&n; *&n; * Locking rule: those places that want to lock multiple runqueues&n; * (such as the load balancing or the thread migration code), lock&n; * acquire operations must be ordered by ascending &amp;runqueue.&n; */
DECL|struct|runqueue
r_struct
id|runqueue
(brace
DECL|member|lock
id|spinlock_t
id|lock
suffix:semicolon
DECL|member|nr_running
DECL|member|nr_switches
DECL|member|expired_timestamp
r_int
r_int
id|nr_running
comma
id|nr_switches
comma
id|expired_timestamp
comma
DECL|member|nr_uninterruptible
id|nr_uninterruptible
suffix:semicolon
DECL|member|curr
DECL|member|idle
id|task_t
op_star
id|curr
comma
op_star
id|idle
suffix:semicolon
DECL|member|prev_mm
r_struct
id|mm_struct
op_star
id|prev_mm
suffix:semicolon
DECL|member|active
DECL|member|expired
DECL|member|arrays
id|prio_array_t
op_star
id|active
comma
op_star
id|expired
comma
id|arrays
(braket
l_int|2
)braket
suffix:semicolon
DECL|member|prev_cpu_load
r_int
id|prev_cpu_load
(braket
id|NR_CPUS
)braket
suffix:semicolon
macro_line|#ifdef CONFIG_NUMA
DECL|member|node_nr_running
id|atomic_t
op_star
id|node_nr_running
suffix:semicolon
DECL|member|prev_node_load
r_int
id|prev_node_load
(braket
id|MAX_NUMNODES
)braket
suffix:semicolon
macro_line|#endif
DECL|member|migration_thread
id|task_t
op_star
id|migration_thread
suffix:semicolon
DECL|member|migration_queue
r_struct
id|list_head
id|migration_queue
suffix:semicolon
DECL|member|nr_iowait
id|atomic_t
id|nr_iowait
suffix:semicolon
DECL|variable|____cacheline_aligned
)brace
id|____cacheline_aligned
suffix:semicolon
DECL|variable|__cacheline_aligned
r_static
r_struct
id|runqueue
id|runqueues
(braket
id|NR_CPUS
)braket
id|__cacheline_aligned
suffix:semicolon
DECL|macro|cpu_rq
mdefine_line|#define cpu_rq(cpu)&t;&t;(runqueues + (cpu))
DECL|macro|this_rq
mdefine_line|#define this_rq()&t;&t;cpu_rq(smp_processor_id())
DECL|macro|task_rq
mdefine_line|#define task_rq(p)&t;&t;cpu_rq(task_cpu(p))
DECL|macro|cpu_curr
mdefine_line|#define cpu_curr(cpu)&t;&t;(cpu_rq(cpu)-&gt;curr)
DECL|macro|rt_task
mdefine_line|#define rt_task(p)&t;&t;((p)-&gt;prio &lt; MAX_RT_PRIO)
multiline_comment|/*&n; * Default context-switch locking:&n; */
macro_line|#ifndef prepare_arch_switch
DECL|macro|prepare_arch_switch
macro_line|# define prepare_arch_switch(rq, next)&t;do { } while(0)
DECL|macro|finish_arch_switch
macro_line|# define finish_arch_switch(rq, next)&t;spin_unlock_irq(&amp;(rq)-&gt;lock)
DECL|macro|task_running
macro_line|# define task_running(rq, p)&t;&t;((rq)-&gt;curr == (p))
macro_line|#endif
macro_line|#ifdef CONFIG_NUMA
multiline_comment|/*&n; * Keep track of running tasks.&n; */
DECL|variable|____cacheline_maxaligned_in_smp
r_static
id|atomic_t
id|node_nr_running
(braket
id|MAX_NUMNODES
)braket
id|____cacheline_maxaligned_in_smp
op_assign
(brace
(braket
l_int|0
dot
dot
dot
id|MAX_NUMNODES
op_minus
l_int|1
)braket
op_assign
id|ATOMIC_INIT
c_func
(paren
l_int|0
)paren
)brace
suffix:semicolon
DECL|function|nr_running_init
r_static
r_inline
r_void
id|nr_running_init
c_func
(paren
r_struct
id|runqueue
op_star
id|rq
)paren
(brace
id|rq-&gt;node_nr_running
op_assign
op_amp
id|node_nr_running
(braket
l_int|0
)braket
suffix:semicolon
)brace
DECL|function|nr_running_inc
r_static
r_inline
r_void
id|nr_running_inc
c_func
(paren
id|runqueue_t
op_star
id|rq
)paren
(brace
id|atomic_inc
c_func
(paren
id|rq-&gt;node_nr_running
)paren
suffix:semicolon
id|rq-&gt;nr_running
op_increment
suffix:semicolon
)brace
DECL|function|nr_running_dec
r_static
r_inline
r_void
id|nr_running_dec
c_func
(paren
id|runqueue_t
op_star
id|rq
)paren
(brace
id|atomic_dec
c_func
(paren
id|rq-&gt;node_nr_running
)paren
suffix:semicolon
id|rq-&gt;nr_running
op_decrement
suffix:semicolon
)brace
DECL|function|node_nr_running_init
id|__init
r_void
id|node_nr_running_init
c_func
(paren
r_void
)paren
(brace
r_int
id|i
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|node_nr_running
op_assign
op_amp
id|node_nr_running
(braket
id|cpu_to_node
c_func
(paren
id|i
)paren
)braket
suffix:semicolon
)brace
macro_line|#else /* !CONFIG_NUMA */
DECL|macro|nr_running_init
macro_line|# define nr_running_init(rq)   do { } while (0)
DECL|macro|nr_running_inc
macro_line|# define nr_running_inc(rq)    do { (rq)-&gt;nr_running++; } while (0)
DECL|macro|nr_running_dec
macro_line|# define nr_running_dec(rq)    do { (rq)-&gt;nr_running--; } while (0)
macro_line|#endif /* CONFIG_NUMA */
multiline_comment|/*&n; * task_rq_lock - lock the runqueue a given task resides on and disable&n; * interrupts.  Note the ordering: we can safely lookup the task_rq without&n; * explicitly disabling preemption.&n; */
DECL|function|task_rq_lock
r_static
r_inline
id|runqueue_t
op_star
id|task_rq_lock
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
op_star
id|flags
)paren
(brace
r_struct
id|runqueue
op_star
id|rq
suffix:semicolon
id|repeat_lock_task
suffix:colon
id|local_irq_save
c_func
(paren
op_star
id|flags
)paren
suffix:semicolon
id|rq
op_assign
id|task_rq
c_func
(paren
id|p
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|rq
op_ne
id|task_rq
c_func
(paren
id|p
)paren
)paren
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
op_star
id|flags
)paren
suffix:semicolon
r_goto
id|repeat_lock_task
suffix:semicolon
)brace
r_return
id|rq
suffix:semicolon
)brace
DECL|function|task_rq_unlock
r_static
r_inline
r_void
id|task_rq_unlock
c_func
(paren
id|runqueue_t
op_star
id|rq
comma
r_int
r_int
op_star
id|flags
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
op_star
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * rq_lock - lock a given runqueue and disable interrupts.&n; */
DECL|function|this_rq_lock
r_static
r_inline
id|runqueue_t
op_star
id|this_rq_lock
c_func
(paren
r_void
)paren
(brace
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|local_irq_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
DECL|function|rq_unlock
r_static
r_inline
r_void
id|rq_unlock
c_func
(paren
id|runqueue_t
op_star
id|rq
)paren
(brace
id|spin_unlock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Adding/removing a task to/from a priority array:&n; */
DECL|function|dequeue_task
r_static
r_inline
r_void
id|dequeue_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|prio_array_t
op_star
id|array
)paren
(brace
id|array-&gt;nr_active
op_decrement
suffix:semicolon
id|list_del
c_func
(paren
op_amp
id|p-&gt;run_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|list_empty
c_func
(paren
id|array-&gt;queue
op_plus
id|p-&gt;prio
)paren
)paren
id|__clear_bit
c_func
(paren
id|p-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
DECL|function|enqueue_task
r_static
r_inline
r_void
id|enqueue_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|prio_array_t
op_star
id|array
)paren
(brace
id|list_add_tail
c_func
(paren
op_amp
id|p-&gt;run_list
comma
id|array-&gt;queue
op_plus
id|p-&gt;prio
)paren
suffix:semicolon
id|__set_bit
c_func
(paren
id|p-&gt;prio
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
id|array-&gt;nr_active
op_increment
suffix:semicolon
id|p-&gt;array
op_assign
id|array
suffix:semicolon
)brace
multiline_comment|/*&n; * effective_prio - return the priority that is based on the static&n; * priority but is modified by bonuses/penalties.&n; *&n; * We scale the actual sleep average [0 .... MAX_SLEEP_AVG]&n; * into the -5 ... 0 ... +5 bonus/penalty range.&n; *&n; * We use 25% of the full 0...39 priority range so that:&n; *&n; * 1) nice +19 interactive tasks do not preempt nice 0 CPU hogs.&n; * 2) nice -20 CPU hogs do not get preempted by nice 0 tasks.&n; *&n; * Both properties are important to certain workloads.&n; */
DECL|function|effective_prio
r_static
r_int
id|effective_prio
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
id|bonus
comma
id|prio
suffix:semicolon
r_if
c_cond
(paren
id|rt_task
c_func
(paren
id|p
)paren
)paren
r_return
id|p-&gt;prio
suffix:semicolon
id|bonus
op_assign
id|MAX_USER_PRIO
op_star
id|PRIO_BONUS_RATIO
op_star
id|p-&gt;sleep_avg
op_div
id|MAX_SLEEP_AVG
op_div
l_int|100
op_minus
id|MAX_USER_PRIO
op_star
id|PRIO_BONUS_RATIO
op_div
l_int|100
op_div
l_int|2
suffix:semicolon
id|prio
op_assign
id|p-&gt;static_prio
op_minus
id|bonus
suffix:semicolon
r_if
c_cond
(paren
id|prio
OL
id|MAX_RT_PRIO
)paren
id|prio
op_assign
id|MAX_RT_PRIO
suffix:semicolon
r_if
c_cond
(paren
id|prio
OG
id|MAX_PRIO
op_minus
l_int|1
)paren
id|prio
op_assign
id|MAX_PRIO
op_minus
l_int|1
suffix:semicolon
r_return
id|prio
suffix:semicolon
)brace
multiline_comment|/*&n; * __activate_task - move a task to the runqueue.&n; */
DECL|function|__activate_task
r_static
r_inline
r_void
id|__activate_task
c_func
(paren
id|task_t
op_star
id|p
comma
id|runqueue_t
op_star
id|rq
)paren
(brace
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
id|nr_running_inc
c_func
(paren
id|rq
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * activate_task - move a task to the runqueue and do priority recalculation&n; *&n; * Update all the scheduling statistics stuff. (sleep average&n; * calculation, priority modifiers, etc.)&n; */
DECL|function|activate_task
r_static
r_inline
r_int
id|activate_task
c_func
(paren
id|task_t
op_star
id|p
comma
id|runqueue_t
op_star
id|rq
)paren
(brace
r_int
id|sleep_time
op_assign
id|jiffies
op_minus
id|p-&gt;last_run
op_minus
l_int|1
suffix:semicolon
r_int
id|requeue_waker
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|sleep_time
OG
l_int|0
)paren
(brace
r_int
id|sleep_avg
suffix:semicolon
multiline_comment|/*&n;&t;&t; * This code gives a bonus to interactive tasks.&n;&t;&t; *&n;&t;&t; * The boost works by updating the &squot;average sleep time&squot;&n;&t;&t; * value here, based on -&gt;last_run. The more time a task&n;&t;&t; * spends sleeping, the higher the average gets - and the&n;&t;&t; * higher the priority boost gets as well.&n;&t;&t; */
id|sleep_avg
op_assign
id|p-&gt;sleep_avg
op_plus
id|sleep_time
suffix:semicolon
multiline_comment|/*&n;&t;&t; * &squot;Overflow&squot; bonus ticks go to the waker as well, so the&n;&t;&t; * ticks are not lost. This has the effect of further&n;&t;&t; * boosting tasks that are related to maximum-interactive&n;&t;&t; * tasks.&n;&t;&t; */
r_if
c_cond
(paren
id|sleep_avg
OG
id|MAX_SLEEP_AVG
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|in_interrupt
c_func
(paren
)paren
)paren
(brace
id|sleep_avg
op_add_assign
id|current-&gt;sleep_avg
op_minus
id|MAX_SLEEP_AVG
suffix:semicolon
r_if
c_cond
(paren
id|sleep_avg
OG
id|MAX_SLEEP_AVG
)paren
id|sleep_avg
op_assign
id|MAX_SLEEP_AVG
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;sleep_avg
op_ne
id|sleep_avg
)paren
(brace
id|current-&gt;sleep_avg
op_assign
id|sleep_avg
suffix:semicolon
id|requeue_waker
op_assign
l_int|1
suffix:semicolon
)brace
)brace
id|sleep_avg
op_assign
id|MAX_SLEEP_AVG
suffix:semicolon
)brace
r_if
c_cond
(paren
id|p-&gt;sleep_avg
op_ne
id|sleep_avg
)paren
(brace
id|p-&gt;sleep_avg
op_assign
id|sleep_avg
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
)brace
id|__activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
r_return
id|requeue_waker
suffix:semicolon
)brace
multiline_comment|/*&n; * deactivate_task - remove a task from the runqueue.&n; */
DECL|function|deactivate_task
r_static
r_inline
r_void
id|deactivate_task
c_func
(paren
r_struct
id|task_struct
op_star
id|p
comma
id|runqueue_t
op_star
id|rq
)paren
(brace
id|nr_running_dec
c_func
(paren
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;state
op_eq
id|TASK_UNINTERRUPTIBLE
)paren
id|rq-&gt;nr_uninterruptible
op_increment
suffix:semicolon
id|dequeue_task
c_func
(paren
id|p
comma
id|p-&gt;array
)paren
suffix:semicolon
id|p-&gt;array
op_assign
l_int|NULL
suffix:semicolon
)brace
multiline_comment|/*&n; * resched_task - mark a task &squot;to be rescheduled now&squot;.&n; *&n; * On UP this means the setting of the need_resched flag, on SMP it&n; * might also involve a cross-CPU call to trigger the scheduler on&n; * the target CPU.&n; */
DECL|function|resched_task
r_static
r_inline
r_void
id|resched_task
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
macro_line|#ifdef CONFIG_SMP
r_int
id|need_resched
comma
id|nrpolling
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* minimise the chance of sending an interrupt to poll_idle() */
id|nrpolling
op_assign
id|test_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_POLLING_NRFLAG
)paren
suffix:semicolon
id|need_resched
op_assign
id|test_and_set_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_NEED_RESCHED
)paren
suffix:semicolon
id|nrpolling
op_or_assign
id|test_tsk_thread_flag
c_func
(paren
id|p
comma
id|TIF_POLLING_NRFLAG
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|need_resched
op_logical_and
op_logical_neg
id|nrpolling
op_logical_and
(paren
id|task_cpu
c_func
(paren
id|p
)paren
op_ne
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
id|smp_send_reschedule
c_func
(paren
id|task_cpu
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
macro_line|#else
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
macro_line|#endif
)brace
macro_line|#ifdef CONFIG_SMP
multiline_comment|/*&n; * wait_task_inactive - wait for a thread to unschedule.&n; *&n; * The caller must ensure that the task *will* unschedule sometime soon,&n; * else this function might spin for a *long* time. This function can&squot;t&n; * be called with interrupts off, or it may introduce deadlock with&n; * smp_call_function() if an IPI is sent by the same process we are&n; * waiting to become inactive.&n; */
DECL|function|wait_task_inactive
r_void
id|wait_task_inactive
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|repeat
suffix:colon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|rq
op_assign
id|task_rq
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|task_running
c_func
(paren
id|rq
comma
id|p
)paren
)paren
)paren
(brace
id|cpu_relax
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * enable/disable preemption just to make this&n;&t;&t; * a preemption point - we are busy-waiting&n;&t;&t; * anyway.&n;&t;&t; */
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_goto
id|repeat
suffix:semicolon
)brace
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|task_running
c_func
(paren
id|rq
comma
id|p
)paren
)paren
)paren
(brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_goto
id|repeat
suffix:semicolon
)brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/*&n; * kick_if_running - kick the remote CPU if the task is running currently.&n; *&n; * This code is used by the signal code to signal tasks&n; * which are in user-mode, as quickly as possible.&n; *&n; * (Note that we do this lockless - if the task does anything&n; * while the message is in flight then it will notice the&n; * sigpending condition anyway.)&n; */
DECL|function|kick_if_running
r_void
id|kick_if_running
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_if
c_cond
(paren
(paren
id|task_running
c_func
(paren
id|task_rq
c_func
(paren
id|p
)paren
comma
id|p
)paren
)paren
op_logical_and
(paren
id|task_cpu
c_func
(paren
id|p
)paren
op_ne
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
id|resched_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
multiline_comment|/***&n; * try_to_wake_up - wake up a thread&n; * @p: the to-be-woken-up thread&n; * @state: the mask of task states that can be woken&n; * @sync: do a synchronous wakeup?&n; *&n; * Put it on the run-queue if it&squot;s not already there. The &quot;current&quot;&n; * thread is always on the run-queue (except when the actual&n; * re-schedule is in progress), and as such you&squot;re allowed to do&n; * the simpler &quot;current-&gt;state = TASK_RUNNING&quot; to mark yourself&n; * runnable without the overhead of this.&n; *&n; * returns failure only if the task is already active.&n; */
DECL|function|try_to_wake_up
r_static
r_int
id|try_to_wake_up
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
id|state
comma
r_int
id|sync
)paren
(brace
r_int
id|success
op_assign
l_int|0
comma
id|requeue_waker
op_assign
l_int|0
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
r_int
id|old_state
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|repeat_lock_task
suffix:colon
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
id|old_state
op_assign
id|p-&gt;state
suffix:semicolon
r_if
c_cond
(paren
id|old_state
op_amp
id|state
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|p-&gt;array
)paren
(brace
multiline_comment|/*&n;&t;&t;&t; * Fast-migrate the task if it&squot;s not running or runnable&n;&t;&t;&t; * currently. Do not violate hard affinity.&n;&t;&t;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|sync
op_logical_and
op_logical_neg
id|task_running
c_func
(paren
id|rq
comma
id|p
)paren
op_logical_and
(paren
id|task_cpu
c_func
(paren
id|p
)paren
op_ne
id|smp_processor_id
c_func
(paren
)paren
)paren
op_logical_and
(paren
id|p-&gt;cpus_allowed
op_amp
(paren
l_int|1UL
op_lshift
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
)paren
)paren
(brace
id|set_task_cpu
c_func
(paren
id|p
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
r_goto
id|repeat_lock_task
suffix:semicolon
)brace
r_if
c_cond
(paren
id|old_state
op_eq
id|TASK_UNINTERRUPTIBLE
)paren
id|rq-&gt;nr_uninterruptible
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|sync
)paren
id|__activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
r_else
(brace
id|requeue_waker
op_assign
id|activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;prio
OL
id|rq-&gt;curr-&gt;prio
)paren
id|resched_task
c_func
(paren
id|rq-&gt;curr
)paren
suffix:semicolon
)brace
id|success
op_assign
l_int|1
suffix:semicolon
)brace
id|p-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
)brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We have to do this outside the other spinlock, the two&n;&t; * runqueues might be different:&n;&t; */
r_if
c_cond
(paren
id|requeue_waker
)paren
(brace
id|prio_array_t
op_star
id|array
suffix:semicolon
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|current
comma
op_amp
id|flags
)paren
suffix:semicolon
id|array
op_assign
id|current-&gt;array
suffix:semicolon
id|dequeue_task
c_func
(paren
id|current
comma
id|array
)paren
suffix:semicolon
id|current-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|current
)paren
suffix:semicolon
id|enqueue_task
c_func
(paren
id|current
comma
id|array
)paren
suffix:semicolon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
)brace
r_return
id|success
suffix:semicolon
)brace
DECL|function|wake_up_process
r_int
id|wake_up_process
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|try_to_wake_up
c_func
(paren
id|p
comma
id|TASK_STOPPED
op_or
id|TASK_INTERRUPTIBLE
op_or
id|TASK_UNINTERRUPTIBLE
comma
l_int|0
)paren
suffix:semicolon
)brace
DECL|function|wake_up_state
r_int
id|wake_up_state
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
id|state
)paren
(brace
r_return
id|try_to_wake_up
c_func
(paren
id|p
comma
id|state
comma
l_int|0
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * wake_up_forked_process - wake up a freshly forked process.&n; *&n; * This function will do some initial scheduler statistics housekeeping&n; * that must be done for every newly created process.&n; */
DECL|function|wake_up_forked_process
r_void
id|wake_up_forked_process
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|runqueue_t
op_star
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|current
comma
op_amp
id|flags
)paren
suffix:semicolon
id|p-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
multiline_comment|/*&n;&t; * We decrease the sleep average of forking parents&n;&t; * and children as well, to keep max-interactive tasks&n;&t; * from forking tasks that are max-interactive.&n;&t; */
id|current-&gt;sleep_avg
op_assign
id|current-&gt;sleep_avg
op_star
id|PARENT_PENALTY
op_div
l_int|100
suffix:semicolon
id|p-&gt;sleep_avg
op_assign
id|p-&gt;sleep_avg
op_star
id|CHILD_PENALTY
op_div
l_int|100
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
id|set_task_cpu
c_func
(paren
id|p
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|current-&gt;array
)paren
)paren
id|__activate_task
c_func
(paren
id|p
comma
id|rq
)paren
suffix:semicolon
r_else
(brace
id|p-&gt;prio
op_assign
id|current-&gt;prio
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|p-&gt;run_list
comma
op_amp
id|current-&gt;run_list
)paren
suffix:semicolon
id|p-&gt;array
op_assign
id|current-&gt;array
suffix:semicolon
id|p-&gt;array-&gt;nr_active
op_increment
suffix:semicolon
id|nr_running_inc
c_func
(paren
id|rq
)paren
suffix:semicolon
)brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Potentially available exiting-child timeslices are&n; * retrieved here - this way the parent does not get&n; * penalized for creating too many threads.&n; *&n; * (this cannot be used to &squot;generate&squot; timeslices&n; * artificially, because any timeslice recovered here&n; * was given away by the parent in the first place.)&n; */
DECL|function|sched_exit
r_void
id|sched_exit
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;first_time_slice
)paren
(brace
id|p-&gt;parent-&gt;time_slice
op_add_assign
id|p-&gt;time_slice
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|p-&gt;parent-&gt;time_slice
OG
id|MAX_TIMESLICE
)paren
)paren
id|p-&gt;parent-&gt;time_slice
op_assign
id|MAX_TIMESLICE
suffix:semicolon
)brace
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * If the child was a (relative-) CPU hog then decrease&n;&t; * the sleep_avg of the parent as well.&n;&t; */
r_if
c_cond
(paren
id|p-&gt;sleep_avg
OL
id|p-&gt;parent-&gt;sleep_avg
)paren
id|p-&gt;parent-&gt;sleep_avg
op_assign
(paren
id|p-&gt;parent-&gt;sleep_avg
op_star
id|EXIT_WEIGHT
op_plus
id|p-&gt;sleep_avg
)paren
op_div
(paren
id|EXIT_WEIGHT
op_plus
l_int|1
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * finish_task_switch - clean up after a task-switch&n; * @prev: the thread we just switched away from.&n; *&n; * We enter this with the runqueue still locked, and finish_arch_switch()&n; * will unlock it along with doing any other architecture-specific cleanup&n; * actions.&n; *&n; * Note that we may have delayed dropping an mm in context_switch(). If&n; * so, we finish that here outside of the runqueue lock.  (Doing it&n; * with the lock held can cause deadlocks; see schedule() for&n; * details.)&n; */
DECL|function|finish_task_switch
r_static
r_inline
r_void
id|finish_task_switch
c_func
(paren
id|task_t
op_star
id|prev
)paren
(brace
id|runqueue_t
op_star
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|rq-&gt;prev_mm
suffix:semicolon
id|rq-&gt;prev_mm
op_assign
l_int|NULL
suffix:semicolon
id|finish_arch_switch
c_func
(paren
id|rq
comma
id|prev
)paren
suffix:semicolon
r_if
c_cond
(paren
id|mm
)paren
id|mmdrop
c_func
(paren
id|mm
)paren
suffix:semicolon
r_if
c_cond
(paren
id|prev-&gt;state
op_amp
(paren
id|TASK_DEAD
op_or
id|TASK_ZOMBIE
)paren
)paren
id|put_task_struct
c_func
(paren
id|prev
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * schedule_tail - first thing a freshly forked thread must call.&n; * @prev: the thread we just switched away from.&n; */
DECL|function|schedule_tail
id|asmlinkage
r_void
id|schedule_tail
c_func
(paren
id|task_t
op_star
id|prev
)paren
(brace
id|finish_task_switch
c_func
(paren
id|prev
)paren
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;set_child_tid
)paren
id|put_user
c_func
(paren
id|current-&gt;pid
comma
id|current-&gt;set_child_tid
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * context_switch - switch to the new MM and the new&n; * thread&squot;s register state.&n; */
DECL|function|context_switch
r_static
r_inline
id|task_t
op_star
id|context_switch
c_func
(paren
id|runqueue_t
op_star
id|rq
comma
id|task_t
op_star
id|prev
comma
id|task_t
op_star
id|next
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|next-&gt;mm
suffix:semicolon
r_struct
id|mm_struct
op_star
id|oldmm
op_assign
id|prev-&gt;active_mm
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|mm
)paren
)paren
(brace
id|next-&gt;active_mm
op_assign
id|oldmm
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|oldmm-&gt;mm_count
)paren
suffix:semicolon
id|enter_lazy_tlb
c_func
(paren
id|oldmm
comma
id|next
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
r_else
id|switch_mm
c_func
(paren
id|oldmm
comma
id|mm
comma
id|next
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|prev-&gt;mm
)paren
)paren
(brace
id|prev-&gt;active_mm
op_assign
l_int|NULL
suffix:semicolon
id|WARN_ON
c_func
(paren
id|rq-&gt;prev_mm
)paren
suffix:semicolon
id|rq-&gt;prev_mm
op_assign
id|oldmm
suffix:semicolon
)brace
multiline_comment|/* Here we just switch the register state and the stack. */
id|switch_to
c_func
(paren
id|prev
comma
id|next
comma
id|prev
)paren
suffix:semicolon
r_return
id|prev
suffix:semicolon
)brace
multiline_comment|/*&n; * nr_running, nr_uninterruptible and nr_context_switches:&n; *&n; * externally visible scheduler statistics: current number of runnable&n; * threads, current number of uninterruptible-sleeping threads, total&n; * number of context switches performed since bootup.&n; */
DECL|function|nr_running
r_int
r_int
id|nr_running
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
id|sum
op_add_assign
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_running
suffix:semicolon
r_return
id|sum
suffix:semicolon
)brace
DECL|function|nr_uninterruptible
r_int
r_int
id|nr_uninterruptible
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|cpu_online
c_func
(paren
id|i
)paren
)paren
r_continue
suffix:semicolon
id|sum
op_add_assign
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_uninterruptible
suffix:semicolon
)brace
r_return
id|sum
suffix:semicolon
)brace
DECL|function|nr_context_switches
r_int
r_int
id|nr_context_switches
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|cpu_online
c_func
(paren
id|i
)paren
)paren
r_continue
suffix:semicolon
id|sum
op_add_assign
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_switches
suffix:semicolon
)brace
r_return
id|sum
suffix:semicolon
)brace
DECL|function|nr_iowait
r_int
r_int
id|nr_iowait
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|i
comma
id|sum
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
op_increment
id|i
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|cpu_online
c_func
(paren
id|i
)paren
)paren
r_continue
suffix:semicolon
id|sum
op_add_assign
id|atomic_read
c_func
(paren
op_amp
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_iowait
)paren
suffix:semicolon
)brace
r_return
id|sum
suffix:semicolon
)brace
multiline_comment|/*&n; * double_rq_lock - safely lock two runqueues&n; *&n; * Note this does not disable interrupts like task_rq_lock,&n; * you need to do so manually before calling.&n; */
DECL|function|double_rq_lock
r_static
r_inline
r_void
id|double_rq_lock
c_func
(paren
id|runqueue_t
op_star
id|rq1
comma
id|runqueue_t
op_star
id|rq2
)paren
(brace
r_if
c_cond
(paren
id|rq1
op_eq
id|rq2
)paren
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
r_else
(brace
r_if
c_cond
(paren
id|rq1
OL
id|rq2
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
)brace
r_else
(brace
id|spin_lock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
)brace
)brace
)brace
multiline_comment|/*&n; * double_rq_unlock - safely unlock two runqueues&n; *&n; * Note this does not restore interrupts like task_rq_unlock,&n; * you need to do so manually after calling.&n; */
DECL|function|double_rq_unlock
r_static
r_inline
r_void
id|double_rq_unlock
c_func
(paren
id|runqueue_t
op_star
id|rq1
comma
id|runqueue_t
op_star
id|rq2
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|rq1-&gt;lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq1
op_ne
id|rq2
)paren
id|spin_unlock
c_func
(paren
op_amp
id|rq2-&gt;lock
)paren
suffix:semicolon
)brace
macro_line|#ifdef CONFIG_NUMA
multiline_comment|/*&n; * If dest_cpu is allowed for this process, migrate the task to it.&n; * This is accomplished by forcing the cpu_allowed mask to only&n; * allow dest_cpu, which will force the cpu onto dest_cpu.  Then&n; * the cpu_allowed mask is restored.&n; */
DECL|function|sched_migrate_task
r_static
r_void
id|sched_migrate_task
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
id|dest_cpu
)paren
(brace
r_int
r_int
id|old_mask
suffix:semicolon
id|old_mask
op_assign
id|p-&gt;cpus_allowed
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
(paren
id|old_mask
op_amp
(paren
l_int|1UL
op_lshift
id|dest_cpu
)paren
)paren
)paren
r_return
suffix:semicolon
multiline_comment|/* force the process onto the specified CPU */
id|set_cpus_allowed
c_func
(paren
id|p
comma
l_int|1UL
op_lshift
id|dest_cpu
)paren
suffix:semicolon
multiline_comment|/* restore the cpus allowed mask */
id|set_cpus_allowed
c_func
(paren
id|p
comma
id|old_mask
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Find the least loaded CPU.  Slightly favor the current CPU by&n; * setting its runqueue length as the minimum to start.&n; */
DECL|function|sched_best_cpu
r_static
r_int
id|sched_best_cpu
c_func
(paren
r_struct
id|task_struct
op_star
id|p
)paren
(brace
r_int
id|i
comma
id|minload
comma
id|load
comma
id|best_cpu
comma
id|node
op_assign
l_int|0
suffix:semicolon
r_int
r_int
id|cpumask
suffix:semicolon
id|best_cpu
op_assign
id|task_cpu
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_rq
c_func
(paren
id|best_cpu
)paren
op_member_access_from_pointer
id|nr_running
op_le
l_int|2
)paren
r_return
id|best_cpu
suffix:semicolon
id|minload
op_assign
l_int|10000000
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|numnodes
suffix:semicolon
id|i
op_increment
)paren
(brace
id|load
op_assign
id|atomic_read
c_func
(paren
op_amp
id|node_nr_running
(braket
id|i
)braket
)paren
suffix:semicolon
r_if
c_cond
(paren
id|load
OL
id|minload
)paren
(brace
id|minload
op_assign
id|load
suffix:semicolon
id|node
op_assign
id|i
suffix:semicolon
)brace
)brace
id|minload
op_assign
l_int|10000000
suffix:semicolon
id|cpumask
op_assign
id|node_to_cpumask
c_func
(paren
id|node
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
op_increment
id|i
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|cpumask
op_amp
(paren
l_int|1UL
op_lshift
id|i
)paren
)paren
)paren
r_continue
suffix:semicolon
r_if
c_cond
(paren
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_running
OL
id|minload
)paren
(brace
id|best_cpu
op_assign
id|i
suffix:semicolon
id|minload
op_assign
id|cpu_rq
c_func
(paren
id|i
)paren
op_member_access_from_pointer
id|nr_running
suffix:semicolon
)brace
)brace
r_return
id|best_cpu
suffix:semicolon
)brace
DECL|function|sched_balance_exec
r_void
id|sched_balance_exec
c_func
(paren
r_void
)paren
(brace
r_int
id|new_cpu
suffix:semicolon
r_if
c_cond
(paren
id|numnodes
OG
l_int|1
)paren
(brace
id|new_cpu
op_assign
id|sched_best_cpu
c_func
(paren
id|current
)paren
suffix:semicolon
r_if
c_cond
(paren
id|new_cpu
op_ne
id|smp_processor_id
c_func
(paren
)paren
)paren
id|sched_migrate_task
c_func
(paren
id|current
comma
id|new_cpu
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * Find the busiest node. All previous node loads contribute with a&n; * geometrically deccaying weight to the load measure:&n; *      load_{t} = load_{t-1}/2 + nr_node_running_{t}&n; * This way sudden load peaks are flattened out a bit.&n; */
DECL|function|find_busiest_node
r_static
r_int
id|find_busiest_node
c_func
(paren
r_int
id|this_node
)paren
(brace
r_int
id|i
comma
id|node
op_assign
op_minus
l_int|1
comma
id|load
comma
id|this_load
comma
id|maxload
suffix:semicolon
id|this_load
op_assign
id|maxload
op_assign
(paren
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|prev_node_load
(braket
id|this_node
)braket
op_rshift
l_int|1
)paren
op_plus
id|atomic_read
c_func
(paren
op_amp
id|node_nr_running
(braket
id|this_node
)braket
)paren
suffix:semicolon
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|prev_node_load
(braket
id|this_node
)braket
op_assign
id|this_load
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|numnodes
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
id|i
op_eq
id|this_node
)paren
r_continue
suffix:semicolon
id|load
op_assign
(paren
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|prev_node_load
(braket
id|i
)braket
op_rshift
l_int|1
)paren
op_plus
id|atomic_read
c_func
(paren
op_amp
id|node_nr_running
(braket
id|i
)braket
)paren
suffix:semicolon
id|this_rq
c_func
(paren
)paren
op_member_access_from_pointer
id|prev_node_load
(braket
id|i
)braket
op_assign
id|load
suffix:semicolon
r_if
c_cond
(paren
id|load
OG
id|maxload
op_logical_and
(paren
l_int|100
op_star
id|load
OG
id|NODE_THRESHOLD
op_star
id|this_load
)paren
)paren
(brace
id|maxload
op_assign
id|load
suffix:semicolon
id|node
op_assign
id|i
suffix:semicolon
)brace
)brace
r_return
id|node
suffix:semicolon
)brace
macro_line|#endif /* CONFIG_NUMA */
macro_line|#if CONFIG_SMP
multiline_comment|/*&n; * double_lock_balance - lock the busiest runqueue&n; *&n; * this_rq is locked already. Recalculate nr_running if we have to&n; * drop the runqueue lock.&n; */
DECL|function|double_lock_balance
r_static
r_inline
r_int
r_int
id|double_lock_balance
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
id|runqueue_t
op_star
id|busiest
comma
r_int
id|this_cpu
comma
r_int
id|idle
comma
r_int
r_int
id|nr_running
)paren
(brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|spin_trylock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
)paren
)paren
(brace
r_if
c_cond
(paren
id|busiest
OL
id|this_rq
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
multiline_comment|/* Need to recalculate nr_running */
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|this_rq-&gt;nr_running
OG
id|this_rq-&gt;prev_cpu_load
(braket
id|this_cpu
)braket
)paren
)paren
id|nr_running
op_assign
id|this_rq-&gt;nr_running
suffix:semicolon
r_else
id|nr_running
op_assign
id|this_rq-&gt;prev_cpu_load
(braket
id|this_cpu
)braket
suffix:semicolon
)brace
r_else
id|spin_lock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
)brace
r_return
id|nr_running
suffix:semicolon
)brace
multiline_comment|/*&n; * find_busiest_queue - find the busiest runqueue among the cpus in cpumask.&n; */
DECL|function|find_busiest_queue
r_static
r_inline
id|runqueue_t
op_star
id|find_busiest_queue
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|this_cpu
comma
r_int
id|idle
comma
r_int
op_star
id|imbalance
comma
r_int
r_int
id|cpumask
)paren
(brace
r_int
id|nr_running
comma
id|load
comma
id|max_load
comma
id|i
suffix:semicolon
id|runqueue_t
op_star
id|busiest
comma
op_star
id|rq_src
suffix:semicolon
multiline_comment|/*&n;&t; * We search all runqueues to find the most busy one.&n;&t; * We do this lockless to reduce cache-bouncing overhead,&n;&t; * we re-check the &squot;best&squot; source CPU later on again, with&n;&t; * the lock held.&n;&t; *&n;&t; * We fend off statistical fluctuations in runqueue lengths by&n;&t; * saving the runqueue length during the previous load-balancing&n;&t; * operation and using the smaller one the current and saved lengths.&n;&t; * If a runqueue is long enough for a longer amount of time then&n;&t; * we recognize it and pull tasks from it.&n;&t; *&n;&t; * The &squot;current runqueue length&squot; is a statistical maximum variable,&n;&t; * for that one we take the longer one - to avoid fluctuations in&n;&t; * the other direction. So for a load-balance to happen it needs&n;&t; * stable long runqueue on the target CPU and stable short runqueue&n;&t; * on the local runqueue.&n;&t; *&n;&t; * We make an exception if this CPU is about to become idle - in&n;&t; * that case we are less picky about moving a task across CPUs and&n;&t; * take what can be taken.&n;&t; */
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|this_rq-&gt;nr_running
OG
id|this_rq-&gt;prev_cpu_load
(braket
id|this_cpu
)braket
)paren
)paren
id|nr_running
op_assign
id|this_rq-&gt;nr_running
suffix:semicolon
r_else
id|nr_running
op_assign
id|this_rq-&gt;prev_cpu_load
(braket
id|this_cpu
)braket
suffix:semicolon
id|busiest
op_assign
l_int|NULL
suffix:semicolon
id|max_load
op_assign
l_int|1
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
(paren
l_int|1UL
op_lshift
id|i
)paren
op_amp
id|cpumask
)paren
)paren
r_continue
suffix:semicolon
id|rq_src
op_assign
id|cpu_rq
c_func
(paren
id|i
)paren
suffix:semicolon
r_if
c_cond
(paren
id|idle
op_logical_or
(paren
id|rq_src-&gt;nr_running
OL
id|this_rq-&gt;prev_cpu_load
(braket
id|i
)braket
)paren
)paren
id|load
op_assign
id|rq_src-&gt;nr_running
suffix:semicolon
r_else
id|load
op_assign
id|this_rq-&gt;prev_cpu_load
(braket
id|i
)braket
suffix:semicolon
id|this_rq-&gt;prev_cpu_load
(braket
id|i
)braket
op_assign
id|rq_src-&gt;nr_running
suffix:semicolon
r_if
c_cond
(paren
(paren
id|load
OG
id|max_load
)paren
op_logical_and
(paren
id|rq_src
op_ne
id|this_rq
)paren
)paren
(brace
id|busiest
op_assign
id|rq_src
suffix:semicolon
id|max_load
op_assign
id|load
suffix:semicolon
)brace
)brace
r_if
c_cond
(paren
id|likely
c_func
(paren
op_logical_neg
id|busiest
)paren
)paren
r_goto
id|out
suffix:semicolon
op_star
id|imbalance
op_assign
(paren
id|max_load
op_minus
id|nr_running
)paren
op_div
l_int|2
suffix:semicolon
multiline_comment|/* It needs an at least ~25% imbalance to trigger balancing. */
r_if
c_cond
(paren
op_logical_neg
id|idle
op_logical_and
(paren
op_star
id|imbalance
OL
(paren
id|max_load
op_plus
l_int|3
)paren
op_div
l_int|4
)paren
)paren
(brace
id|busiest
op_assign
l_int|NULL
suffix:semicolon
r_goto
id|out
suffix:semicolon
)brace
id|nr_running
op_assign
id|double_lock_balance
c_func
(paren
id|this_rq
comma
id|busiest
comma
id|this_cpu
comma
id|idle
comma
id|nr_running
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Make sure nothing changed since we checked the&n;&t; * runqueue length.&n;&t; */
r_if
c_cond
(paren
id|busiest-&gt;nr_running
op_le
id|nr_running
op_plus
l_int|1
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
id|busiest
op_assign
l_int|NULL
suffix:semicolon
)brace
id|out
suffix:colon
r_return
id|busiest
suffix:semicolon
)brace
multiline_comment|/*&n; * pull_task - move a task from a remote runqueue to the local runqueue.&n; * Both runqueues must be locked.&n; */
DECL|function|pull_task
r_static
r_inline
r_void
id|pull_task
c_func
(paren
id|runqueue_t
op_star
id|src_rq
comma
id|prio_array_t
op_star
id|src_array
comma
id|task_t
op_star
id|p
comma
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|this_cpu
)paren
(brace
id|dequeue_task
c_func
(paren
id|p
comma
id|src_array
)paren
suffix:semicolon
id|nr_running_dec
c_func
(paren
id|src_rq
)paren
suffix:semicolon
id|set_task_cpu
c_func
(paren
id|p
comma
id|this_cpu
)paren
suffix:semicolon
id|nr_running_inc
c_func
(paren
id|this_rq
)paren
suffix:semicolon
id|enqueue_task
c_func
(paren
id|p
comma
id|this_rq-&gt;active
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Note that idle threads have a prio of MAX_PRIO, for this test&n;&t; * to be always true for them.&n;&t; */
r_if
c_cond
(paren
id|p-&gt;prio
OL
id|this_rq-&gt;curr-&gt;prio
)paren
id|set_need_resched
c_func
(paren
)paren
suffix:semicolon
r_else
(brace
r_if
c_cond
(paren
id|p-&gt;prio
op_eq
id|this_rq-&gt;curr-&gt;prio
op_logical_and
id|p-&gt;time_slice
OG
id|this_rq-&gt;curr-&gt;time_slice
)paren
id|set_need_resched
c_func
(paren
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * Current runqueue is empty, or rebalance tick: if there is an&n; * inbalance (current runqueue is too short) then pull from&n; * busiest runqueue(s).&n; *&n; * We call this with the current runqueue locked,&n; * irqs disabled.&n; */
DECL|function|load_balance
r_static
r_void
id|load_balance
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|idle
comma
r_int
r_int
id|cpumask
)paren
(brace
r_int
id|imbalance
comma
id|idx
comma
id|this_cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|runqueue_t
op_star
id|busiest
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
r_struct
id|list_head
op_star
id|head
comma
op_star
id|curr
suffix:semicolon
id|task_t
op_star
id|tmp
suffix:semicolon
id|busiest
op_assign
id|find_busiest_queue
c_func
(paren
id|this_rq
comma
id|this_cpu
comma
id|idle
comma
op_amp
id|imbalance
comma
id|cpumask
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|busiest
)paren
r_goto
id|out
suffix:semicolon
multiline_comment|/*&n;&t; * We first consider expired tasks. Those will likely not be&n;&t; * executed in the near future, and they are most likely to&n;&t; * be cache-cold, thus switching CPUs has the least effect&n;&t; * on them.&n;&t; */
r_if
c_cond
(paren
id|busiest-&gt;expired-&gt;nr_active
)paren
id|array
op_assign
id|busiest-&gt;expired
suffix:semicolon
r_else
id|array
op_assign
id|busiest-&gt;active
suffix:semicolon
id|new_array
suffix:colon
multiline_comment|/* Start searching at priority 0: */
id|idx
op_assign
l_int|0
suffix:semicolon
id|skip_bitmap
suffix:colon
r_if
c_cond
(paren
op_logical_neg
id|idx
)paren
id|idx
op_assign
id|sched_find_first_bit
c_func
(paren
id|array-&gt;bitmap
)paren
suffix:semicolon
r_else
id|idx
op_assign
id|find_next_bit
c_func
(paren
id|array-&gt;bitmap
comma
id|MAX_PRIO
comma
id|idx
)paren
suffix:semicolon
r_if
c_cond
(paren
id|idx
op_ge
id|MAX_PRIO
)paren
(brace
r_if
c_cond
(paren
id|array
op_eq
id|busiest-&gt;expired
)paren
(brace
id|array
op_assign
id|busiest-&gt;active
suffix:semicolon
r_goto
id|new_array
suffix:semicolon
)brace
r_goto
id|out_unlock
suffix:semicolon
)brace
id|head
op_assign
id|array-&gt;queue
op_plus
id|idx
suffix:semicolon
id|curr
op_assign
id|head-&gt;prev
suffix:semicolon
id|skip_queue
suffix:colon
id|tmp
op_assign
id|list_entry
c_func
(paren
id|curr
comma
id|task_t
comma
id|run_list
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We do not migrate tasks that are:&n;&t; * 1) running (obviously), or&n;&t; * 2) cannot be migrated to this CPU due to cpus_allowed, or&n;&t; * 3) are cache-hot on their current CPU.&n;&t; */
DECL|macro|CAN_MIGRATE_TASK
mdefine_line|#define CAN_MIGRATE_TASK(p,rq,this_cpu)&t;&t;&t;&t;&t;&bslash;&n;&t;((jiffies - (p)-&gt;last_run &gt; cache_decay_ticks) &amp;&amp;&t;&bslash;&n;&t;&t;!task_running(rq, p) &amp;&amp;&t;&t;&t;&t;&t;&bslash;&n;&t;&t;&t;((p)-&gt;cpus_allowed &amp; (1UL &lt;&lt; (this_cpu))))
id|curr
op_assign
id|curr-&gt;prev
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|CAN_MIGRATE_TASK
c_func
(paren
id|tmp
comma
id|busiest
comma
id|this_cpu
)paren
)paren
(brace
r_if
c_cond
(paren
id|curr
op_ne
id|head
)paren
r_goto
id|skip_queue
suffix:semicolon
id|idx
op_increment
suffix:semicolon
r_goto
id|skip_bitmap
suffix:semicolon
)brace
id|pull_task
c_func
(paren
id|busiest
comma
id|array
comma
id|tmp
comma
id|this_rq
comma
id|this_cpu
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|idle
op_logical_and
op_decrement
id|imbalance
)paren
(brace
r_if
c_cond
(paren
id|curr
op_ne
id|head
)paren
r_goto
id|skip_queue
suffix:semicolon
id|idx
op_increment
suffix:semicolon
r_goto
id|skip_bitmap
suffix:semicolon
)brace
id|out_unlock
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|busiest-&gt;lock
)paren
suffix:semicolon
id|out
suffix:colon
suffix:semicolon
)brace
multiline_comment|/*&n; * One of the idle_cpu_tick() and busy_cpu_tick() functions will&n; * get called every timer tick, on every CPU. Our balancing action&n; * frequency and balancing agressivity depends on whether the CPU is&n; * idle or not.&n; *&n; * busy-rebalance every 200 msecs. idle-rebalance every 1 msec. (or on&n; * systems with HZ=100, every 10 msecs.)&n; *&n; * On NUMA, do a node-rebalance every 400 msecs.&n; */
DECL|macro|IDLE_REBALANCE_TICK
mdefine_line|#define IDLE_REBALANCE_TICK (HZ/1000 ?: 1)
DECL|macro|BUSY_REBALANCE_TICK
mdefine_line|#define BUSY_REBALANCE_TICK (HZ/5 ?: 1)
DECL|macro|IDLE_NODE_REBALANCE_TICK
mdefine_line|#define IDLE_NODE_REBALANCE_TICK (IDLE_REBALANCE_TICK * 5)
DECL|macro|BUSY_NODE_REBALANCE_TICK
mdefine_line|#define BUSY_NODE_REBALANCE_TICK (BUSY_REBALANCE_TICK * 100)
macro_line|#ifdef CONFIG_NUMA
DECL|function|balance_node
r_static
r_void
id|balance_node
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|idle
comma
r_int
id|this_cpu
)paren
(brace
r_int
id|node
op_assign
id|find_busiest_node
c_func
(paren
id|cpu_to_node
c_func
(paren
id|this_cpu
)paren
)paren
suffix:semicolon
r_int
r_int
id|cpumask
comma
id|this_cpumask
op_assign
l_int|1UL
op_lshift
id|this_cpu
suffix:semicolon
r_if
c_cond
(paren
id|node
op_ge
l_int|0
)paren
(brace
id|cpumask
op_assign
id|node_to_cpumask
c_func
(paren
id|node
)paren
op_or
id|this_cpumask
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
id|load_balance
c_func
(paren
id|this_rq
comma
id|idle
comma
id|cpumask
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
)brace
)brace
macro_line|#endif
DECL|function|rebalance_tick
r_static
r_void
id|rebalance_tick
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|idle
)paren
(brace
macro_line|#ifdef CONFIG_NUMA
r_int
id|this_cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
r_int
r_int
id|j
op_assign
id|jiffies
suffix:semicolon
multiline_comment|/*&n;&t; * First do inter-node rebalancing, then intra-node rebalancing,&n;&t; * if both events happen in the same tick. The inter-node&n;&t; * rebalancing does not necessarily have to create a perfect&n;&t; * balance within the node, since we load-balance the most loaded&n;&t; * node with the current CPU. (ie. other CPUs in the local node&n;&t; * are not balanced.)&n;&t; */
r_if
c_cond
(paren
id|idle
)paren
(brace
macro_line|#ifdef CONFIG_NUMA
r_if
c_cond
(paren
op_logical_neg
(paren
id|j
op_mod
id|IDLE_NODE_REBALANCE_TICK
)paren
)paren
id|balance_node
c_func
(paren
id|this_rq
comma
id|idle
comma
id|this_cpu
)paren
suffix:semicolon
macro_line|#endif
r_if
c_cond
(paren
op_logical_neg
(paren
id|j
op_mod
id|IDLE_REBALANCE_TICK
)paren
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
id|load_balance
c_func
(paren
id|this_rq
comma
l_int|0
comma
id|cpu_to_node_mask
c_func
(paren
id|this_cpu
)paren
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
)brace
r_return
suffix:semicolon
)brace
macro_line|#ifdef CONFIG_NUMA
r_if
c_cond
(paren
op_logical_neg
(paren
id|j
op_mod
id|BUSY_NODE_REBALANCE_TICK
)paren
)paren
id|balance_node
c_func
(paren
id|this_rq
comma
id|idle
comma
id|this_cpu
)paren
suffix:semicolon
macro_line|#endif
r_if
c_cond
(paren
op_logical_neg
(paren
id|j
op_mod
id|BUSY_REBALANCE_TICK
)paren
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
id|load_balance
c_func
(paren
id|this_rq
comma
id|idle
comma
id|cpu_to_node_mask
c_func
(paren
id|this_cpu
)paren
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|this_rq-&gt;lock
)paren
suffix:semicolon
)brace
)brace
macro_line|#else
multiline_comment|/*&n; * on UP we do not need to balance between CPUs:&n; */
DECL|function|rebalance_tick
r_static
r_inline
r_void
id|rebalance_tick
c_func
(paren
id|runqueue_t
op_star
id|this_rq
comma
r_int
id|idle
)paren
(brace
)brace
macro_line|#endif
id|DEFINE_PER_CPU
c_func
(paren
r_struct
id|kernel_stat
comma
id|kstat
)paren
op_assign
(brace
(brace
l_int|0
)brace
)brace
suffix:semicolon
multiline_comment|/*&n; * We place interactive tasks back into the active array, if possible.&n; *&n; * To guarantee that this does not starve expired tasks we ignore the&n; * interactivity of a task if the first expired task had to wait more&n; * than a &squot;reasonable&squot; amount of time. This deadline timeout is&n; * load-dependent, as the frequency of array switched decreases with&n; * increasing number of running tasks:&n; */
DECL|macro|EXPIRED_STARVING
mdefine_line|#define EXPIRED_STARVING(rq) &bslash;&n;&t;&t;(STARVATION_LIMIT &amp;&amp; ((rq)-&gt;expired_timestamp &amp;&amp; &bslash;&n;&t;&t;(jiffies - (rq)-&gt;expired_timestamp &gt;= &bslash;&n;&t;&t;&t;STARVATION_LIMIT * ((rq)-&gt;nr_running) + 1)))
multiline_comment|/*&n; * This function gets called by the timer code, with HZ frequency.&n; * We call it with interrupts disabled.&n; *&n; * It also gets called by the fork code, when changing the parent&squot;s&n; * timeslices.&n; */
DECL|function|scheduler_tick
r_void
id|scheduler_tick
c_func
(paren
r_int
id|user_ticks
comma
r_int
id|sys_ticks
)paren
(brace
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
id|runqueue_t
op_star
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|task_t
op_star
id|p
op_assign
id|current
suffix:semicolon
r_if
c_cond
(paren
id|rcu_pending
c_func
(paren
id|cpu
)paren
)paren
id|rcu_check_callbacks
c_func
(paren
id|cpu
comma
id|user_ticks
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p
op_eq
id|rq-&gt;idle
)paren
(brace
multiline_comment|/* note: this timer irq context must be accounted for as well */
r_if
c_cond
(paren
id|irq_count
c_func
(paren
)paren
op_minus
id|HARDIRQ_OFFSET
op_ge
id|SOFTIRQ_OFFSET
)paren
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.system
op_add_assign
id|sys_ticks
suffix:semicolon
r_else
r_if
c_cond
(paren
id|atomic_read
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
)paren
OG
l_int|0
)paren
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.iowait
op_add_assign
id|sys_ticks
suffix:semicolon
r_else
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.idle
op_add_assign
id|sys_ticks
suffix:semicolon
id|rebalance_tick
c_func
(paren
id|rq
comma
l_int|1
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
r_if
c_cond
(paren
id|TASK_NICE
c_func
(paren
id|p
)paren
OG
l_int|0
)paren
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.nice
op_add_assign
id|user_ticks
suffix:semicolon
r_else
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.user
op_add_assign
id|user_ticks
suffix:semicolon
id|kstat_cpu
c_func
(paren
id|cpu
)paren
dot
id|cpustat.system
op_add_assign
id|sys_ticks
suffix:semicolon
multiline_comment|/* Task might have expired already, but not scheduled off yet */
r_if
c_cond
(paren
id|p-&gt;array
op_ne
id|rq-&gt;active
)paren
(brace
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|spin_lock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The task was running during this tick - update the&n;&t; * time slice counter and the sleep average. Note: we&n;&t; * do not update a thread&squot;s priority until it either&n;&t; * goes to sleep or uses up its timeslice. This makes&n;&t; * it possible for interactive tasks to use up their&n;&t; * timeslices at their highest priority levels.&n;&t; */
r_if
c_cond
(paren
id|p-&gt;sleep_avg
)paren
id|p-&gt;sleep_avg
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|rt_task
c_func
(paren
id|p
)paren
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * RR tasks need a special form of timeslice management.&n;&t;&t; * FIFO tasks have no timeslices.&n;&t;&t; */
r_if
c_cond
(paren
(paren
id|p-&gt;policy
op_eq
id|SCHED_RR
)paren
op_logical_and
op_logical_neg
op_decrement
id|p-&gt;time_slice
)paren
(brace
id|p-&gt;time_slice
op_assign
id|task_timeslice
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;first_time_slice
op_assign
l_int|0
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
multiline_comment|/* put it at the end of the queue: */
id|dequeue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
)brace
r_goto
id|out
suffix:semicolon
)brace
r_if
c_cond
(paren
op_logical_neg
op_decrement
id|p-&gt;time_slice
)paren
(brace
id|dequeue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;prio
op_assign
id|effective_prio
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;time_slice
op_assign
id|task_timeslice
c_func
(paren
id|p
)paren
suffix:semicolon
id|p-&gt;first_time_slice
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|TASK_INTERACTIVE
c_func
(paren
id|p
)paren
op_logical_or
id|EXPIRED_STARVING
c_func
(paren
id|rq
)paren
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;expired_timestamp
)paren
id|rq-&gt;expired_timestamp
op_assign
id|jiffies
suffix:semicolon
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;expired
)paren
suffix:semicolon
)brace
r_else
id|enqueue_task
c_func
(paren
id|p
comma
id|rq-&gt;active
)paren
suffix:semicolon
)brace
id|out
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|rebalance_tick
c_func
(paren
id|rq
comma
l_int|0
)paren
suffix:semicolon
)brace
DECL|function|scheduling_functions_start_here
r_void
id|scheduling_functions_start_here
c_func
(paren
r_void
)paren
(brace
)brace
multiline_comment|/*&n; * schedule() is the main scheduler function.&n; */
DECL|function|schedule
id|asmlinkage
r_void
id|schedule
c_func
(paren
r_void
)paren
(brace
id|task_t
op_star
id|prev
comma
op_star
id|next
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
r_struct
id|list_head
op_star
id|queue
suffix:semicolon
r_int
id|idx
suffix:semicolon
multiline_comment|/*&n;&t; * Test if we are atomic.  Since do_exit() needs to call into&n;&t; * schedule() atomically, we ignore that path for now.&n;&t; * Otherwise, whine if we are scheduling when we should not be.&n;&t; */
r_if
c_cond
(paren
id|likely
c_func
(paren
op_logical_neg
(paren
id|current-&gt;state
op_amp
(paren
id|TASK_DEAD
op_or
id|TASK_ZOMBIE
)paren
)paren
)paren
)paren
(brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|in_atomic
c_func
(paren
)paren
)paren
)paren
(brace
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;bad: scheduling while atomic!&bslash;n&quot;
)paren
suffix:semicolon
id|dump_stack
c_func
(paren
)paren
suffix:semicolon
)brace
)brace
id|check_highmem_ptes
c_func
(paren
)paren
suffix:semicolon
id|need_resched
suffix:colon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
id|prev
op_assign
id|current
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|release_kernel_lock
c_func
(paren
id|prev
)paren
suffix:semicolon
id|prev-&gt;last_run
op_assign
id|jiffies
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * if entering off of a kernel preemption go straight&n;&t; * to picking the next task.&n;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|preempt_count
c_func
(paren
)paren
op_amp
id|PREEMPT_ACTIVE
)paren
)paren
r_goto
id|pick_next_task
suffix:semicolon
r_switch
c_cond
(paren
id|prev-&gt;state
)paren
(brace
r_case
id|TASK_INTERRUPTIBLE
suffix:colon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|signal_pending
c_func
(paren
id|prev
)paren
)paren
)paren
(brace
id|prev-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
r_break
suffix:semicolon
)brace
r_default
suffix:colon
id|deactivate_task
c_func
(paren
id|prev
comma
id|rq
)paren
suffix:semicolon
r_case
id|TASK_RUNNING
suffix:colon
suffix:semicolon
)brace
id|pick_next_task
suffix:colon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|rq-&gt;nr_running
)paren
)paren
(brace
macro_line|#if CONFIG_SMP
id|load_balance
c_func
(paren
id|rq
comma
l_int|1
comma
id|cpu_to_node_mask
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;nr_running
)paren
r_goto
id|pick_next_task
suffix:semicolon
macro_line|#endif
id|next
op_assign
id|rq-&gt;idle
suffix:semicolon
id|rq-&gt;expired_timestamp
op_assign
l_int|0
suffix:semicolon
r_goto
id|switch_tasks
suffix:semicolon
)brace
id|array
op_assign
id|rq-&gt;active
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|array-&gt;nr_active
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * Switch the active and expired arrays.&n;&t;&t; */
id|rq-&gt;active
op_assign
id|rq-&gt;expired
suffix:semicolon
id|rq-&gt;expired
op_assign
id|array
suffix:semicolon
id|array
op_assign
id|rq-&gt;active
suffix:semicolon
id|rq-&gt;expired_timestamp
op_assign
l_int|0
suffix:semicolon
)brace
id|idx
op_assign
id|sched_find_first_bit
c_func
(paren
id|array-&gt;bitmap
)paren
suffix:semicolon
id|queue
op_assign
id|array-&gt;queue
op_plus
id|idx
suffix:semicolon
id|next
op_assign
id|list_entry
c_func
(paren
id|queue-&gt;next
comma
id|task_t
comma
id|run_list
)paren
suffix:semicolon
id|switch_tasks
suffix:colon
id|prefetch
c_func
(paren
id|next
)paren
suffix:semicolon
id|clear_tsk_need_resched
c_func
(paren
id|prev
)paren
suffix:semicolon
id|RCU_qsctr
c_func
(paren
id|prev-&gt;thread_info-&gt;cpu
)paren
op_increment
suffix:semicolon
r_if
c_cond
(paren
id|likely
c_func
(paren
id|prev
op_ne
id|next
)paren
)paren
(brace
id|rq-&gt;nr_switches
op_increment
suffix:semicolon
id|rq-&gt;curr
op_assign
id|next
suffix:semicolon
id|prepare_arch_switch
c_func
(paren
id|rq
comma
id|next
)paren
suffix:semicolon
id|prev
op_assign
id|context_switch
c_func
(paren
id|rq
comma
id|prev
comma
id|next
)paren
suffix:semicolon
id|barrier
c_func
(paren
)paren
suffix:semicolon
id|finish_task_switch
c_func
(paren
id|prev
)paren
suffix:semicolon
)brace
r_else
id|spin_unlock_irq
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|reacquire_kernel_lock
c_func
(paren
id|current
)paren
suffix:semicolon
id|preempt_enable_no_resched
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|test_thread_flag
c_func
(paren
id|TIF_NEED_RESCHED
)paren
)paren
r_goto
id|need_resched
suffix:semicolon
)brace
macro_line|#ifdef CONFIG_PREEMPT
multiline_comment|/*&n; * this is is the entry point to schedule() from in-kernel preemption&n; * off of preempt_enable.  Kernel preemptions off return from interrupt&n; * occur there and call schedule directly.&n; */
DECL|function|preempt_schedule
id|asmlinkage
r_void
id|preempt_schedule
c_func
(paren
r_void
)paren
(brace
r_struct
id|thread_info
op_star
id|ti
op_assign
id|current_thread_info
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * If there is a non-zero preempt_count or interrupts are disabled,&n;&t; * we do not want to preempt the current task.  Just return..&n;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|ti-&gt;preempt_count
op_logical_or
id|irqs_disabled
c_func
(paren
)paren
)paren
)paren
r_return
suffix:semicolon
id|need_resched
suffix:colon
id|ti-&gt;preempt_count
op_assign
id|PREEMPT_ACTIVE
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|ti-&gt;preempt_count
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* we could miss a preemption opportunity between schedule and now */
id|barrier
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|test_thread_flag
c_func
(paren
id|TIF_NEED_RESCHED
)paren
)paren
)paren
r_goto
id|need_resched
suffix:semicolon
)brace
macro_line|#endif /* CONFIG_PREEMPT */
DECL|function|default_wake_function
r_int
id|default_wake_function
c_func
(paren
id|wait_queue_t
op_star
id|curr
comma
r_int
id|mode
comma
r_int
id|sync
)paren
(brace
id|task_t
op_star
id|p
op_assign
id|curr-&gt;task
suffix:semicolon
r_return
id|try_to_wake_up
c_func
(paren
id|p
comma
id|mode
comma
id|sync
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * The core wakeup function.  Non-exclusive wakeups (nr_exclusive == 0) just&n; * wake everything up.  If it&squot;s an exclusive wakeup (nr_exclusive == small +ve&n; * number) then we wake all the non-exclusive tasks and one exclusive task.&n; *&n; * There are circumstances in which we can try to wake a task which has already&n; * started to run but is not in state TASK_RUNNING.  try_to_wake_up() returns&n; * zero in this (rare) case, and we handle it by continuing to scan the queue.&n; */
DECL|function|__wake_up_common
r_static
r_void
id|__wake_up_common
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
comma
r_int
id|nr_exclusive
comma
r_int
id|sync
)paren
(brace
r_struct
id|list_head
op_star
id|tmp
comma
op_star
id|next
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|tmp
comma
id|next
comma
op_amp
id|q-&gt;task_list
)paren
(brace
id|wait_queue_t
op_star
id|curr
suffix:semicolon
r_int
id|flags
suffix:semicolon
id|curr
op_assign
id|list_entry
c_func
(paren
id|tmp
comma
id|wait_queue_t
comma
id|task_list
)paren
suffix:semicolon
id|flags
op_assign
id|curr-&gt;flags
suffix:semicolon
r_if
c_cond
(paren
id|curr
op_member_access_from_pointer
id|func
c_func
(paren
id|curr
comma
id|mode
comma
id|sync
)paren
op_logical_and
(paren
id|flags
op_amp
id|WQ_FLAG_EXCLUSIVE
)paren
op_logical_and
op_logical_neg
op_decrement
id|nr_exclusive
)paren
r_break
suffix:semicolon
)brace
)brace
multiline_comment|/**&n; * __wake_up - wake up threads blocked on a waitqueue.&n; * @q: the waitqueue&n; * @mode: which threads&n; * @nr_exclusive: how many wake-one or wake-many threads to wake up&n; */
DECL|function|__wake_up
r_void
id|__wake_up
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
comma
r_int
id|nr_exclusive
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|q
)paren
)paren
r_return
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|__wake_up_common
c_func
(paren
id|q
comma
id|mode
comma
id|nr_exclusive
comma
l_int|0
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Same as __wake_up but called with the spinlock in wait_queue_head_t held.&n; */
DECL|function|__wake_up_locked
r_void
id|__wake_up_locked
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
)paren
(brace
id|__wake_up_common
c_func
(paren
id|q
comma
id|mode
comma
l_int|1
comma
l_int|0
)paren
suffix:semicolon
)brace
macro_line|#if CONFIG_SMP
multiline_comment|/**&n; * __wake_up - sync- wake up threads blocked on a waitqueue.&n; * @q: the waitqueue&n; * @mode: which threads&n; * @nr_exclusive: how many wake-one or wake-many threads to wake up&n; *&n; * The sync wakeup differs that the waker knows that it will schedule&n; * away soon, so while the target thread will be woken up, it will not&n; * be migrated to another CPU - ie. the two threads are &squot;synchronized&squot;&n; * with each other. This can prevent needless bouncing between CPUs.&n; */
DECL|function|__wake_up_sync
r_void
id|__wake_up_sync
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
r_int
id|mode
comma
r_int
id|nr_exclusive
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|q
)paren
)paren
r_return
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|likely
c_func
(paren
id|nr_exclusive
)paren
)paren
id|__wake_up_common
c_func
(paren
id|q
comma
id|mode
comma
id|nr_exclusive
comma
l_int|1
)paren
suffix:semicolon
r_else
id|__wake_up_common
c_func
(paren
id|q
comma
id|mode
comma
id|nr_exclusive
comma
l_int|0
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|q-&gt;lock
comma
id|flags
)paren
suffix:semicolon
)brace
macro_line|#endif
DECL|function|complete
r_void
id|complete
c_func
(paren
r_struct
id|completion
op_star
id|x
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
id|x-&gt;done
op_increment
suffix:semicolon
id|__wake_up_common
c_func
(paren
op_amp
id|x-&gt;wait
comma
id|TASK_UNINTERRUPTIBLE
op_or
id|TASK_INTERRUPTIBLE
comma
l_int|1
comma
l_int|0
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|function|complete_all
r_void
id|complete_all
c_func
(paren
r_struct
id|completion
op_star
id|x
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
id|x-&gt;done
op_add_assign
id|UINT_MAX
op_div
l_int|2
suffix:semicolon
id|__wake_up_common
c_func
(paren
op_amp
id|x-&gt;wait
comma
id|TASK_UNINTERRUPTIBLE
op_or
id|TASK_INTERRUPTIBLE
comma
l_int|0
comma
l_int|0
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|x-&gt;wait.lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|function|wait_for_completion
r_void
id|wait_for_completion
c_func
(paren
r_struct
id|completion
op_star
id|x
)paren
(brace
id|might_sleep
c_func
(paren
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|x-&gt;done
)paren
(brace
id|DECLARE_WAITQUEUE
c_func
(paren
id|wait
comma
id|current
)paren
suffix:semicolon
id|wait.flags
op_or_assign
id|WQ_FLAG_EXCLUSIVE
suffix:semicolon
id|__add_wait_queue_tail
c_func
(paren
op_amp
id|x-&gt;wait
comma
op_amp
id|wait
)paren
suffix:semicolon
r_do
(brace
id|__set_current_state
c_func
(paren
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
op_logical_neg
id|x-&gt;done
)paren
suffix:semicolon
id|__remove_wait_queue
c_func
(paren
op_amp
id|x-&gt;wait
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
id|x-&gt;done
op_decrement
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|x-&gt;wait.lock
)paren
suffix:semicolon
)brace
DECL|macro|SLEEP_ON_VAR
mdefine_line|#define&t;SLEEP_ON_VAR&t;&t;&t;&t;&bslash;&n;&t;unsigned long flags;&t;&t;&t;&bslash;&n;&t;wait_queue_t wait;&t;&t;&t;&bslash;&n;&t;init_waitqueue_entry(&amp;wait, current);
DECL|macro|SLEEP_ON_HEAD
mdefine_line|#define SLEEP_ON_HEAD&t;&t;&t;&t;&t;&bslash;&n;&t;spin_lock_irqsave(&amp;q-&gt;lock,flags);&t;&t;&bslash;&n;&t;__add_wait_queue(q, &amp;wait);&t;&t;&t;&bslash;&n;&t;spin_unlock(&amp;q-&gt;lock);
DECL|macro|SLEEP_ON_TAIL
mdefine_line|#define&t;SLEEP_ON_TAIL&t;&t;&t;&t;&t;&t;&bslash;&n;&t;spin_lock_irq(&amp;q-&gt;lock);&t;&t;&t;&t;&bslash;&n;&t;__remove_wait_queue(q, &amp;wait);&t;&t;&t;&t;&bslash;&n;&t;spin_unlock_irqrestore(&amp;q-&gt;lock, flags);
DECL|function|interruptible_sleep_on
r_void
id|interruptible_sleep_on
c_func
(paren
id|wait_queue_head_t
op_star
id|q
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
)brace
DECL|function|interruptible_sleep_on_timeout
r_int
id|interruptible_sleep_on_timeout
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
id|timeout
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|timeout
op_assign
id|schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
r_return
id|timeout
suffix:semicolon
)brace
DECL|function|sleep_on
r_void
id|sleep_on
c_func
(paren
id|wait_queue_head_t
op_star
id|q
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_UNINTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
)brace
DECL|function|sleep_on_timeout
r_int
id|sleep_on_timeout
c_func
(paren
id|wait_queue_head_t
op_star
id|q
comma
r_int
id|timeout
)paren
(brace
id|SLEEP_ON_VAR
id|current-&gt;state
op_assign
id|TASK_UNINTERRUPTIBLE
suffix:semicolon
id|SLEEP_ON_HEAD
id|timeout
op_assign
id|schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|SLEEP_ON_TAIL
r_return
id|timeout
suffix:semicolon
)brace
DECL|function|scheduling_functions_end_here
r_void
id|scheduling_functions_end_here
c_func
(paren
r_void
)paren
(brace
)brace
DECL|function|set_user_nice
r_void
id|set_user_nice
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
id|nice
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_if
c_cond
(paren
id|TASK_NICE
c_func
(paren
id|p
)paren
op_eq
id|nice
op_logical_or
id|nice
template_param
l_int|19
)paren
r_return
suffix:semicolon
multiline_comment|/*&n;&t; * We have to be careful, if called from sys_setpriority(),&n;&t; * the task might be in the middle of scheduling on another CPU.&n;&t; */
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rt_task
c_func
(paren
id|p
)paren
)paren
(brace
id|p-&gt;static_prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
r_goto
id|out_unlock
suffix:semicolon
)brace
id|array
op_assign
id|p-&gt;array
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|dequeue_task
c_func
(paren
id|p
comma
id|array
)paren
suffix:semicolon
id|p-&gt;static_prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
id|p-&gt;prio
op_assign
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
(brace
id|enqueue_task
c_func
(paren
id|p
comma
id|array
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * If the task is running and lowered its priority,&n;&t;&t; * or increased its priority then reschedule its CPU:&n;&t;&t; */
r_if
c_cond
(paren
(paren
id|NICE_TO_PRIO
c_func
(paren
id|nice
)paren
OL
id|p-&gt;static_prio
)paren
op_logical_or
id|task_running
c_func
(paren
id|rq
comma
id|p
)paren
)paren
id|resched_task
c_func
(paren
id|rq-&gt;curr
)paren
suffix:semicolon
)brace
id|out_unlock
suffix:colon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
)brace
macro_line|#ifndef __alpha__
multiline_comment|/*&n; * sys_nice - change the priority of the current process.&n; * @increment: priority increment&n; *&n; * sys_setpriority is a more generic, but much slower function that&n; * does similar things.&n; */
DECL|function|sys_nice
id|asmlinkage
r_int
id|sys_nice
c_func
(paren
r_int
id|increment
)paren
(brace
r_int
id|retval
suffix:semicolon
r_int
id|nice
suffix:semicolon
multiline_comment|/*&n;&t; *&t;Setpriority might change our priority at the same moment.&n;&t; *&t;We don&squot;t have to worry. Conceptually one call occurs first&n;&t; *&t;and we have a single winner.&n;&t; */
r_if
c_cond
(paren
id|increment
OL
l_int|0
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_return
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
id|increment
OL
op_minus
l_int|40
)paren
id|increment
op_assign
op_minus
l_int|40
suffix:semicolon
)brace
r_if
c_cond
(paren
id|increment
OG
l_int|40
)paren
id|increment
op_assign
l_int|40
suffix:semicolon
id|nice
op_assign
id|PRIO_TO_NICE
c_func
(paren
id|current-&gt;static_prio
)paren
op_plus
id|increment
suffix:semicolon
r_if
c_cond
(paren
id|nice
OL
op_minus
l_int|20
)paren
id|nice
op_assign
op_minus
l_int|20
suffix:semicolon
r_if
c_cond
(paren
id|nice
OG
l_int|19
)paren
id|nice
op_assign
l_int|19
suffix:semicolon
id|retval
op_assign
id|security_task_setnice
c_func
(paren
id|current
comma
id|nice
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_return
id|retval
suffix:semicolon
id|set_user_nice
c_func
(paren
id|current
comma
id|nice
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
macro_line|#endif
multiline_comment|/**&n; * task_prio - return the priority value of a given task.&n; * @p: the task in question.&n; *&n; * This is the priority value as seen by users in /proc.&n; * RT tasks are offset by -200. Normal tasks are centered&n; * around 0, value goes from -16 to +15.&n; */
DECL|function|task_prio
r_int
id|task_prio
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|p-&gt;prio
op_minus
id|MAX_USER_RT_PRIO
suffix:semicolon
)brace
multiline_comment|/**&n; * task_nice - return the nice value of a given task.&n; * @p: the task in question.&n; */
DECL|function|task_nice
r_int
id|task_nice
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|TASK_NICE
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * task_curr - is this task currently executing on a CPU?&n; * @p: the task in question.&n; */
DECL|function|task_curr
r_int
id|task_curr
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_return
id|cpu_curr
c_func
(paren
id|task_cpu
c_func
(paren
id|p
)paren
)paren
op_eq
id|p
suffix:semicolon
)brace
multiline_comment|/**&n; * idle_cpu - is a given cpu idle currently?&n; * @cpu: the processor in question.&n; */
DECL|function|idle_cpu
r_int
id|idle_cpu
c_func
(paren
r_int
id|cpu
)paren
(brace
r_return
id|cpu_curr
c_func
(paren
id|cpu
)paren
op_eq
id|cpu_rq
c_func
(paren
id|cpu
)paren
op_member_access_from_pointer
id|idle
suffix:semicolon
)brace
multiline_comment|/**&n; * find_process_by_pid - find a process with a matching PID value.&n; * @pid: the pid in question.&n; */
DECL|function|find_process_by_pid
r_static
r_inline
id|task_t
op_star
id|find_process_by_pid
c_func
(paren
id|pid_t
id|pid
)paren
(brace
r_return
id|pid
ques
c_cond
id|find_task_by_pid
c_func
(paren
id|pid
)paren
suffix:colon
id|current
suffix:semicolon
)brace
multiline_comment|/*&n; * setscheduler - change the scheduling policy and/or RT priority of a thread.&n; */
DECL|function|setscheduler
r_static
r_int
id|setscheduler
c_func
(paren
id|pid_t
id|pid
comma
r_int
id|policy
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_struct
id|sched_param
id|lp
suffix:semicolon
r_int
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
id|prio_array_t
op_star
id|array
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|param
op_logical_or
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|EFAULT
suffix:semicolon
r_if
c_cond
(paren
id|copy_from_user
c_func
(paren
op_amp
id|lp
comma
id|param
comma
r_sizeof
(paren
r_struct
id|sched_param
)paren
)paren
)paren
r_goto
id|out_nounlock
suffix:semicolon
multiline_comment|/*&n;&t; * We play safe to avoid deadlocks.&n;&t; */
id|read_lock_irq
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock_tasklist
suffix:semicolon
multiline_comment|/*&n;&t; * To be able to change p-&gt;policy safely, the apropriate&n;&t; * runqueue lock must be held.&n;&t; */
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|policy
OL
l_int|0
)paren
id|policy
op_assign
id|p-&gt;policy
suffix:semicolon
r_else
(brace
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|policy
op_ne
id|SCHED_FIFO
op_logical_and
id|policy
op_ne
id|SCHED_RR
op_logical_and
id|policy
op_ne
id|SCHED_NORMAL
)paren
r_goto
id|out_unlock
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Valid priorities for SCHED_FIFO and SCHED_RR are&n;&t; * 1..MAX_USER_RT_PRIO-1, valid priority for SCHED_NORMAL is 0.&n;&t; */
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|lp.sched_priority
template_param
id|MAX_USER_RT_PRIO
op_minus
l_int|1
)paren
r_goto
id|out_unlock
suffix:semicolon
r_if
c_cond
(paren
(paren
id|policy
op_eq
id|SCHED_NORMAL
)paren
op_ne
(paren
id|lp.sched_priority
op_eq
l_int|0
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
(paren
id|policy
op_eq
id|SCHED_FIFO
op_logical_or
id|policy
op_eq
id|SCHED_RR
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
r_if
c_cond
(paren
(paren
id|current-&gt;euid
op_ne
id|p-&gt;euid
)paren
op_logical_and
(paren
id|current-&gt;euid
op_ne
id|p-&gt;uid
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
id|security_task_setscheduler
c_func
(paren
id|p
comma
id|policy
comma
op_amp
id|lp
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_goto
id|out_unlock
suffix:semicolon
id|array
op_assign
id|p-&gt;array
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|deactivate_task
c_func
(paren
id|p
comma
id|task_rq
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|p-&gt;policy
op_assign
id|policy
suffix:semicolon
id|p-&gt;rt_priority
op_assign
id|lp.sched_priority
suffix:semicolon
r_if
c_cond
(paren
id|policy
op_ne
id|SCHED_NORMAL
)paren
id|p-&gt;prio
op_assign
id|MAX_USER_RT_PRIO
op_minus
l_int|1
op_minus
id|p-&gt;rt_priority
suffix:semicolon
r_else
id|p-&gt;prio
op_assign
id|p-&gt;static_prio
suffix:semicolon
r_if
c_cond
(paren
id|array
)paren
id|__activate_task
c_func
(paren
id|p
comma
id|task_rq
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
id|out_unlock
suffix:colon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|out_unlock_tasklist
suffix:colon
id|read_unlock_irq
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_setscheduler - set/change the scheduler policy and RT priority&n; * @pid: the pid in question.&n; * @policy: new policy&n; * @param: structure containing the new RT priority.&n; */
DECL|function|sys_sched_setscheduler
id|asmlinkage
r_int
id|sys_sched_setscheduler
c_func
(paren
id|pid_t
id|pid
comma
r_int
id|policy
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_return
id|setscheduler
c_func
(paren
id|pid
comma
id|policy
comma
id|param
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_setparam - set/change the RT priority of a thread&n; * @pid: the pid in question.&n; * @param: structure containing the new RT priority.&n; */
DECL|function|sys_sched_setparam
id|asmlinkage
r_int
id|sys_sched_setparam
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_return
id|setscheduler
c_func
(paren
id|pid
comma
op_minus
l_int|1
comma
id|param
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_getscheduler - get the policy (scheduling class) of a thread&n; * @pid: the pid in question.&n; */
DECL|function|sys_sched_getscheduler
id|asmlinkage
r_int
id|sys_sched_getscheduler
c_func
(paren
id|pid_t
id|pid
)paren
(brace
r_int
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p
)paren
(brace
id|retval
op_assign
id|security_task_getscheduler
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|retval
)paren
id|retval
op_assign
id|p-&gt;policy
suffix:semicolon
)brace
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_getscheduler - get the RT priority of a thread&n; * @pid: the pid in question.&n; * @param: structure containing the RT priority.&n; */
DECL|function|sys_sched_getparam
id|asmlinkage
r_int
id|sys_sched_getparam
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|sched_param
op_star
id|param
)paren
(brace
r_struct
id|sched_param
id|lp
suffix:semicolon
r_int
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|param
op_logical_or
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
id|security_task_getscheduler
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_goto
id|out_unlock
suffix:semicolon
id|lp.sched_priority
op_assign
id|p-&gt;rt_priority
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * This one might sleep, we cannot do it with a spinlock held ...&n;&t; */
id|retval
op_assign
id|copy_to_user
c_func
(paren
id|param
comma
op_amp
id|lp
comma
r_sizeof
(paren
op_star
id|param
)paren
)paren
ques
c_cond
op_minus
id|EFAULT
suffix:colon
l_int|0
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
id|out_unlock
suffix:colon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_setaffinity - set the cpu affinity of a process&n; * @pid: pid of the process&n; * @len: length in bytes of the bitmask pointed to by user_mask_ptr&n; * @user_mask_ptr: user-space pointer to the new cpu mask&n; */
DECL|function|sys_sched_setaffinity
id|asmlinkage
r_int
id|sys_sched_setaffinity
c_func
(paren
id|pid_t
id|pid
comma
r_int
r_int
id|len
comma
r_int
r_int
op_star
id|user_mask_ptr
)paren
(brace
r_int
r_int
id|new_mask
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
id|len
OL
r_sizeof
(paren
id|new_mask
)paren
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
r_if
c_cond
(paren
id|copy_from_user
c_func
(paren
op_amp
id|new_mask
comma
id|user_mask_ptr
comma
r_sizeof
(paren
id|new_mask
)paren
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
id|new_mask
op_and_assign
id|cpu_online_map
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_mask
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
(brace
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_return
op_minus
id|ESRCH
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * It is not safe to call set_cpus_allowed with the&n;&t; * tasklist_lock held.  We will bump the task_struct&squot;s&n;&t; * usage count and then drop tasklist_lock.&n;&t; */
id|get_task_struct
c_func
(paren
id|p
)paren
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|EPERM
suffix:semicolon
r_if
c_cond
(paren
(paren
id|current-&gt;euid
op_ne
id|p-&gt;euid
)paren
op_logical_and
(paren
id|current-&gt;euid
op_ne
id|p-&gt;uid
)paren
op_logical_and
op_logical_neg
id|capable
c_func
(paren
id|CAP_SYS_NICE
)paren
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|set_cpus_allowed
c_func
(paren
id|p
comma
id|new_mask
)paren
suffix:semicolon
id|out_unlock
suffix:colon
id|put_task_struct
c_func
(paren
id|p
)paren
suffix:semicolon
r_return
id|retval
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_getaffinity - get the cpu affinity of a process&n; * @pid: pid of the process&n; * @len: length in bytes of the bitmask pointed to by user_mask_ptr&n; * @user_mask_ptr: user-space pointer to hold the current cpu mask&n; */
DECL|function|sys_sched_getaffinity
id|asmlinkage
r_int
id|sys_sched_getaffinity
c_func
(paren
id|pid_t
id|pid
comma
r_int
r_int
id|len
comma
r_int
r_int
op_star
id|user_mask_ptr
)paren
(brace
r_int
r_int
id|real_len
suffix:semicolon
r_int
r_int
id|mask
suffix:semicolon
r_int
id|retval
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
id|real_len
op_assign
r_sizeof
(paren
id|mask
)paren
suffix:semicolon
r_if
c_cond
(paren
id|len
OL
id|real_len
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
l_int|0
suffix:semicolon
id|mask
op_assign
id|p-&gt;cpus_allowed
op_amp
id|cpu_online_map
suffix:semicolon
id|out_unlock
suffix:colon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_return
id|retval
suffix:semicolon
r_if
c_cond
(paren
id|copy_to_user
c_func
(paren
id|user_mask_ptr
comma
op_amp
id|mask
comma
id|real_len
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
r_return
id|real_len
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_yield - yield the current processor to other threads.&n; *&n; * this function yields the current CPU by moving the calling thread&n; * to the expired array. If there are no other threads running on this&n; * CPU then this function will return.&n; */
DECL|function|sys_sched_yield
id|asmlinkage
r_int
id|sys_sched_yield
c_func
(paren
r_void
)paren
(brace
id|runqueue_t
op_star
id|rq
op_assign
id|this_rq_lock
c_func
(paren
)paren
suffix:semicolon
id|prio_array_t
op_star
id|array
op_assign
id|current-&gt;array
suffix:semicolon
multiline_comment|/*&n;&t; * We implement yielding by moving the task into the expired&n;&t; * queue.&n;&t; *&n;&t; * (special rule: RT tasks will just roundrobin in the active&n;&t; *  array.)&n;&t; */
r_if
c_cond
(paren
id|likely
c_func
(paren
op_logical_neg
id|rt_task
c_func
(paren
id|current
)paren
)paren
)paren
(brace
id|dequeue_task
c_func
(paren
id|current
comma
id|array
)paren
suffix:semicolon
id|enqueue_task
c_func
(paren
id|current
comma
id|rq-&gt;expired
)paren
suffix:semicolon
)brace
r_else
(brace
id|list_del
c_func
(paren
op_amp
id|current-&gt;run_list
)paren
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|current-&gt;run_list
comma
id|array-&gt;queue
op_plus
id|current-&gt;prio
)paren
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Since we are going to call schedule() anyway, there&squot;s&n;&t; * no need to preempt:&n;&t; */
id|_raw_spin_unlock
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|preempt_enable_no_resched
c_func
(paren
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|__cond_resched
r_void
id|__cond_resched
c_func
(paren
r_void
)paren
(brace
id|set_current_state
c_func
(paren
id|TASK_RUNNING
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * yield - yield the current processor to other threads.&n; *&n; * this is a shortcut for kernel-space yielding - it marks the&n; * thread runnable and calls sys_sched_yield().&n; */
DECL|function|yield
r_void
id|yield
c_func
(paren
r_void
)paren
(brace
id|set_current_state
c_func
(paren
id|TASK_RUNNING
)paren
suffix:semicolon
id|sys_sched_yield
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This task is about to go to sleep on IO.  Increment rq-&gt;nr_iowait so&n; * that process accounting knows that this is a task in IO wait state.&n; *&n; * But don&squot;t do that if it is a deliberate, throttling IO wait (this task&n; * has set its backing_dev_info: the queue against which it should throttle)&n; */
DECL|function|io_schedule
r_void
id|io_schedule
c_func
(paren
r_void
)paren
(brace
r_struct
id|runqueue
op_star
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
id|atomic_dec
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
)paren
suffix:semicolon
)brace
DECL|function|io_schedule_timeout
r_int
id|io_schedule_timeout
c_func
(paren
r_int
id|timeout
)paren
(brace
r_struct
id|runqueue
op_star
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
r_int
id|ret
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
)paren
suffix:semicolon
id|ret
op_assign
id|schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|atomic_dec
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_get_priority_max - return maximum RT priority.&n; * @policy: scheduling class.&n; *&n; * this syscall returns the maximum rt_priority that can be used&n; * by a given scheduling class.&n; */
DECL|function|sys_sched_get_priority_max
id|asmlinkage
r_int
id|sys_sched_get_priority_max
c_func
(paren
r_int
id|policy
)paren
(brace
r_int
id|ret
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_switch
c_cond
(paren
id|policy
)paren
(brace
r_case
id|SCHED_FIFO
suffix:colon
r_case
id|SCHED_RR
suffix:colon
id|ret
op_assign
id|MAX_USER_RT_PRIO
op_minus
l_int|1
suffix:semicolon
r_break
suffix:semicolon
r_case
id|SCHED_NORMAL
suffix:colon
id|ret
op_assign
l_int|0
suffix:semicolon
r_break
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_get_priority_mix - return minimum RT priority.&n; * @policy: scheduling class.&n; *&n; * this syscall returns the minimum rt_priority that can be used&n; * by a given scheduling class.&n; */
DECL|function|sys_sched_get_priority_min
id|asmlinkage
r_int
id|sys_sched_get_priority_min
c_func
(paren
r_int
id|policy
)paren
(brace
r_int
id|ret
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_switch
c_cond
(paren
id|policy
)paren
(brace
r_case
id|SCHED_FIFO
suffix:colon
r_case
id|SCHED_RR
suffix:colon
id|ret
op_assign
l_int|1
suffix:semicolon
r_break
suffix:semicolon
r_case
id|SCHED_NORMAL
suffix:colon
id|ret
op_assign
l_int|0
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/**&n; * sys_sched_rr_get_interval - return the default timeslice of a process.&n; * @pid: pid of the process.&n; * @interval: userspace pointer to the timeslice value.&n; *&n; * this syscall writes the default timeslice value of a given process&n; * into the user-space timespec buffer. A value of &squot;0&squot; means infinity.&n; */
DECL|function|sys_sched_rr_get_interval
id|asmlinkage
r_int
id|sys_sched_rr_get_interval
c_func
(paren
id|pid_t
id|pid
comma
r_struct
id|timespec
op_star
id|interval
)paren
(brace
r_int
id|retval
op_assign
op_minus
id|EINVAL
suffix:semicolon
r_struct
id|timespec
id|t
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
id|pid
OL
l_int|0
)paren
r_goto
id|out_nounlock
suffix:semicolon
id|retval
op_assign
op_minus
id|ESRCH
suffix:semicolon
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|p
op_assign
id|find_process_by_pid
c_func
(paren
id|pid
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p
)paren
r_goto
id|out_unlock
suffix:semicolon
id|retval
op_assign
id|security_task_getscheduler
c_func
(paren
id|p
)paren
suffix:semicolon
r_if
c_cond
(paren
id|retval
)paren
r_goto
id|out_unlock
suffix:semicolon
id|jiffies_to_timespec
c_func
(paren
id|p-&gt;policy
op_amp
id|SCHED_FIFO
ques
c_cond
l_int|0
suffix:colon
id|task_timeslice
c_func
(paren
id|p
)paren
comma
op_amp
id|t
)paren
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|retval
op_assign
id|copy_to_user
c_func
(paren
id|interval
comma
op_amp
id|t
comma
r_sizeof
(paren
id|t
)paren
)paren
ques
c_cond
op_minus
id|EFAULT
suffix:colon
l_int|0
suffix:semicolon
id|out_nounlock
suffix:colon
r_return
id|retval
suffix:semicolon
id|out_unlock
suffix:colon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
r_return
id|retval
suffix:semicolon
)brace
DECL|function|eldest_child
r_static
r_inline
r_struct
id|task_struct
op_star
id|eldest_child
c_func
(paren
r_struct
id|task_struct
op_star
id|p
)paren
(brace
r_if
c_cond
(paren
id|list_empty
c_func
(paren
op_amp
id|p-&gt;children
)paren
)paren
r_return
l_int|NULL
suffix:semicolon
r_return
id|list_entry
c_func
(paren
id|p-&gt;children.next
comma
r_struct
id|task_struct
comma
id|sibling
)paren
suffix:semicolon
)brace
DECL|function|older_sibling
r_static
r_inline
r_struct
id|task_struct
op_star
id|older_sibling
c_func
(paren
r_struct
id|task_struct
op_star
id|p
)paren
(brace
r_if
c_cond
(paren
id|p-&gt;sibling.prev
op_eq
op_amp
id|p-&gt;parent-&gt;children
)paren
r_return
l_int|NULL
suffix:semicolon
r_return
id|list_entry
c_func
(paren
id|p-&gt;sibling.prev
comma
r_struct
id|task_struct
comma
id|sibling
)paren
suffix:semicolon
)brace
DECL|function|younger_sibling
r_static
r_inline
r_struct
id|task_struct
op_star
id|younger_sibling
c_func
(paren
r_struct
id|task_struct
op_star
id|p
)paren
(brace
r_if
c_cond
(paren
id|p-&gt;sibling.next
op_eq
op_amp
id|p-&gt;parent-&gt;children
)paren
r_return
l_int|NULL
suffix:semicolon
r_return
id|list_entry
c_func
(paren
id|p-&gt;sibling.next
comma
r_struct
id|task_struct
comma
id|sibling
)paren
suffix:semicolon
)brace
DECL|function|show_task
r_static
r_void
id|show_task
c_func
(paren
id|task_t
op_star
id|p
)paren
(brace
r_int
r_int
id|free
op_assign
l_int|0
suffix:semicolon
id|task_t
op_star
id|relative
suffix:semicolon
r_int
id|state
suffix:semicolon
r_static
r_const
r_char
op_star
id|stat_nam
(braket
)braket
op_assign
(brace
l_string|&quot;R&quot;
comma
l_string|&quot;S&quot;
comma
l_string|&quot;D&quot;
comma
l_string|&quot;T&quot;
comma
l_string|&quot;Z&quot;
comma
l_string|&quot;W&quot;
)brace
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%-13.13s &quot;
comma
id|p-&gt;comm
)paren
suffix:semicolon
id|state
op_assign
id|p-&gt;state
ques
c_cond
id|__ffs
c_func
(paren
id|p-&gt;state
)paren
op_plus
l_int|1
suffix:colon
l_int|0
suffix:semicolon
r_if
c_cond
(paren
(paren
(paren
r_int
)paren
id|state
)paren
OL
r_sizeof
(paren
id|stat_nam
)paren
op_div
r_sizeof
(paren
r_char
op_star
)paren
)paren
id|printk
c_func
(paren
id|stat_nam
(braket
id|state
)braket
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; &quot;
)paren
suffix:semicolon
macro_line|#if (BITS_PER_LONG == 32)
r_if
c_cond
(paren
id|p
op_eq
id|current
)paren
id|printk
c_func
(paren
l_string|&quot; current  &quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; %08lX &quot;
comma
id|thread_saved_pc
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
macro_line|#else
r_if
c_cond
(paren
id|p
op_eq
id|current
)paren
id|printk
c_func
(paren
l_string|&quot;   current task   &quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; %016lx &quot;
comma
id|thread_saved_pc
c_func
(paren
id|p
)paren
)paren
suffix:semicolon
macro_line|#endif
(brace
r_int
r_int
op_star
id|n
op_assign
(paren
r_int
r_int
op_star
)paren
(paren
id|p-&gt;thread_info
op_plus
l_int|1
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
op_star
id|n
)paren
id|n
op_increment
suffix:semicolon
id|free
op_assign
(paren
r_int
r_int
)paren
id|n
op_minus
(paren
r_int
r_int
)paren
(paren
id|p
op_plus
l_int|1
)paren
suffix:semicolon
)brace
id|printk
c_func
(paren
l_string|&quot;%5lu %5d %6d &quot;
comma
id|free
comma
id|p-&gt;pid
comma
id|p-&gt;parent-&gt;pid
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|eldest_child
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%5d &quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;      &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|younger_sibling
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%7d&quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;       &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|relative
op_assign
id|older_sibling
c_func
(paren
id|p
)paren
)paren
)paren
id|printk
c_func
(paren
l_string|&quot; %5d&quot;
comma
id|relative-&gt;pid
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;      &quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|p-&gt;mm
)paren
id|printk
c_func
(paren
l_string|&quot; (L-TLB)&bslash;n&quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot; (NOTLB)&bslash;n&quot;
)paren
suffix:semicolon
(brace
r_extern
r_void
id|show_trace_task
c_func
(paren
id|task_t
op_star
id|tsk
)paren
suffix:semicolon
id|show_trace_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
)brace
DECL|function|show_state
r_void
id|show_state
c_func
(paren
r_void
)paren
(brace
id|task_t
op_star
id|g
comma
op_star
id|p
suffix:semicolon
macro_line|#if (BITS_PER_LONG == 32)
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
l_string|&quot;                         free                        sibling&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;  task             PC    stack   pid father child younger older&bslash;n&quot;
)paren
suffix:semicolon
macro_line|#else
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
l_string|&quot;                                 free                        sibling&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;  task                 PC        stack   pid father child younger older&bslash;n&quot;
)paren
suffix:semicolon
macro_line|#endif
id|read_lock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
id|do_each_thread
c_func
(paren
id|g
comma
id|p
)paren
(brace
multiline_comment|/*&n;&t;&t; * reset the NMI-timeout, listing all files on a slow&n;&t;&t; * console might take alot of time:&n;&t;&t; */
id|touch_nmi_watchdog
c_func
(paren
)paren
suffix:semicolon
id|show_task
c_func
(paren
id|p
)paren
suffix:semicolon
)brace
id|while_each_thread
c_func
(paren
id|g
comma
id|p
)paren
suffix:semicolon
id|read_unlock
c_func
(paren
op_amp
id|tasklist_lock
)paren
suffix:semicolon
)brace
DECL|function|init_idle
r_void
id|__init
id|init_idle
c_func
(paren
id|task_t
op_star
id|idle
comma
r_int
id|cpu
)paren
(brace
id|runqueue_t
op_star
id|idle_rq
op_assign
id|cpu_rq
c_func
(paren
id|cpu
)paren
comma
op_star
id|rq
op_assign
id|cpu_rq
c_func
(paren
id|task_cpu
c_func
(paren
id|idle
)paren
)paren
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|double_rq_lock
c_func
(paren
id|idle_rq
comma
id|rq
)paren
suffix:semicolon
id|idle_rq-&gt;curr
op_assign
id|idle_rq-&gt;idle
op_assign
id|idle
suffix:semicolon
id|deactivate_task
c_func
(paren
id|idle
comma
id|rq
)paren
suffix:semicolon
id|idle-&gt;array
op_assign
l_int|NULL
suffix:semicolon
id|idle-&gt;prio
op_assign
id|MAX_PRIO
suffix:semicolon
id|idle-&gt;state
op_assign
id|TASK_RUNNING
suffix:semicolon
id|set_task_cpu
c_func
(paren
id|idle
comma
id|cpu
)paren
suffix:semicolon
id|double_rq_unlock
c_func
(paren
id|idle_rq
comma
id|rq
)paren
suffix:semicolon
id|set_tsk_need_resched
c_func
(paren
id|idle
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/* Set the preempt count _outside_ the spinlocks! */
macro_line|#ifdef CONFIG_PREEMPT
id|idle-&gt;thread_info-&gt;preempt_count
op_assign
(paren
id|idle-&gt;lock_depth
op_ge
l_int|0
)paren
suffix:semicolon
macro_line|#else
id|idle-&gt;thread_info-&gt;preempt_count
op_assign
l_int|0
suffix:semicolon
macro_line|#endif
)brace
macro_line|#if CONFIG_SMP
multiline_comment|/*&n; * This is how migration works:&n; *&n; * 1) we queue a migration_req_t structure in the source CPU&squot;s&n; *    runqueue and wake up that CPU&squot;s migration thread.&n; * 2) we down() the locked semaphore =&gt; thread blocks.&n; * 3) migration thread wakes up (implicitly it forces the migrated&n; *    thread off the CPU)&n; * 4) it gets the migration request and checks whether the migrated&n; *    task is still in the wrong runqueue.&n; * 5) if it&squot;s in the wrong runqueue then the migration thread removes&n; *    it and puts it into the right queue.&n; * 6) migration thread up()s the semaphore.&n; * 7) we wake up and the migration is done.&n; */
r_typedef
r_struct
(brace
DECL|member|list
r_struct
id|list_head
id|list
suffix:semicolon
DECL|member|task
id|task_t
op_star
id|task
suffix:semicolon
DECL|member|done
r_struct
id|completion
id|done
suffix:semicolon
DECL|typedef|migration_req_t
)brace
id|migration_req_t
suffix:semicolon
multiline_comment|/*&n; * Change a given task&squot;s CPU affinity. Migrate the thread to a&n; * proper CPU and schedule it away if the CPU it&squot;s executing on&n; * is removed from the allowed bitmask.&n; *&n; * NOTE: the caller must have a valid reference to the task, the&n; * task must not exit() &amp; deallocate itself prematurely.  The&n; * call is not atomic; no spinlocks may be held.&n; */
DECL|function|set_cpus_allowed
r_void
id|set_cpus_allowed
c_func
(paren
id|task_t
op_star
id|p
comma
r_int
r_int
id|new_mask
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|migration_req_t
id|req
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
macro_line|#if 0 /* FIXME: Grab cpu_lock, return error on this case. --RR */
id|new_mask
op_and_assign
id|cpu_online_map
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_mask
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
id|rq
op_assign
id|task_rq_lock
c_func
(paren
id|p
comma
op_amp
id|flags
)paren
suffix:semicolon
id|p-&gt;cpus_allowed
op_assign
id|new_mask
suffix:semicolon
multiline_comment|/*&n;&t; * Can the task run on the task&squot;s current CPU? If not then&n;&t; * migrate the thread off to a proper CPU.&n;&t; */
r_if
c_cond
(paren
id|new_mask
op_amp
(paren
l_int|1UL
op_lshift
id|task_cpu
c_func
(paren
id|p
)paren
)paren
)paren
(brace
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * If the task is not on a runqueue (and not running), then&n;&t; * it is sufficient to simply update the task&squot;s cpu field.&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|p-&gt;array
op_logical_and
op_logical_neg
id|task_running
c_func
(paren
id|rq
comma
id|p
)paren
)paren
(brace
id|set_task_cpu
c_func
(paren
id|p
comma
id|__ffs
c_func
(paren
id|p-&gt;cpus_allowed
)paren
)paren
suffix:semicolon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|init_completion
c_func
(paren
op_amp
id|req.done
)paren
suffix:semicolon
id|req.task
op_assign
id|p
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|req.list
comma
op_amp
id|rq-&gt;migration_queue
)paren
suffix:semicolon
id|task_rq_unlock
c_func
(paren
id|rq
comma
op_amp
id|flags
)paren
suffix:semicolon
id|wake_up_process
c_func
(paren
id|rq-&gt;migration_thread
)paren
suffix:semicolon
id|wait_for_completion
c_func
(paren
op_amp
id|req.done
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * migration_thread - this is a highprio system thread that performs&n; * thread migration by &squot;pulling&squot; threads into the target runqueue.&n; */
DECL|function|migration_thread
r_static
r_int
id|migration_thread
c_func
(paren
r_void
op_star
id|data
)paren
(brace
r_struct
id|sched_param
id|param
op_assign
(brace
dot
id|sched_priority
op_assign
id|MAX_RT_PRIO
op_minus
l_int|1
)brace
suffix:semicolon
r_int
id|cpu
op_assign
(paren
r_int
)paren
id|data
suffix:semicolon
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_int
id|ret
suffix:semicolon
id|daemonize
c_func
(paren
l_string|&quot;migration/%d&quot;
comma
id|cpu
)paren
suffix:semicolon
id|set_fs
c_func
(paren
id|KERNEL_DS
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Either we are running on the right CPU, or there&squot;s a&n;&t; * a migration thread on the target CPU, guaranteed.&n;&t; */
id|set_cpus_allowed
c_func
(paren
id|current
comma
l_int|1UL
op_lshift
id|cpu
)paren
suffix:semicolon
id|ret
op_assign
id|setscheduler
c_func
(paren
l_int|0
comma
id|SCHED_FIFO
comma
op_amp
id|param
)paren
suffix:semicolon
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|rq-&gt;migration_thread
op_assign
id|current
suffix:semicolon
r_for
c_loop
(paren
suffix:semicolon
suffix:semicolon
)paren
(brace
id|runqueue_t
op_star
id|rq_src
comma
op_star
id|rq_dest
suffix:semicolon
r_struct
id|list_head
op_star
id|head
suffix:semicolon
r_int
id|cpu_src
comma
id|cpu_dest
suffix:semicolon
id|migration_req_t
op_star
id|req
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
id|task_t
op_star
id|p
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|head
op_assign
op_amp
id|rq-&gt;migration_queue
suffix:semicolon
id|current-&gt;state
op_assign
id|TASK_INTERRUPTIBLE
suffix:semicolon
r_if
c_cond
(paren
id|list_empty
c_func
(paren
id|head
)paren
)paren
(brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|schedule
c_func
(paren
)paren
suffix:semicolon
r_continue
suffix:semicolon
)brace
id|req
op_assign
id|list_entry
c_func
(paren
id|head-&gt;next
comma
id|migration_req_t
comma
id|list
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
id|head-&gt;next
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|rq-&gt;lock
comma
id|flags
)paren
suffix:semicolon
id|p
op_assign
id|req-&gt;task
suffix:semicolon
id|cpu_dest
op_assign
id|__ffs
c_func
(paren
id|p-&gt;cpus_allowed
op_amp
id|cpu_online_map
)paren
suffix:semicolon
id|rq_dest
op_assign
id|cpu_rq
c_func
(paren
id|cpu_dest
)paren
suffix:semicolon
id|repeat
suffix:colon
id|cpu_src
op_assign
id|task_cpu
c_func
(paren
id|p
)paren
suffix:semicolon
id|rq_src
op_assign
id|cpu_rq
c_func
(paren
id|cpu_src
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|double_rq_lock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
r_if
c_cond
(paren
id|task_cpu
c_func
(paren
id|p
)paren
op_ne
id|cpu_src
)paren
(brace
id|double_rq_unlock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
r_goto
id|repeat
suffix:semicolon
)brace
r_if
c_cond
(paren
id|rq_src
op_eq
id|rq
)paren
(brace
id|set_task_cpu
c_func
(paren
id|p
comma
id|cpu_dest
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;array
)paren
(brace
id|deactivate_task
c_func
(paren
id|p
comma
id|rq_src
)paren
suffix:semicolon
id|__activate_task
c_func
(paren
id|p
comma
id|rq_dest
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;prio
OL
id|rq_dest-&gt;curr-&gt;prio
)paren
id|resched_task
c_func
(paren
id|rq_dest-&gt;curr
)paren
suffix:semicolon
)brace
)brace
id|double_rq_unlock
c_func
(paren
id|rq_src
comma
id|rq_dest
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
id|complete
c_func
(paren
op_amp
id|req-&gt;done
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * migration_call - callback that gets triggered when a CPU is added.&n; * Here we can start up the necessary migration thread for the new CPU.&n; */
DECL|function|migration_call
r_static
r_int
id|migration_call
c_func
(paren
r_struct
id|notifier_block
op_star
id|nfb
comma
r_int
r_int
id|action
comma
r_void
op_star
id|hcpu
)paren
(brace
r_switch
c_cond
(paren
id|action
)paren
(brace
r_case
id|CPU_ONLINE
suffix:colon
id|printk
c_func
(paren
l_string|&quot;Starting migration thread for cpu %li&bslash;n&quot;
comma
(paren
r_int
)paren
id|hcpu
)paren
suffix:semicolon
id|kernel_thread
c_func
(paren
id|migration_thread
comma
id|hcpu
comma
id|CLONE_KERNEL
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|cpu_rq
c_func
(paren
(paren
r_int
)paren
id|hcpu
)paren
op_member_access_from_pointer
id|migration_thread
)paren
id|yield
c_func
(paren
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
r_return
id|NOTIFY_OK
suffix:semicolon
)brace
DECL|variable|migration_notifier
r_static
r_struct
id|notifier_block
id|migration_notifier
op_assign
(brace
op_amp
id|migration_call
comma
l_int|NULL
comma
l_int|0
)brace
suffix:semicolon
DECL|function|migration_init
id|__init
r_int
id|migration_init
c_func
(paren
r_void
)paren
(brace
multiline_comment|/* Start one for boot CPU. */
id|migration_call
c_func
(paren
op_amp
id|migration_notifier
comma
id|CPU_ONLINE
comma
(paren
r_void
op_star
)paren
(paren
r_int
)paren
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|register_cpu_notifier
c_func
(paren
op_amp
id|migration_notifier
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
macro_line|#endif
macro_line|#if CONFIG_SMP || CONFIG_PREEMPT
multiline_comment|/*&n; * The &squot;big kernel lock&squot;&n; *&n; * This spinlock is taken and released recursively by lock_kernel()&n; * and unlock_kernel().  It is transparently dropped and reaquired&n; * over schedule().  It is used to protect legacy code that hasn&squot;t&n; * been migrated to a proper locking design yet.&n; *&n; * Don&squot;t use in new code.&n; */
DECL|variable|__cacheline_aligned_in_smp
id|spinlock_t
id|kernel_flag
id|__cacheline_aligned_in_smp
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
macro_line|#endif
DECL|function|kstat_init_cpu
r_static
r_void
id|kstat_init_cpu
c_func
(paren
r_int
id|cpu
)paren
(brace
multiline_comment|/* Add any initialisation to kstat here */
multiline_comment|/* Useful when cpu offlining logic is added.. */
)brace
DECL|function|kstat_cpu_notify
r_static
r_int
id|__devinit
id|kstat_cpu_notify
c_func
(paren
r_struct
id|notifier_block
op_star
id|self
comma
r_int
r_int
id|action
comma
r_void
op_star
id|hcpu
)paren
(brace
r_int
id|cpu
op_assign
(paren
r_int
r_int
)paren
id|hcpu
suffix:semicolon
r_switch
c_cond
(paren
id|action
)paren
(brace
r_case
id|CPU_UP_PREPARE
suffix:colon
id|kstat_init_cpu
c_func
(paren
id|cpu
)paren
suffix:semicolon
r_break
suffix:semicolon
r_default
suffix:colon
r_break
suffix:semicolon
)brace
r_return
id|NOTIFY_OK
suffix:semicolon
)brace
DECL|variable|kstat_nb
r_static
r_struct
id|notifier_block
id|__devinitdata
id|kstat_nb
op_assign
(brace
dot
id|notifier_call
op_assign
id|kstat_cpu_notify
comma
dot
id|next
op_assign
l_int|NULL
comma
)brace
suffix:semicolon
DECL|function|init_kstat
id|__init
r_static
r_void
id|init_kstat
c_func
(paren
r_void
)paren
(brace
id|kstat_cpu_notify
c_func
(paren
op_amp
id|kstat_nb
comma
(paren
r_int
r_int
)paren
id|CPU_UP_PREPARE
comma
(paren
r_void
op_star
)paren
(paren
r_int
)paren
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|register_cpu_notifier
c_func
(paren
op_amp
id|kstat_nb
)paren
suffix:semicolon
)brace
DECL|function|sched_init
r_void
id|__init
id|sched_init
c_func
(paren
r_void
)paren
(brace
id|runqueue_t
op_star
id|rq
suffix:semicolon
r_int
id|i
comma
id|j
comma
id|k
suffix:semicolon
multiline_comment|/* Init the kstat counters */
id|init_kstat
c_func
(paren
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
id|i
op_increment
)paren
(brace
id|prio_array_t
op_star
id|array
suffix:semicolon
id|rq
op_assign
id|cpu_rq
c_func
(paren
id|i
)paren
suffix:semicolon
id|rq-&gt;active
op_assign
id|rq-&gt;arrays
suffix:semicolon
id|rq-&gt;expired
op_assign
id|rq-&gt;arrays
op_plus
l_int|1
suffix:semicolon
id|spin_lock_init
c_func
(paren
op_amp
id|rq-&gt;lock
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|rq-&gt;migration_queue
)paren
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|rq-&gt;nr_iowait
comma
l_int|0
)paren
suffix:semicolon
id|nr_running_init
c_func
(paren
id|rq
)paren
suffix:semicolon
r_for
c_loop
(paren
id|j
op_assign
l_int|0
suffix:semicolon
id|j
OL
l_int|2
suffix:semicolon
id|j
op_increment
)paren
(brace
id|array
op_assign
id|rq-&gt;arrays
op_plus
id|j
suffix:semicolon
r_for
c_loop
(paren
id|k
op_assign
l_int|0
suffix:semicolon
id|k
OL
id|MAX_PRIO
suffix:semicolon
id|k
op_increment
)paren
(brace
id|INIT_LIST_HEAD
c_func
(paren
id|array-&gt;queue
op_plus
id|k
)paren
suffix:semicolon
id|__clear_bit
c_func
(paren
id|k
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
singleline_comment|// delimiter for bitsearch
id|__set_bit
c_func
(paren
id|MAX_PRIO
comma
id|array-&gt;bitmap
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * We have to do a little magic to get the first&n;&t; * thread right in SMP mode.&n;&t; */
id|rq
op_assign
id|this_rq
c_func
(paren
)paren
suffix:semicolon
id|rq-&gt;curr
op_assign
id|current
suffix:semicolon
id|rq-&gt;idle
op_assign
id|current
suffix:semicolon
id|set_task_cpu
c_func
(paren
id|current
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|wake_up_forked_process
c_func
(paren
id|current
)paren
suffix:semicolon
id|init_timers
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The boot idle thread does lazy MMU switching as well:&n;&t; */
id|atomic_inc
c_func
(paren
op_amp
id|init_mm.mm_count
)paren
suffix:semicolon
id|enter_lazy_tlb
c_func
(paren
op_amp
id|init_mm
comma
id|current
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
macro_line|#ifdef CONFIG_DEBUG_SPINLOCK_SLEEP
DECL|function|__might_sleep
r_void
id|__might_sleep
c_func
(paren
r_char
op_star
id|file
comma
r_int
id|line
)paren
(brace
macro_line|#if defined(in_atomic)
r_static
r_int
r_int
id|prev_jiffy
suffix:semicolon
multiline_comment|/* ratelimiting */
r_if
c_cond
(paren
id|in_atomic
c_func
(paren
)paren
)paren
(brace
r_if
c_cond
(paren
id|time_before
c_func
(paren
id|jiffies
comma
id|prev_jiffy
op_plus
id|HZ
)paren
)paren
r_return
suffix:semicolon
id|prev_jiffy
op_assign
id|jiffies
suffix:semicolon
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;Debug: sleeping function called from illegal&quot;
l_string|&quot; context at %s:%d&bslash;n&quot;
comma
id|file
comma
id|line
)paren
suffix:semicolon
id|dump_stack
c_func
(paren
)paren
suffix:semicolon
)brace
macro_line|#endif
)brace
macro_line|#endif
macro_line|#if defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_PREEMPT)
multiline_comment|/*&n; * This could be a long-held lock.  If another CPU holds it for a long time,&n; * and that CPU is not asked to reschedule then *this* CPU will spin on the&n; * lock for a long time, even if *this* CPU is asked to reschedule.&n; *&n; * So what we do here, in the slow (contended) path is to spin on the lock by&n; * hand while permitting preemption.&n; *&n; * Called inside preempt_disable().&n; */
DECL|function|__preempt_spin_lock
r_void
id|__preempt_spin_lock
c_func
(paren
id|spinlock_t
op_star
id|lock
)paren
(brace
r_if
c_cond
(paren
id|preempt_count
c_func
(paren
)paren
OG
l_int|1
)paren
(brace
id|_raw_spin_lock
c_func
(paren
id|lock
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
r_do
(brace
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_while
c_loop
(paren
id|spin_is_locked
c_func
(paren
id|lock
)paren
)paren
id|cpu_relax
c_func
(paren
)paren
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
op_logical_neg
id|_raw_spin_trylock
c_func
(paren
id|lock
)paren
)paren
suffix:semicolon
)brace
DECL|function|__preempt_write_lock
r_void
id|__preempt_write_lock
c_func
(paren
id|rwlock_t
op_star
id|lock
)paren
(brace
r_if
c_cond
(paren
id|preempt_count
c_func
(paren
)paren
OG
l_int|1
)paren
(brace
id|_raw_write_lock
c_func
(paren
id|lock
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
r_do
(brace
id|preempt_enable
c_func
(paren
)paren
suffix:semicolon
r_while
c_loop
(paren
id|rwlock_is_locked
c_func
(paren
id|lock
)paren
)paren
id|cpu_relax
c_func
(paren
)paren
suffix:semicolon
id|preempt_disable
c_func
(paren
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
op_logical_neg
id|_raw_write_trylock
c_func
(paren
id|lock
)paren
)paren
suffix:semicolon
)brace
macro_line|#endif
eof
