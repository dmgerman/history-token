multiline_comment|/*&n; * linux/fs/mbcache.c&n; * (C) 2001-2002 Andreas Gruenbacher, &lt;a.gruenbacher@computer.org&gt;&n; */
multiline_comment|/*&n; * Filesystem Meta Information Block Cache (mbcache)&n; *&n; * The mbcache caches blocks of block devices that need to be located&n; * by their device/block number, as well as by other criteria (such&n; * as the block&squot;s contents).&n; *&n; * There can only be one cache entry in a cache per device and block number.&n; * Additional indexes need not be unique in this sense. The number of&n; * additional indexes (=other criteria) can be hardwired at compile time&n; * or specified at cache create time.&n; *&n; * Each cache entry is of fixed size. An entry may be `valid&squot; or `invalid&squot;&n; * in the cache. A valid entry is in the main hash tables of the cache,&n; * and may also be in the lru list. An invalid entry is not in any hashes&n; * or lists.&n; *&n; * A valid cache entry is only in the lru list if no handles refer to it.&n; * Invalid cache entries will be freed when the last handle to the cache&n; * entry is released. Entries that cannot be freed immediately are put&n; * back on the lru list.&n; */
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/module.h&gt;
macro_line|#include &lt;linux/hash.h&gt;
macro_line|#include &lt;linux/fs.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/slab.h&gt;
macro_line|#include &lt;linux/sched.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/mbcache.h&gt;
macro_line|#ifdef MB_CACHE_DEBUG
DECL|macro|mb_debug
macro_line|# define mb_debug(f...) do { &bslash;&n;&t;&t;printk(KERN_DEBUG f); &bslash;&n;&t;&t;printk(&quot;&bslash;n&quot;); &bslash;&n;&t;} while (0)
DECL|macro|mb_assert
mdefine_line|#define mb_assert(c) do { if (!(c)) &bslash;&n;&t;&t;printk(KERN_ERR &quot;assertion &quot; #c &quot; failed&bslash;n&quot;); &bslash;&n;&t;} while(0)
macro_line|#else
DECL|macro|mb_debug
macro_line|# define mb_debug(f...) do { } while(0)
DECL|macro|mb_assert
macro_line|# define mb_assert(c) do { } while(0)
macro_line|#endif
DECL|macro|mb_error
mdefine_line|#define mb_error(f...) do { &bslash;&n;&t;&t;printk(KERN_ERR f); &bslash;&n;&t;&t;printk(&quot;&bslash;n&quot;); &bslash;&n;&t;} while(0)
id|MODULE_AUTHOR
c_func
(paren
l_string|&quot;Andreas Gruenbacher &lt;a.gruenbacher@computer.org&gt;&quot;
)paren
suffix:semicolon
id|MODULE_DESCRIPTION
c_func
(paren
l_string|&quot;Meta block cache (for extended attributes)&quot;
)paren
suffix:semicolon
id|MODULE_LICENSE
c_func
(paren
l_string|&quot;GPL&quot;
)paren
suffix:semicolon
DECL|variable|mb_cache_create
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_create
)paren
suffix:semicolon
DECL|variable|mb_cache_shrink
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_shrink
)paren
suffix:semicolon
DECL|variable|mb_cache_destroy
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_destroy
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_alloc
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_alloc
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_insert
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_insert
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_release
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_release
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_free
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_free
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_get
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_get
)paren
suffix:semicolon
macro_line|#if !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT &gt; 0)
DECL|variable|mb_cache_entry_find_first
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_find_first
)paren
suffix:semicolon
DECL|variable|mb_cache_entry_find_next
id|EXPORT_SYMBOL
c_func
(paren
id|mb_cache_entry_find_next
)paren
suffix:semicolon
macro_line|#endif
DECL|struct|mb_cache
r_struct
id|mb_cache
(brace
DECL|member|c_cache_list
r_struct
id|list_head
id|c_cache_list
suffix:semicolon
DECL|member|c_name
r_const
r_char
op_star
id|c_name
suffix:semicolon
DECL|member|c_op
r_struct
id|mb_cache_op
id|c_op
suffix:semicolon
DECL|member|c_entry_count
id|atomic_t
id|c_entry_count
suffix:semicolon
DECL|member|c_bucket_bits
r_int
id|c_bucket_bits
suffix:semicolon
macro_line|#ifndef MB_CACHE_INDEXES_COUNT
DECL|member|c_indexes_count
r_int
id|c_indexes_count
suffix:semicolon
macro_line|#endif
DECL|member|c_entry_cache
id|kmem_cache_t
op_star
id|c_entry_cache
suffix:semicolon
DECL|member|c_block_hash
r_struct
id|list_head
op_star
id|c_block_hash
suffix:semicolon
DECL|member|c_indexes_hash
r_struct
id|list_head
op_star
id|c_indexes_hash
(braket
l_int|0
)braket
suffix:semicolon
)brace
suffix:semicolon
multiline_comment|/*&n; * Global data: list of all mbcache&squot;s, lru list, and a spinlock for&n; * accessing cache data structures on SMP machines. The lru list is&n; * global across all mbcaches.&n; */
r_static
id|LIST_HEAD
c_func
(paren
id|mb_cache_list
)paren
suffix:semicolon
r_static
id|LIST_HEAD
c_func
(paren
id|mb_cache_lru_list
)paren
suffix:semicolon
DECL|variable|mb_cache_spinlock
r_static
id|spinlock_t
id|mb_cache_spinlock
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
DECL|variable|mb_shrinker
r_static
r_struct
id|shrinker
op_star
id|mb_shrinker
suffix:semicolon
r_static
r_inline
r_int
DECL|function|mb_cache_indexes
id|mb_cache_indexes
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
)paren
(brace
macro_line|#ifdef MB_CACHE_INDEXES_COUNT
r_return
id|MB_CACHE_INDEXES_COUNT
suffix:semicolon
macro_line|#else
r_return
id|cache-&gt;c_indexes_count
suffix:semicolon
macro_line|#endif
)brace
multiline_comment|/*&n; * What the mbcache registers as to get shrunk dynamically.&n; */
r_static
r_int
id|mb_cache_shrink_fn
c_func
(paren
r_int
id|nr_to_scan
comma
r_int
r_int
id|gfp_mask
)paren
suffix:semicolon
r_static
r_inline
r_int
DECL|function|__mb_cache_entry_is_hashed
id|__mb_cache_entry_is_hashed
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
)paren
(brace
r_return
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|ce-&gt;e_block_list
)paren
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|__mb_cache_entry_unhash
id|__mb_cache_entry_unhash
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
)paren
(brace
r_int
id|n
suffix:semicolon
r_if
c_cond
(paren
id|__mb_cache_entry_is_hashed
c_func
(paren
id|ce
)paren
)paren
(brace
id|list_del_init
c_func
(paren
op_amp
id|ce-&gt;e_block_list
)paren
suffix:semicolon
r_for
c_loop
(paren
id|n
op_assign
l_int|0
suffix:semicolon
id|n
OL
id|mb_cache_indexes
c_func
(paren
id|ce-&gt;e_cache
)paren
suffix:semicolon
id|n
op_increment
)paren
id|list_del
c_func
(paren
op_amp
id|ce-&gt;e_indexes
(braket
id|n
)braket
dot
id|o_list
)paren
suffix:semicolon
)brace
)brace
r_static
r_inline
r_void
DECL|function|__mb_cache_entry_forget
id|__mb_cache_entry_forget
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
comma
r_int
id|gfp_mask
)paren
(brace
r_struct
id|mb_cache
op_star
id|cache
op_assign
id|ce-&gt;e_cache
suffix:semicolon
id|mb_assert
c_func
(paren
id|atomic_read
c_func
(paren
op_amp
id|ce-&gt;e_used
)paren
op_eq
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cache-&gt;c_op.free
op_logical_and
id|cache-&gt;c_op
dot
id|free
c_func
(paren
id|ce
comma
id|gfp_mask
)paren
)paren
(brace
multiline_comment|/* free failed -- put back on the lru list&n;&t;&t;   for freeing later. */
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
comma
op_amp
id|mb_cache_lru_list
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
)brace
r_else
(brace
id|kmem_cache_free
c_func
(paren
id|cache-&gt;c_entry_cache
comma
id|ce
)paren
suffix:semicolon
id|atomic_dec
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
suffix:semicolon
)brace
)brace
r_static
r_inline
r_void
DECL|function|__mb_cache_entry_release_unlock
id|__mb_cache_entry_release_unlock
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
)paren
(brace
r_if
c_cond
(paren
id|atomic_dec_and_test
c_func
(paren
op_amp
id|ce-&gt;e_used
)paren
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|__mb_cache_entry_is_hashed
c_func
(paren
id|ce
)paren
)paren
r_goto
id|forget
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
comma
op_amp
id|mb_cache_lru_list
)paren
suffix:semicolon
)brace
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_return
suffix:semicolon
id|forget
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|__mb_cache_entry_forget
c_func
(paren
id|ce
comma
id|GFP_KERNEL
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_shrink_fn()  memory pressure callback&n; *&n; * This function is called by the kernel memory management when memory&n; * gets low.&n; *&n; * @nr_to_scan: Number of objects to scan&n; * @gfp_mask: (ignored)&n; *&n; * Returns the number of objects which are present in the cache.&n; */
r_static
r_int
DECL|function|mb_cache_shrink_fn
id|mb_cache_shrink_fn
c_func
(paren
r_int
id|nr_to_scan
comma
r_int
r_int
id|gfp_mask
)paren
(brace
id|LIST_HEAD
c_func
(paren
id|free_list
)paren
suffix:semicolon
r_struct
id|list_head
op_star
id|l
comma
op_star
id|ltmp
suffix:semicolon
r_int
id|count
op_assign
l_int|0
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each
c_func
(paren
id|l
comma
op_amp
id|mb_cache_list
)paren
(brace
r_struct
id|mb_cache
op_star
id|cache
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache
comma
id|c_cache_list
)paren
suffix:semicolon
id|mb_debug
c_func
(paren
l_string|&quot;cache %s (%d)&quot;
comma
id|cache-&gt;c_name
comma
id|atomic_read
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
)paren
suffix:semicolon
id|count
op_add_assign
id|atomic_read
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
suffix:semicolon
)brace
id|mb_debug
c_func
(paren
l_string|&quot;trying to free %d entries&quot;
comma
id|nr_to_scan
)paren
suffix:semicolon
r_if
c_cond
(paren
id|nr_to_scan
op_eq
l_int|0
)paren
(brace
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
)brace
r_while
c_loop
(paren
id|nr_to_scan
op_decrement
op_logical_and
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|mb_cache_lru_list
)paren
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
op_assign
id|list_entry
c_func
(paren
id|mb_cache_lru_list.next
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
suffix:semicolon
id|list_move_tail
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
comma
op_amp
id|free_list
)paren
suffix:semicolon
id|__mb_cache_entry_unhash
c_func
(paren
id|ce
)paren
suffix:semicolon
)brace
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|l
comma
id|ltmp
comma
op_amp
id|free_list
)paren
(brace
id|__mb_cache_entry_forget
c_func
(paren
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
comma
id|gfp_mask
)paren
suffix:semicolon
)brace
id|out
suffix:colon
r_return
id|count
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_create()  create a new cache&n; *&n; * All entries in one cache are equal size. Cache entries may be from&n; * multiple devices. If this is the first mbcache created, registers&n; * the cache with kernel memory management. Returns NULL if no more&n; * memory was available.&n; *&n; * @name: name of the cache (informal)&n; * @cache_op: contains the callback called when freeing a cache entry&n; * @entry_size: The size of a cache entry, including&n; *              struct mb_cache_entry&n; * @indexes_count: number of additional indexes in the cache. Must equal&n; *                 MB_CACHE_INDEXES_COUNT if the number of indexes is&n; *                 hardwired.&n; * @bucket_bits: log2(number of hash buckets)&n; */
r_struct
id|mb_cache
op_star
DECL|function|mb_cache_create
id|mb_cache_create
c_func
(paren
r_const
r_char
op_star
id|name
comma
r_struct
id|mb_cache_op
op_star
id|cache_op
comma
r_int
id|entry_size
comma
r_int
id|indexes_count
comma
r_int
id|bucket_bits
)paren
(brace
r_int
id|m
op_assign
l_int|0
comma
id|n
comma
id|bucket_count
op_assign
l_int|1
op_lshift
id|bucket_bits
suffix:semicolon
r_struct
id|mb_cache
op_star
id|cache
op_assign
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|entry_size
OL
r_sizeof
(paren
r_struct
id|mb_cache_entry
)paren
op_plus
id|indexes_count
op_star
r_sizeof
(paren
(paren
(paren
r_struct
id|mb_cache_entry
op_star
)paren
l_int|0
)paren
op_member_access_from_pointer
id|e_indexes
(braket
l_int|0
)braket
)paren
)paren
(brace
r_return
l_int|NULL
suffix:semicolon
)brace
id|cache
op_assign
id|kmalloc
c_func
(paren
r_sizeof
(paren
r_struct
id|mb_cache
)paren
op_plus
id|indexes_count
op_star
r_sizeof
(paren
r_struct
id|list_head
)paren
comma
id|GFP_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|cache
)paren
r_goto
id|fail
suffix:semicolon
id|cache-&gt;c_name
op_assign
id|name
suffix:semicolon
id|cache-&gt;c_op.free
op_assign
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|cache_op
)paren
id|cache-&gt;c_op.free
op_assign
id|cache_op-&gt;free
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
comma
l_int|0
)paren
suffix:semicolon
id|cache-&gt;c_bucket_bits
op_assign
id|bucket_bits
suffix:semicolon
macro_line|#ifdef MB_CACHE_INDEXES_COUNT
id|mb_assert
c_func
(paren
id|indexes_count
op_eq
id|MB_CACHE_INDEXES_COUNT
)paren
suffix:semicolon
macro_line|#else
id|cache-&gt;c_indexes_count
op_assign
id|indexes_count
suffix:semicolon
macro_line|#endif
id|cache-&gt;c_block_hash
op_assign
id|kmalloc
c_func
(paren
id|bucket_count
op_star
r_sizeof
(paren
r_struct
id|list_head
)paren
comma
id|GFP_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|cache-&gt;c_block_hash
)paren
r_goto
id|fail
suffix:semicolon
r_for
c_loop
(paren
id|n
op_assign
l_int|0
suffix:semicolon
id|n
OL
id|bucket_count
suffix:semicolon
id|n
op_increment
)paren
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|cache-&gt;c_block_hash
(braket
id|n
)braket
)paren
suffix:semicolon
r_for
c_loop
(paren
id|m
op_assign
l_int|0
suffix:semicolon
id|m
OL
id|indexes_count
suffix:semicolon
id|m
op_increment
)paren
(brace
id|cache-&gt;c_indexes_hash
(braket
id|m
)braket
op_assign
id|kmalloc
c_func
(paren
id|bucket_count
op_star
r_sizeof
(paren
r_struct
id|list_head
)paren
comma
id|GFP_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|cache-&gt;c_indexes_hash
(braket
id|m
)braket
)paren
r_goto
id|fail
suffix:semicolon
r_for
c_loop
(paren
id|n
op_assign
l_int|0
suffix:semicolon
id|n
OL
id|bucket_count
suffix:semicolon
id|n
op_increment
)paren
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|cache-&gt;c_indexes_hash
(braket
id|m
)braket
(braket
id|n
)braket
)paren
suffix:semicolon
)brace
id|cache-&gt;c_entry_cache
op_assign
id|kmem_cache_create
c_func
(paren
id|name
comma
id|entry_size
comma
l_int|0
comma
id|SLAB_RECLAIM_ACCOUNT
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|cache-&gt;c_entry_cache
)paren
r_goto
id|fail
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|cache-&gt;c_cache_list
comma
op_amp
id|mb_cache_list
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_return
id|cache
suffix:semicolon
id|fail
suffix:colon
r_if
c_cond
(paren
id|cache
)paren
(brace
r_while
c_loop
(paren
op_decrement
id|m
op_ge
l_int|0
)paren
id|kfree
c_func
(paren
id|cache-&gt;c_indexes_hash
(braket
id|m
)braket
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cache-&gt;c_block_hash
)paren
id|kfree
c_func
(paren
id|cache-&gt;c_block_hash
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|cache
)paren
suffix:semicolon
)brace
r_return
l_int|NULL
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_shrink()&n; *&n; * Removes all cache entires of a device from the cache. All cache entries&n; * currently in use cannot be freed, and thus remain in the cache. All others&n; * are freed.&n; *&n; * @cache: which cache to shrink&n; * @bdev: which device&squot;s cache entries to shrink&n; */
r_void
DECL|function|mb_cache_shrink
id|mb_cache_shrink
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
comma
r_struct
id|block_device
op_star
id|bdev
)paren
(brace
id|LIST_HEAD
c_func
(paren
id|free_list
)paren
suffix:semicolon
r_struct
id|list_head
op_star
id|l
comma
op_star
id|ltmp
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|l
comma
id|ltmp
comma
op_amp
id|mb_cache_lru_list
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce-&gt;e_bdev
op_eq
id|bdev
)paren
(brace
id|list_move_tail
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
comma
op_amp
id|free_list
)paren
suffix:semicolon
id|__mb_cache_entry_unhash
c_func
(paren
id|ce
)paren
suffix:semicolon
)brace
)brace
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|l
comma
id|ltmp
comma
op_amp
id|free_list
)paren
(brace
id|__mb_cache_entry_forget
c_func
(paren
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
comma
id|GFP_KERNEL
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * mb_cache_destroy()&n; *&n; * Shrinks the cache to its minimum possible size (hopefully 0 entries),&n; * and then destroys it. If this was the last mbcache, un-registers the&n; * mbcache from kernel memory management.&n; */
r_void
DECL|function|mb_cache_destroy
id|mb_cache_destroy
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
)paren
(brace
id|LIST_HEAD
c_func
(paren
id|free_list
)paren
suffix:semicolon
r_struct
id|list_head
op_star
id|l
comma
op_star
id|ltmp
suffix:semicolon
r_int
id|n
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|l
comma
id|ltmp
comma
op_amp
id|mb_cache_lru_list
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce-&gt;e_cache
op_eq
id|cache
)paren
(brace
id|list_move_tail
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
comma
op_amp
id|free_list
)paren
suffix:semicolon
id|__mb_cache_entry_unhash
c_func
(paren
id|ce
)paren
suffix:semicolon
)brace
)brace
id|list_del
c_func
(paren
op_amp
id|cache-&gt;c_cache_list
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|l
comma
id|ltmp
comma
op_amp
id|free_list
)paren
(brace
id|__mb_cache_entry_forget
c_func
(paren
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_lru_list
)paren
comma
id|GFP_KERNEL
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|atomic_read
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
OG
l_int|0
)paren
(brace
id|mb_error
c_func
(paren
l_string|&quot;cache %s: %d orphaned entries&quot;
comma
id|cache-&gt;c_name
comma
id|atomic_read
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
)paren
suffix:semicolon
)brace
id|kmem_cache_destroy
c_func
(paren
id|cache-&gt;c_entry_cache
)paren
suffix:semicolon
r_for
c_loop
(paren
id|n
op_assign
l_int|0
suffix:semicolon
id|n
OL
id|mb_cache_indexes
c_func
(paren
id|cache
)paren
suffix:semicolon
id|n
op_increment
)paren
id|kfree
c_func
(paren
id|cache-&gt;c_indexes_hash
(braket
id|n
)braket
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|cache-&gt;c_block_hash
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|cache
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_alloc()&n; *&n; * Allocates a new cache entry. The new entry will not be valid initially,&n; * and thus cannot be looked up yet. It should be filled with data, and&n; * then inserted into the cache using mb_cache_entry_insert(). Returns NULL&n; * if no more memory was available.&n; */
r_struct
id|mb_cache_entry
op_star
DECL|function|mb_cache_entry_alloc
id|mb_cache_entry_alloc
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|cache-&gt;c_entry_count
)paren
suffix:semicolon
id|ce
op_assign
id|kmem_cache_alloc
c_func
(paren
id|cache-&gt;c_entry_cache
comma
id|GFP_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce
)paren
(brace
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|ce-&gt;e_block_list
)paren
suffix:semicolon
id|ce-&gt;e_cache
op_assign
id|cache
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|ce-&gt;e_used
comma
l_int|1
)paren
suffix:semicolon
)brace
r_return
id|ce
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_insert()&n; *&n; * Inserts an entry that was allocated using mb_cache_entry_alloc() into&n; * the cache. After this, the cache entry can be looked up, but is not yet&n; * in the lru list as the caller still holds a handle to it. Returns 0 on&n; * success, or -EBUSY if a cache entry for that device + inode exists&n; * already (this may happen after a failed lookup, but when another process&n; * has inserted the same cache entry in the meantime).&n; *&n; * @bdev: device the cache entry belongs to&n; * @block: block number&n; * @keys: array of additional keys. There must be indexes_count entries&n; *        in the array (as specified when creating the cache).&n; */
r_int
DECL|function|mb_cache_entry_insert
id|mb_cache_entry_insert
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
comma
r_struct
id|block_device
op_star
id|bdev
comma
id|sector_t
id|block
comma
r_int
r_int
id|keys
(braket
)braket
)paren
(brace
r_struct
id|mb_cache
op_star
id|cache
op_assign
id|ce-&gt;e_cache
suffix:semicolon
r_int
r_int
id|bucket
suffix:semicolon
r_struct
id|list_head
op_star
id|l
suffix:semicolon
r_int
id|error
op_assign
op_minus
id|EBUSY
comma
id|n
suffix:semicolon
id|bucket
op_assign
id|hash_long
c_func
(paren
(paren
r_int
r_int
)paren
id|bdev
op_plus
(paren
id|block
op_amp
l_int|0xffffffff
)paren
comma
id|cache-&gt;c_bucket_bits
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each_prev
c_func
(paren
id|l
comma
op_amp
id|cache-&gt;c_block_hash
(braket
id|bucket
)braket
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_block_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce-&gt;e_bdev
op_eq
id|bdev
op_logical_and
id|ce-&gt;e_block
op_eq
id|block
)paren
r_goto
id|out
suffix:semicolon
)brace
id|__mb_cache_entry_unhash
c_func
(paren
id|ce
)paren
suffix:semicolon
id|ce-&gt;e_bdev
op_assign
id|bdev
suffix:semicolon
id|ce-&gt;e_block
op_assign
id|block
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|ce-&gt;e_block_list
comma
op_amp
id|cache-&gt;c_block_hash
(braket
id|bucket
)braket
)paren
suffix:semicolon
r_for
c_loop
(paren
id|n
op_assign
l_int|0
suffix:semicolon
id|n
OL
id|mb_cache_indexes
c_func
(paren
id|cache
)paren
suffix:semicolon
id|n
op_increment
)paren
(brace
id|ce-&gt;e_indexes
(braket
id|n
)braket
dot
id|o_key
op_assign
id|keys
(braket
id|n
)braket
suffix:semicolon
id|bucket
op_assign
id|hash_long
c_func
(paren
id|keys
(braket
id|n
)braket
comma
id|cache-&gt;c_bucket_bits
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|ce-&gt;e_indexes
(braket
id|n
)braket
dot
id|o_list
comma
op_amp
id|cache-&gt;c_indexes_hash
(braket
id|n
)braket
(braket
id|bucket
)braket
)paren
suffix:semicolon
)brace
id|error
op_assign
l_int|0
suffix:semicolon
id|out
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_return
id|error
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_release()&n; *&n; * Release a handle to a cache entry. When the last handle to a cache entry&n; * is released it is either freed (if it is invalid) or otherwise inserted&n; * in to the lru list.&n; */
r_void
DECL|function|mb_cache_entry_release
id|mb_cache_entry_release
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|__mb_cache_entry_release_unlock
c_func
(paren
id|ce
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_free()&n; *&n; * This is equivalent to the sequence mb_cache_entry_takeout() --&n; * mb_cache_entry_release().&n; */
r_void
DECL|function|mb_cache_entry_free
id|mb_cache_entry_free
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|ce
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|mb_assert
c_func
(paren
id|list_empty
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
)paren
suffix:semicolon
id|__mb_cache_entry_unhash
c_func
(paren
id|ce
)paren
suffix:semicolon
id|__mb_cache_entry_release_unlock
c_func
(paren
id|ce
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_get()&n; *&n; * Get a cache entry  by device / block number. (There can only be one entry&n; * in the cache per device and block.) Returns NULL if no such cache entry&n; * exists.&n; */
r_struct
id|mb_cache_entry
op_star
DECL|function|mb_cache_entry_get
id|mb_cache_entry_get
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
comma
r_struct
id|block_device
op_star
id|bdev
comma
id|sector_t
id|block
)paren
(brace
r_int
r_int
id|bucket
suffix:semicolon
r_struct
id|list_head
op_star
id|l
suffix:semicolon
r_struct
id|mb_cache_entry
op_star
id|ce
suffix:semicolon
id|bucket
op_assign
id|hash_long
c_func
(paren
(paren
r_int
r_int
)paren
id|bdev
op_plus
(paren
id|block
op_amp
l_int|0xffffffff
)paren
comma
id|cache-&gt;c_bucket_bits
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|list_for_each
c_func
(paren
id|l
comma
op_amp
id|cache-&gt;c_block_hash
(braket
id|bucket
)braket
)paren
(brace
id|ce
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_block_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce-&gt;e_bdev
op_eq
id|bdev
op_logical_and
id|ce-&gt;e_block
op_eq
id|block
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
)paren
id|list_del_init
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|ce-&gt;e_used
)paren
suffix:semicolon
r_goto
id|cleanup
suffix:semicolon
)brace
)brace
id|ce
op_assign
l_int|NULL
suffix:semicolon
id|cleanup
suffix:colon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_return
id|ce
suffix:semicolon
)brace
macro_line|#if !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT &gt; 0)
r_static
r_struct
id|mb_cache_entry
op_star
DECL|function|__mb_cache_entry_find
id|__mb_cache_entry_find
c_func
(paren
r_struct
id|list_head
op_star
id|l
comma
r_struct
id|list_head
op_star
id|head
comma
r_int
id|index
comma
r_struct
id|block_device
op_star
id|bdev
comma
r_int
r_int
id|key
)paren
(brace
r_while
c_loop
(paren
id|l
op_ne
id|head
)paren
(brace
r_struct
id|mb_cache_entry
op_star
id|ce
op_assign
id|list_entry
c_func
(paren
id|l
comma
r_struct
id|mb_cache_entry
comma
id|e_indexes
(braket
id|index
)braket
dot
id|o_list
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ce-&gt;e_bdev
op_eq
id|bdev
op_logical_and
id|ce-&gt;e_indexes
(braket
id|index
)braket
dot
id|o_key
op_eq
id|key
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
)paren
id|list_del_init
c_func
(paren
op_amp
id|ce-&gt;e_lru_list
)paren
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|ce-&gt;e_used
)paren
suffix:semicolon
r_return
id|ce
suffix:semicolon
)brace
id|l
op_assign
id|l-&gt;next
suffix:semicolon
)brace
r_return
l_int|NULL
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_find_first()&n; *&n; * Find the first cache entry on a given device with a certain key in&n; * an additional index. Additonal matches can be found with&n; * mb_cache_entry_find_next(). Returns NULL if no match was found.&n; *&n; * @cache: the cache to search&n; * @index: the number of the additonal index to search (0&lt;=index&lt;indexes_count)&n; * @bdev: the device the cache entry should belong to&n; * @key: the key in the index&n; */
r_struct
id|mb_cache_entry
op_star
DECL|function|mb_cache_entry_find_first
id|mb_cache_entry_find_first
c_func
(paren
r_struct
id|mb_cache
op_star
id|cache
comma
r_int
id|index
comma
r_struct
id|block_device
op_star
id|bdev
comma
r_int
r_int
id|key
)paren
(brace
r_int
r_int
id|bucket
op_assign
id|hash_long
c_func
(paren
id|key
comma
id|cache-&gt;c_bucket_bits
)paren
suffix:semicolon
r_struct
id|list_head
op_star
id|l
suffix:semicolon
r_struct
id|mb_cache_entry
op_star
id|ce
suffix:semicolon
id|mb_assert
c_func
(paren
id|index
OL
id|mb_cache_indexes
c_func
(paren
id|cache
)paren
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|l
op_assign
id|cache-&gt;c_indexes_hash
(braket
id|index
)braket
(braket
id|bucket
)braket
dot
id|next
suffix:semicolon
id|ce
op_assign
id|__mb_cache_entry_find
c_func
(paren
id|l
comma
op_amp
id|cache-&gt;c_indexes_hash
(braket
id|index
)braket
(braket
id|bucket
)braket
comma
id|index
comma
id|bdev
comma
id|key
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
r_return
id|ce
suffix:semicolon
)brace
multiline_comment|/*&n; * mb_cache_entry_find_next()&n; *&n; * Find the next cache entry on a given device with a certain key in an&n; * additional index. Returns NULL if no match could be found. The previous&n; * entry is atomatically released, so that mb_cache_entry_find_next() can&n; * be called like this:&n; *&n; * entry = mb_cache_entry_find_first();&n; * while (entry) {&n; * &t;...&n; *&t;entry = mb_cache_entry_find_next(entry, ...);&n; * }&n; *&n; * @prev: The previous match&n; * @index: the number of the additonal index to search (0&lt;=index&lt;indexes_count)&n; * @bdev: the device the cache entry should belong to&n; * @key: the key in the index&n; */
r_struct
id|mb_cache_entry
op_star
DECL|function|mb_cache_entry_find_next
id|mb_cache_entry_find_next
c_func
(paren
r_struct
id|mb_cache_entry
op_star
id|prev
comma
r_int
id|index
comma
r_struct
id|block_device
op_star
id|bdev
comma
r_int
r_int
id|key
)paren
(brace
r_struct
id|mb_cache
op_star
id|cache
op_assign
id|prev-&gt;e_cache
suffix:semicolon
r_int
r_int
id|bucket
op_assign
id|hash_long
c_func
(paren
id|key
comma
id|cache-&gt;c_bucket_bits
)paren
suffix:semicolon
r_struct
id|list_head
op_star
id|l
suffix:semicolon
r_struct
id|mb_cache_entry
op_star
id|ce
suffix:semicolon
id|mb_assert
c_func
(paren
id|index
OL
id|mb_cache_indexes
c_func
(paren
id|cache
)paren
)paren
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|mb_cache_spinlock
)paren
suffix:semicolon
id|l
op_assign
id|prev-&gt;e_indexes
(braket
id|index
)braket
dot
id|o_list.next
suffix:semicolon
id|ce
op_assign
id|__mb_cache_entry_find
c_func
(paren
id|l
comma
op_amp
id|cache-&gt;c_indexes_hash
(braket
id|index
)braket
(braket
id|bucket
)braket
comma
id|index
comma
id|bdev
comma
id|key
)paren
suffix:semicolon
id|__mb_cache_entry_release_unlock
c_func
(paren
id|prev
)paren
suffix:semicolon
r_return
id|ce
suffix:semicolon
)brace
macro_line|#endif  /* !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT &gt; 0) */
DECL|function|init_mbcache
r_static
r_int
id|__init
id|init_mbcache
c_func
(paren
r_void
)paren
(brace
id|mb_shrinker
op_assign
id|set_shrinker
c_func
(paren
id|DEFAULT_SEEKS
comma
id|mb_cache_shrink_fn
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|exit_mbcache
r_static
r_void
id|__exit
id|exit_mbcache
c_func
(paren
r_void
)paren
(brace
id|remove_shrinker
c_func
(paren
id|mb_shrinker
)paren
suffix:semicolon
)brace
id|module_init
c_func
(paren
id|init_mbcache
)paren
id|module_exit
c_func
(paren
id|exit_mbcache
)paren
eof
