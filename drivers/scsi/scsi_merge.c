multiline_comment|/*&n; *  scsi_merge.c Copyright (C) 1999 Eric Youngdale&n; *&n; *  SCSI queueing library.&n; *      Initial versions: Eric Youngdale (eric@andante.org).&n; *                        Based upon conversations with large numbers&n; *                        of people at Linux Expo.&n; *&t;Support for dynamic DMA mapping: Jakub Jelinek (jakub@redhat.com).&n; *&t;Support for highmem I/O: Jens Axboe &lt;axboe@suse.de&gt;&n; */
multiline_comment|/*&n; * This file contains queue management functions that are used by SCSI.&n; * Typically this is used for several purposes.   First, we need to ensure&n; * that commands do not grow so large that they cannot be handled all at&n; * once by a host adapter.   The various flavors of merge functions included&n; * here serve this purpose.&n; *&n; * Note that it would be quite trivial to allow the low-level driver the&n; * flexibility to define it&squot;s own queue handling functions.  For the time&n; * being, the hooks are not present.   Right now we are just using the&n; * data in the host template as an indicator of how we should be handling&n; * queues, and we select routines that are optimized for that purpose.&n; *&n; * Some hosts do not impose any restrictions on the size of a request.&n; * In such cases none of the merge functions in this file are called,&n; * and we allow ll_rw_blk to merge requests in the default manner.&n; * This isn&squot;t guaranteed to be optimal, but it should be pretty darned&n; * good.   If someone comes up with ideas of better ways of managing queues&n; * to improve on the default behavior, then certainly fit it into this&n; * scheme in whatever manner makes the most sense.   Please note that&n; * since each device has it&squot;s own queue, we have considerable flexibility&n; * in queue management.&n; */
DECL|macro|__NO_VERSION__
mdefine_line|#define __NO_VERSION__
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/module.h&gt;
macro_line|#include &lt;linux/sched.h&gt;
macro_line|#include &lt;linux/timer.h&gt;
macro_line|#include &lt;linux/string.h&gt;
macro_line|#include &lt;linux/slab.h&gt;
macro_line|#include &lt;linux/ioport.h&gt;
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/stat.h&gt;
macro_line|#include &lt;linux/blk.h&gt;
macro_line|#include &lt;linux/interrupt.h&gt;
macro_line|#include &lt;linux/delay.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
DECL|macro|__KERNEL_SYSCALLS__
mdefine_line|#define __KERNEL_SYSCALLS__
macro_line|#include &lt;linux/unistd.h&gt;
macro_line|#include &lt;asm/system.h&gt;
macro_line|#include &lt;asm/irq.h&gt;
macro_line|#include &lt;asm/dma.h&gt;
macro_line|#include &lt;asm/io.h&gt;
macro_line|#include &quot;scsi.h&quot;
macro_line|#include &quot;hosts.h&quot;
macro_line|#include &quot;constants.h&quot;
macro_line|#include &lt;scsi/scsi_ioctl.h&gt;
multiline_comment|/*&n; * This means that bounce buffers cannot be allocated in chunks &gt; PAGE_SIZE.&n; * Ultimately we should get away from using a dedicated DMA bounce buffer&n; * pool, and we should instead try and use kmalloc() instead.  If we can&n; * eliminate this pool, then this restriction would no longer be needed.&n; */
DECL|macro|DMA_SEGMENT_SIZE_LIMITED
mdefine_line|#define DMA_SEGMENT_SIZE_LIMITED
DECL|function|dma_exhausted
r_static
r_void
id|dma_exhausted
c_func
(paren
id|Scsi_Cmnd
op_star
id|SCpnt
comma
r_int
id|i
)paren
(brace
r_int
id|jj
suffix:semicolon
r_struct
id|scatterlist
op_star
id|sgpnt
suffix:semicolon
r_void
op_star
op_star
id|bbpnt
suffix:semicolon
r_int
id|consumed
op_assign
l_int|0
suffix:semicolon
id|sgpnt
op_assign
(paren
r_struct
id|scatterlist
op_star
)paren
id|SCpnt-&gt;request_buffer
suffix:semicolon
id|bbpnt
op_assign
id|SCpnt-&gt;bounce_buffers
suffix:semicolon
multiline_comment|/*&n;&t; * Now print out a bunch of stats.  First, start with the request&n;&t; * size.&n;&t; */
id|printk
c_func
(paren
l_string|&quot;dma_free_sectors:%d&bslash;n&quot;
comma
id|scsi_dma_free_sectors
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;use_sg:%d&bslash;ti:%d&bslash;n&quot;
comma
id|SCpnt-&gt;use_sg
comma
id|i
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;request_bufflen:%d&bslash;n&quot;
comma
id|SCpnt-&gt;request_bufflen
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Now dump the scatter-gather table, up to the point of failure.&n;&t; */
r_for
c_loop
(paren
id|jj
op_assign
l_int|0
suffix:semicolon
id|jj
OL
id|SCpnt-&gt;use_sg
suffix:semicolon
id|jj
op_increment
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;[%d]&bslash;tlen:%d&bslash;taddr:%p&bslash;tbounce:%p&bslash;n&quot;
comma
id|jj
comma
id|sgpnt
(braket
id|jj
)braket
dot
id|length
comma
id|sgpnt
(braket
id|jj
)braket
dot
id|address
comma
(paren
id|bbpnt
ques
c_cond
id|bbpnt
(braket
id|jj
)braket
suffix:colon
l_int|NULL
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|bbpnt
op_logical_and
id|bbpnt
(braket
id|jj
)braket
)paren
id|consumed
op_add_assign
id|sgpnt
(braket
id|jj
)braket
dot
id|length
suffix:semicolon
)brace
id|printk
c_func
(paren
l_string|&quot;Total %d sectors consumed&bslash;n&quot;
comma
id|consumed
)paren
suffix:semicolon
id|panic
c_func
(paren
l_string|&quot;DMA pool exhausted&quot;
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This entire source file deals with the new queueing code.&n; */
multiline_comment|/*&n; * Function:    __count_segments()&n; *&n; * Purpose:     Prototype for queue merge function.&n; *&n; * Arguments:   q       - Queue for which we are merging request.&n; *              req     - request into which we wish to merge.&n; *              dma_host - 1 if this host has ISA DMA issues (bus doesn&squot;t&n; *                      expose all of the address lines, so that DMA cannot&n; *                      be done from an arbitrary address).&n; *&t;&t;remainder - used to track the residual size of the last&n; *&t;&t;&t;segment.  Comes in handy when we want to limit the &n; *&t;&t;&t;size of bounce buffer segments to PAGE_SIZE.&n; *&n; * Returns:     Count of the number of SG segments for the request.&n; *&n; * Lock status: &n; *&n; * Notes:       This is only used for diagnostic purposes.&n; */
DECL|function|__count_segments
id|__inline
r_static
r_int
id|__count_segments
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|dma_host
comma
r_int
op_star
id|remainder
)paren
(brace
r_int
id|ret
op_assign
l_int|1
suffix:semicolon
r_int
id|reqsize
op_assign
l_int|0
suffix:semicolon
r_int
id|i
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_struct
id|bio_vec
op_star
id|bvec
suffix:semicolon
r_if
c_cond
(paren
id|remainder
)paren
id|reqsize
op_assign
op_star
id|remainder
suffix:semicolon
multiline_comment|/*&n;&t; * Add in the size increment for the first buffer.&n;&t; */
id|bio
op_assign
id|req-&gt;bio
suffix:semicolon
macro_line|#ifdef DMA_SEGMENT_SIZE_LIMITED
r_if
c_cond
(paren
id|reqsize
op_plus
id|bio-&gt;bi_size
OG
id|PAGE_SIZE
)paren
id|ret
op_increment
suffix:semicolon
macro_line|#endif
id|rq_for_each_bio
c_func
(paren
id|bio
comma
id|req
)paren
(brace
id|bio_for_each_segment
c_func
(paren
id|bvec
comma
id|bio
comma
id|i
)paren
id|ret
op_increment
suffix:semicolon
id|reqsize
op_add_assign
id|bio-&gt;bi_size
suffix:semicolon
)brace
r_if
c_cond
(paren
id|remainder
)paren
op_star
id|remainder
op_assign
id|reqsize
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/*&n; * Function:    recount_segments()&n; *&n; * Purpose:     Recount the number of scatter-gather segments for this request.&n; *&n; * Arguments:   req     - request that needs recounting.&n; *&n; * Returns:     Count of the number of SG segments for the request.&n; *&n; * Lock status: Irrelevant.&n; *&n; * Notes:&t;This is only used when we have partially completed requests&n; *&t;&t;and the bit that is leftover is of an indeterminate size.&n; *&t;&t;This can come up if you get a MEDIUM_ERROR, for example,&n; *&t;&t;as we will have &quot;completed&quot; all of the sectors up to and&n; *&t;&t;including the bad sector, and the leftover bit is what&n; *&t;&t;we have to do now.  This tends to be a rare occurrence, so&n; *&t;&t;we aren&squot;t busting our butts to instantiate separate versions&n; *&t;&t;of this function for the 4 different flag values.  We&n; *&t;&t;probably should, however.&n; */
r_void
DECL|function|recount_segments
id|recount_segments
c_func
(paren
id|Scsi_Cmnd
op_star
id|SCpnt
)paren
(brace
r_struct
id|request
op_star
id|req
op_assign
op_amp
id|SCpnt-&gt;request
suffix:semicolon
r_struct
id|Scsi_Host
op_star
id|SHpnt
op_assign
id|SCpnt-&gt;host
suffix:semicolon
id|req-&gt;nr_segments
op_assign
id|__count_segments
c_func
(paren
id|req
comma
id|SHpnt-&gt;unchecked_isa_dma
comma
l_int|NULL
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * IOMMU hackery for sparc64&n; */
macro_line|#ifdef DMA_CHUNK_SIZE
DECL|macro|MERGEABLE_BUFFERS
mdefine_line|#define MERGEABLE_BUFFERS(X,Y) &bslash;&n;&t;((((bvec_to_phys(__BVEC_END((X))) + __BVEC_END((X))-&gt;bv_len) | bio_to_phys((Y))) &amp; (DMA_CHUNK_SIZE - 1)) == 0)
DECL|function|scsi_new_mergeable
r_static
r_inline
r_int
id|scsi_new_mergeable
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_segs
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * pci_map_sg will be able to merge these two&n;&t; * into a single hardware sg entry, check if&n;&t; * we&squot;ll have enough memory for the sg list.&n;&t; * scsi.c allocates for this purpose&n;&t; * min(64,sg_tablesize) entries.&n;&t; */
r_if
c_cond
(paren
id|req-&gt;nr_segments
op_plus
id|nr_segs
OG
id|q-&gt;max_segments
)paren
r_return
l_int|0
suffix:semicolon
id|req-&gt;nr_segments
op_add_assign
id|nr_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|scsi_new_segment
r_static
r_inline
r_int
id|scsi_new_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_segs
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * pci_map_sg won&squot;t be able to map these two&n;&t; * into a single hardware sg entry, so we have to&n;&t; * check if things fit into sg_tablesize.&n;&t; */
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_plus
id|nr_segs
OG
id|q-&gt;max_segments
)paren
r_return
l_int|0
suffix:semicolon
r_else
r_if
c_cond
(paren
id|req-&gt;nr_segments
op_plus
id|nr_segs
OG
id|q-&gt;max_segments
)paren
r_return
l_int|0
suffix:semicolon
id|req-&gt;nr_hw_segments
op_add_assign
id|nr_segs
suffix:semicolon
id|req-&gt;nr_segments
op_add_assign
id|nr_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
macro_line|#else /* DMA_CHUNK_SIZE */
DECL|function|scsi_new_segment
r_static
r_inline
r_int
id|scsi_new_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_segs
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_segments
op_plus
id|nr_segs
OG
id|q-&gt;max_segments
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * This will form the start of a new segment.  Bump the &n;&t; * counter.&n;&t; */
id|req-&gt;nr_segments
op_add_assign
id|nr_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
macro_line|#endif /* DMA_CHUNK_SIZE */
multiline_comment|/*&n; * Function:    __scsi_merge_fn()&n; *&n; * Purpose:     Prototype for queue merge function.&n; *&n; * Arguments:   q       - Queue for which we are merging request.&n; *              req     - request into which we wish to merge.&n; *              bio     - Block which we may wish to merge into request&n; *              dma_host - 1 if this host has ISA DMA issues (bus doesn&squot;t&n; *                      expose all of the address lines, so that DMA cannot&n; *                      be done from an arbitrary address).&n; *&n; * Returns:     1 if it is OK to merge the block into the request.  0&n; *              if it is not OK.&n; *&n; * Lock status: queue lock is assumed to be held here.&n; *&n; * Notes:       Some drivers have limited scatter-gather table sizes, and&n; *              thus they cannot queue an infinitely large command.  This&n; *              function is called from ll_rw_blk before it attempts to merge&n; *              a new block into a request to make sure that the request will&n; *              not become too large.&n; *&n; *              This function is not designed to be directly called.  Instead&n; *              it should be referenced from other functions where the&n; *              dma_host parameter should be an integer constant. The&n; *              compiler should thus be able to properly optimize the code,&n; *              eliminating stuff that is irrelevant.&n; *              It is more maintainable to do this way with a single function&n; *              than to have 4 separate functions all doing roughly the&n; *              same thing.&n; */
DECL|function|__scsi_back_merge_fn
id|__inline
r_static
r_int
id|__scsi_back_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
macro_line|#ifdef DMA_CHUNK_SIZE
r_if
c_cond
(paren
id|MERGEABLE_BUFFERS
c_func
(paren
id|bio
comma
id|req-&gt;bio
)paren
)paren
r_return
id|scsi_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
macro_line|#endif
r_return
id|scsi_new_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
DECL|function|__scsi_front_merge_fn
id|__inline
r_static
r_int
id|__scsi_front_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
macro_line|#ifdef DMA_CHUNK_SIZE
r_if
c_cond
(paren
id|MERGEABLE_BUFFERS
c_func
(paren
id|bio
comma
id|req-&gt;bio
)paren
)paren
r_return
id|scsi_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
macro_line|#endif
r_return
id|scsi_new_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Function:    scsi_merge_fn_()&n; *&n; * Purpose:     queue merge function.&n; *&n; * Arguments:   q       - Queue for which we are merging request.&n; *              req     - request into which we wish to merge.&n; *              bio     - Block which we may wish to merge into request&n; *&n; * Returns:     1 if it is OK to merge the block into the request.  0&n; *              if it is not OK.&n; *&n; * Lock status: queue lock is assumed to be held here.&n; *&n; * Notes:       Optimized for different cases depending upon whether&n; *              ISA DMA is in use and whether clustering should be used.&n; */
DECL|macro|MERGEFCT
mdefine_line|#define MERGEFCT(_FUNCTION, _BACK_FRONT)&t;&t;&t;&t;&bslash;&n;static int _FUNCTION(request_queue_t * q,&t;&t;&t;&t;&bslash;&n;&t;&t;     struct request * req,&t;&t;&t;&t;&bslash;&n;&t;&t;     struct bio *bio)&t;&t;&t;&t;&t;&bslash;&n;{&t;&t;&t;&t;&t;&t;&t;&t;&t;&bslash;&n;    int ret;&t;&t;&t;&t;&t;&t;&t;&t;&bslash;&n;    ret =  __scsi_ ## _BACK_FRONT ## _merge_fn(q,&t;&t;&t;&bslash;&n;&t;&t;&t;&t;&t;       req,&t;&t;&t;&bslash;&n;&t;&t;&t;&t;&t;       bio);&t;&t;&t;&bslash;&n;    return ret;&t;&t;&t;&t;&t;&t;&t;&t;&bslash;&n;}
id|MERGEFCT
c_func
(paren
id|scsi_back_merge_fn
comma
id|back
)paren
id|MERGEFCT
c_func
(paren
id|scsi_front_merge_fn
comma
id|front
)paren
multiline_comment|/*&n; * Function:    scsi_merge_requests_fn_()&n; *&n; * Purpose:     queue merge function.&n; *&n; * Arguments:   q       - Queue for which we are merging request.&n; *              req     - request into which we wish to merge.&n; *              next    - Block which we may wish to merge into request&n; *&n; * Returns:     1 if it is OK to merge the block into the request.  0&n; *              if it is not OK.&n; *&n; * Lock status: queue lock is assumed to be held here.&n; *&n; */
DECL|function|scsi_merge_requests_fn
r_inline
r_static
r_int
id|scsi_merge_requests_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|request
op_star
id|next
)paren
(brace
r_int
id|bio_segs
suffix:semicolon
multiline_comment|/*&n;&t; * First check if the either of the requests are re-queued&n;&t; * requests.  Can&squot;t merge them if they are.&n;&t; */
r_if
c_cond
(paren
id|req-&gt;special
op_logical_or
id|next-&gt;special
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * will become to large?&n;&t; */
r_if
c_cond
(paren
(paren
id|req-&gt;nr_sectors
op_plus
id|next-&gt;nr_sectors
)paren
OG
id|q-&gt;max_sectors
)paren
r_return
l_int|0
suffix:semicolon
id|bio_segs
op_assign
id|req-&gt;nr_segments
op_plus
id|next-&gt;nr_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
id|bio_segs
op_decrement
suffix:semicolon
multiline_comment|/*&n;&t; * exceeds our max allowed segments?&n;&t; */
r_if
c_cond
(paren
id|bio_segs
OG
id|q-&gt;max_segments
)paren
r_return
l_int|0
suffix:semicolon
macro_line|#ifdef DMA_CHUNK_SIZE
id|bio_segs
op_assign
id|req-&gt;nr_hw_segments
op_plus
id|next-&gt;nr_hw_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
id|bio_segs
op_decrement
suffix:semicolon
multiline_comment|/* If dynamic DMA mapping can merge last segment in req with&n;&t; * first segment in next, then the check for hw segments was&n;&t; * done above already, so we can always merge.&n;&t; */
r_if
c_cond
(paren
id|bio_segs
OG
id|q-&gt;max_segments
)paren
r_return
l_int|0
suffix:semicolon
id|req-&gt;nr_hw_segments
op_assign
id|bio_segs
suffix:semicolon
macro_line|#endif
multiline_comment|/*&n;&t; * This will form the start of a new segment.  Bump the &n;&t; * counter.&n;&t; */
id|req-&gt;nr_segments
op_assign
id|bio_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
multiline_comment|/*&n; * Function:    __init_io()&n; *&n; * Purpose:     Prototype for io initialize function.&n; *&n; * Arguments:   SCpnt   - Command descriptor we wish to initialize&n; *              sg_count_valid  - 1 if the sg count in the req is valid.&n; *              dma_host - 1 if this host has ISA DMA issues (bus doesn&squot;t&n; *                      expose all of the address lines, so that DMA cannot&n; *                      be done from an arbitrary address).&n; *&n; * Returns:     1 on success.&n; *&n; * Lock status: &n; *&n; * Notes:       Only the SCpnt argument should be a non-constant variable.&n; *              This function is designed in such a way that it will be&n; *              invoked from a series of small stubs, each of which would&n; *              be optimized for specific circumstances.&n; *&n; *              The advantage of this is that hosts that don&squot;t do DMA&n; *              get versions of the function that essentially don&squot;t have&n; *              any of the DMA code.  Same goes for clustering - in the&n; *              case of hosts with no need for clustering, there is no point&n; *              in a whole bunch of overhead.&n; *&n; *              Finally, in the event that a host has set can_queue to SG_ALL&n; *              implying that there is no limit to the length of a scatter&n; *              gather list, the sg count in the request won&squot;t be valid&n; *              (mainly because we don&squot;t need queue management functions&n; *              which keep the tally uptodate.&n; */
DECL|function|__init_io
id|__inline
r_static
r_int
id|__init_io
c_func
(paren
id|Scsi_Cmnd
op_star
id|SCpnt
comma
r_int
id|sg_count_valid
comma
r_int
id|dma_host
)paren
(brace
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_char
op_star
id|buff
suffix:semicolon
r_int
id|count
suffix:semicolon
r_int
id|i
suffix:semicolon
r_struct
id|request
op_star
id|req
suffix:semicolon
r_int
id|sectors
suffix:semicolon
r_struct
id|scatterlist
op_star
id|sgpnt
suffix:semicolon
r_int
id|this_count
suffix:semicolon
r_void
op_star
op_star
id|bbpnt
suffix:semicolon
id|req
op_assign
op_amp
id|SCpnt-&gt;request
suffix:semicolon
multiline_comment|/*&n;&t; * First we need to know how many scatter gather segments are needed.&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|sg_count_valid
)paren
(brace
id|count
op_assign
id|__count_segments
c_func
(paren
id|req
comma
id|dma_host
comma
l_int|NULL
)paren
suffix:semicolon
)brace
r_else
(brace
id|count
op_assign
id|req-&gt;nr_segments
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * If the dma pool is nearly empty, then queue a minimal request&n;&t; * with a single segment.  Typically this will satisfy a single&n;&t; * buffer.&n;&t; */
r_if
c_cond
(paren
id|dma_host
op_logical_and
id|scsi_dma_free_sectors
op_le
l_int|10
)paren
(brace
id|this_count
op_assign
id|req-&gt;current_nr_sectors
suffix:semicolon
r_goto
id|single_segment
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * we used to not use scatter-gather for single segment request,&n;&t; * but now we do (it makes highmem I/O easier to support without&n;&t; * kmapping pages)&n;&t; */
id|SCpnt-&gt;use_sg
op_assign
id|count
suffix:semicolon
multiline_comment|/* &n;&t; * Allocate the actual scatter-gather table itself.&n;&t; */
id|SCpnt-&gt;sglist_len
op_assign
(paren
id|SCpnt-&gt;use_sg
op_star
r_sizeof
(paren
r_struct
id|scatterlist
)paren
)paren
suffix:semicolon
multiline_comment|/* If we could potentially require ISA bounce buffers, allocate&n;&t; * space for this array here.&n;&t; */
r_if
c_cond
(paren
id|dma_host
)paren
id|SCpnt-&gt;sglist_len
op_add_assign
(paren
id|SCpnt-&gt;use_sg
op_star
r_sizeof
(paren
r_void
op_star
)paren
)paren
suffix:semicolon
multiline_comment|/* scsi_malloc can only allocate in chunks of 512 bytes so&n;&t; * round it up.&n;&t; */
id|SCpnt-&gt;sglist_len
op_assign
(paren
id|SCpnt-&gt;sglist_len
op_plus
l_int|511
)paren
op_amp
op_complement
l_int|511
suffix:semicolon
id|sgpnt
op_assign
(paren
r_struct
id|scatterlist
op_star
)paren
id|scsi_malloc
c_func
(paren
id|SCpnt-&gt;sglist_len
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|sgpnt
)paren
(brace
r_struct
id|Scsi_Host
op_star
id|SHpnt
op_assign
id|SCpnt-&gt;host
suffix:semicolon
multiline_comment|/*&n;&t;&t; * If we cannot allocate the scatter-gather table, then&n;&t;&t; * simply write the first buffer all by itself.&n;&t;&t; */
id|printk
c_func
(paren
l_string|&quot;Warning - running *really* short on DMA buffers&bslash;n&quot;
)paren
suffix:semicolon
id|this_count
op_assign
id|req-&gt;current_nr_sectors
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;SCSI: depth is %d, # segs %d, # hw segs %d&bslash;n&quot;
comma
id|SHpnt-&gt;host_busy
comma
id|req-&gt;nr_segments
comma
id|req-&gt;nr_hw_segments
)paren
suffix:semicolon
r_goto
id|single_segment
suffix:semicolon
)brace
id|memset
c_func
(paren
id|sgpnt
comma
l_int|0
comma
id|SCpnt-&gt;sglist_len
)paren
suffix:semicolon
id|SCpnt-&gt;request_buffer
op_assign
(paren
r_char
op_star
)paren
id|sgpnt
suffix:semicolon
id|SCpnt-&gt;request_bufflen
op_assign
l_int|0
suffix:semicolon
id|req-&gt;buffer
op_assign
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|dma_host
)paren
id|bbpnt
op_assign
(paren
r_void
op_star
op_star
)paren
(paren
(paren
r_char
op_star
)paren
id|sgpnt
op_plus
(paren
id|SCpnt-&gt;use_sg
op_star
r_sizeof
(paren
r_struct
id|scatterlist
)paren
)paren
)paren
suffix:semicolon
r_else
id|bbpnt
op_assign
l_int|NULL
suffix:semicolon
id|SCpnt-&gt;bounce_buffers
op_assign
id|bbpnt
suffix:semicolon
multiline_comment|/* &n;&t; * Next, walk the list, and fill in the addresses and sizes of&n;&t; * each segment.&n;&t; */
id|SCpnt-&gt;request_bufflen
op_assign
id|req-&gt;nr_sectors
op_lshift
l_int|9
suffix:semicolon
id|count
op_assign
id|blk_rq_map_sg
c_func
(paren
id|req-&gt;q
comma
id|req
comma
id|SCpnt-&gt;request_buffer
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Verify that the count is correct.&n;&t; */
r_if
c_cond
(paren
id|count
OG
id|SCpnt-&gt;use_sg
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;Incorrect number of segments after building list&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;counted %d, received %d&bslash;n&quot;
comma
id|count
comma
id|SCpnt-&gt;use_sg
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;req nr_sec %lu, cur_nr_sec %u&bslash;n&quot;
comma
id|req-&gt;nr_sectors
comma
id|req-&gt;current_nr_sectors
)paren
suffix:semicolon
id|scsi_free
c_func
(paren
id|SCpnt-&gt;request_buffer
comma
id|SCpnt-&gt;sglist_len
)paren
suffix:semicolon
id|this_count
op_assign
id|req-&gt;current_nr_sectors
suffix:semicolon
r_goto
id|single_segment
suffix:semicolon
)brace
id|SCpnt-&gt;use_sg
op_assign
id|count
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|dma_host
)paren
r_return
l_int|1
suffix:semicolon
multiline_comment|/*&n;&t; * Now allocate bounce buffers, if needed.&n;&t; */
id|SCpnt-&gt;request_bufflen
op_assign
l_int|0
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|count
suffix:semicolon
id|i
op_increment
)paren
(brace
id|sectors
op_assign
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|length
op_rshift
l_int|9
)paren
suffix:semicolon
id|SCpnt-&gt;request_bufflen
op_add_assign
id|sgpnt
(braket
id|i
)braket
dot
id|length
suffix:semicolon
r_if
c_cond
(paren
id|virt_to_phys
c_func
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|address
)paren
op_plus
id|sgpnt
(braket
id|i
)braket
dot
id|length
op_minus
l_int|1
OG
id|ISA_DMA_THRESHOLD
)paren
(brace
r_if
c_cond
(paren
id|scsi_dma_free_sectors
op_minus
id|sectors
op_le
l_int|10
)paren
(brace
multiline_comment|/*&n;&t;&t;&t;&t; * If this would nearly drain the DMA&n;&t;&t;&t;&t; * pool empty, then let&squot;s stop here.&n;&t;&t;&t;&t; * Don&squot;t make this request any larger.&n;&t;&t;&t;&t; * This is kind of a safety valve that&n;&t;&t;&t;&t; * we use - we could get screwed later&n;&t;&t;&t;&t; * on if we run out completely.  &n;&t;&t;&t;&t; */
id|SCpnt-&gt;request_bufflen
op_sub_assign
id|sgpnt
(braket
id|i
)braket
dot
id|length
suffix:semicolon
id|SCpnt-&gt;use_sg
op_assign
id|i
suffix:semicolon
r_if
c_cond
(paren
id|i
op_eq
l_int|0
)paren
(brace
r_goto
id|big_trouble
suffix:semicolon
)brace
r_break
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t;&t; * this is not a dma host, so it will never&n;&t;&t;&t; * be a highmem page&n;&t;&t;&t; */
id|bbpnt
(braket
id|i
)braket
op_assign
id|page_address
c_func
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|page
)paren
op_plus
id|sgpnt
(braket
id|i
)braket
dot
id|offset
suffix:semicolon
id|sgpnt
(braket
id|i
)braket
dot
id|address
op_assign
(paren
r_char
op_star
)paren
id|scsi_malloc
c_func
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|length
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * If we cannot allocate memory for this DMA bounce&n;&t;&t;&t; * buffer, then queue just what we have done so far.&n;&t;&t;&t; */
r_if
c_cond
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|address
op_eq
l_int|NULL
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;Warning - running low on DMA memory&bslash;n&quot;
)paren
suffix:semicolon
id|SCpnt-&gt;request_bufflen
op_sub_assign
id|sgpnt
(braket
id|i
)braket
dot
id|length
suffix:semicolon
id|SCpnt-&gt;use_sg
op_assign
id|i
suffix:semicolon
r_if
c_cond
(paren
id|i
op_eq
l_int|0
)paren
(brace
r_goto
id|big_trouble
suffix:semicolon
)brace
r_break
suffix:semicolon
)brace
r_if
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
op_eq
id|WRITE
)paren
id|memcpy
c_func
(paren
id|sgpnt
(braket
id|i
)braket
dot
id|address
comma
id|bbpnt
(braket
id|i
)braket
comma
id|sgpnt
(braket
id|i
)braket
dot
id|length
)paren
suffix:semicolon
)brace
)brace
r_return
l_int|1
suffix:semicolon
id|big_trouble
suffix:colon
multiline_comment|/*&n;&t; * We come here in the event that we get one humongous&n;&t; * request, where we need a bounce buffer, and the buffer is&n;&t; * more than we can allocate in a single call to&n;&t; * scsi_malloc().  In addition, we only come here when it is&n;&t; * the 0th element of the scatter-gather table that gets us&n;&t; * into this trouble.  As a fallback, we fall back to&n;&t; * non-scatter-gather, and ask for a single segment.  We make&n;&t; * a half-hearted attempt to pick a reasonably large request&n;&t; * size mainly so that we don&squot;t thrash the thing with&n;&t; * iddy-biddy requests.&n;&t; */
multiline_comment|/*&n;&t; * The original number of sectors in the 0th element of the&n;&t; * scatter-gather table.  &n;&t; */
id|sectors
op_assign
id|sgpnt
(braket
l_int|0
)braket
dot
id|length
op_rshift
l_int|9
suffix:semicolon
multiline_comment|/* &n;&t; * Free up the original scatter-gather table.  Note that since&n;&t; * it was the 0th element that got us here, we don&squot;t have to&n;&t; * go in and free up memory from the other slots.  &n;&t; */
id|SCpnt-&gt;request_bufflen
op_assign
l_int|0
suffix:semicolon
id|SCpnt-&gt;use_sg
op_assign
l_int|0
suffix:semicolon
id|scsi_free
c_func
(paren
id|SCpnt-&gt;request_buffer
comma
id|SCpnt-&gt;sglist_len
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Make an attempt to pick up as much as we reasonably can.&n;&t; * Just keep adding sectors until the pool starts running kind of&n;&t; * low.  The limit of 30 is somewhat arbitrary - the point is that&n;&t; * it would kind of suck if we dropped down and limited ourselves to&n;&t; * single-block requests if we had hundreds of free sectors.&n;&t; */
r_if
c_cond
(paren
id|scsi_dma_free_sectors
OG
l_int|30
)paren
(brace
r_for
c_loop
(paren
id|this_count
op_assign
l_int|0
comma
id|bio
op_assign
id|req-&gt;bio
suffix:semicolon
id|bio
suffix:semicolon
id|bio
op_assign
id|bio-&gt;bi_next
)paren
(brace
r_if
c_cond
(paren
id|scsi_dma_free_sectors
op_minus
id|this_count
OL
l_int|30
op_logical_or
id|this_count
op_eq
id|sectors
)paren
(brace
r_break
suffix:semicolon
)brace
id|this_count
op_add_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
)brace
)brace
r_else
(brace
multiline_comment|/*&n;&t;&t; * Yow!   Take the absolute minimum here.&n;&t;&t; */
id|this_count
op_assign
id|req-&gt;current_nr_sectors
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Now drop through into the single-segment case.&n;&t; */
id|single_segment
suffix:colon
multiline_comment|/*&n;&t; * Come here if for any reason we choose to do this as a single&n;&t; * segment.  Possibly the entire request, or possibly a small&n;&t; * chunk of the entire request.&n;&t; */
id|bio
op_assign
id|req-&gt;bio
suffix:semicolon
id|buff
op_assign
id|req-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|dma_host
op_logical_or
id|PageHighMem
c_func
(paren
id|bio_page
c_func
(paren
id|bio
)paren
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * Allocate a DMA bounce buffer.  If the allocation fails, fall&n;&t;&t; * back and allocate a really small one - enough to satisfy&n;&t;&t; * the first buffer.&n;&t;&t; */
r_if
c_cond
(paren
id|bio_to_phys
c_func
(paren
id|bio
)paren
op_plus
id|bio-&gt;bi_size
op_minus
l_int|1
OG
id|ISA_DMA_THRESHOLD
)paren
(brace
id|buff
op_assign
(paren
r_char
op_star
)paren
id|scsi_malloc
c_func
(paren
id|this_count
op_lshift
l_int|9
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|buff
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;Warning - running low on DMA memory&bslash;n&quot;
)paren
suffix:semicolon
id|this_count
op_assign
id|req-&gt;current_nr_sectors
suffix:semicolon
id|buff
op_assign
(paren
r_char
op_star
)paren
id|scsi_malloc
c_func
(paren
id|this_count
op_lshift
l_int|9
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|buff
)paren
(brace
id|dma_exhausted
c_func
(paren
id|SCpnt
comma
l_int|0
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
)brace
r_if
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
op_eq
id|WRITE
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_char
op_star
id|buf
op_assign
id|bio_kmap_irq
c_func
(paren
id|bio
comma
op_amp
id|flags
)paren
suffix:semicolon
id|memcpy
c_func
(paren
id|buff
comma
id|buf
comma
id|this_count
op_lshift
l_int|9
)paren
suffix:semicolon
id|bio_kunmap_irq
c_func
(paren
id|buf
comma
op_amp
id|flags
)paren
suffix:semicolon
)brace
)brace
)brace
id|SCpnt-&gt;request_bufflen
op_assign
id|this_count
op_lshift
l_int|9
suffix:semicolon
id|SCpnt-&gt;request_buffer
op_assign
id|buff
suffix:semicolon
id|SCpnt-&gt;use_sg
op_assign
l_int|0
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|macro|INITIO
mdefine_line|#define INITIO(_FUNCTION, _VALID, _DMA)&t;&t;&bslash;&n;static int _FUNCTION(Scsi_Cmnd * SCpnt)&t;&t;&bslash;&n;{&t;&t;&t;&t;&t;&t;&bslash;&n;    return __init_io(SCpnt, _VALID, _DMA);&t;&bslash;&n;}
multiline_comment|/*&n; * ll_rw_blk.c now keeps track of the number of segments in&n; * a request.  Thus we don&squot;t have to do it any more here.&n; * We always force &quot;_VALID&quot; to 1.  Eventually clean this up&n; * and get rid of the extra argument.&n; */
id|INITIO
c_func
(paren
id|scsi_init_io_v
comma
l_int|1
comma
l_int|0
)paren
id|INITIO
c_func
(paren
id|scsi_init_io_vd
comma
l_int|1
comma
l_int|1
)paren
multiline_comment|/*&n; * Function:    initialize_merge_fn()&n; *&n; * Purpose:     Initialize merge function for a host&n; *&n; * Arguments:   SHpnt   - Host descriptor.&n; *&n; * Returns:     Nothing.&n; *&n; * Lock status: &n; *&n; * Notes:&n; */
DECL|function|initialize_merge_fn
r_void
id|initialize_merge_fn
c_func
(paren
id|Scsi_Device
op_star
id|SDpnt
)paren
(brace
r_struct
id|Scsi_Host
op_star
id|SHpnt
op_assign
id|SDpnt-&gt;host
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
op_amp
id|SDpnt-&gt;request_queue
suffix:semicolon
id|dma64_addr_t
id|bounce_limit
suffix:semicolon
multiline_comment|/*&n;&t; * If this host has an unlimited tablesize, then don&squot;t bother with a&n;&t; * merge manager.  The whole point of the operation is to make sure&n;&t; * that requests don&squot;t grow too large, and this host isn&squot;t picky.&n;&t; *&n;&t; * Note that ll_rw_blk.c is effectively maintaining a segment&n;&t; * count which is only valid if clustering is used, and it obviously&n;&t; * doesn&squot;t handle the DMA case.   In the end, it&n;&t; * is simply easier to do it ourselves with our own functions&n;&t; * rather than rely upon the default behavior of ll_rw_blk.&n;&t; */
id|q-&gt;back_merge_fn
op_assign
id|scsi_back_merge_fn
suffix:semicolon
id|q-&gt;front_merge_fn
op_assign
id|scsi_front_merge_fn
suffix:semicolon
id|q-&gt;merge_requests_fn
op_assign
id|scsi_merge_requests_fn
suffix:semicolon
r_if
c_cond
(paren
id|SHpnt-&gt;unchecked_isa_dma
op_eq
l_int|0
)paren
(brace
id|SDpnt-&gt;scsi_init_io_fn
op_assign
id|scsi_init_io_v
suffix:semicolon
)brace
r_else
(brace
id|SDpnt-&gt;scsi_init_io_fn
op_assign
id|scsi_init_io_vd
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * now enable highmem I/O, if appropriate&n;&t; */
id|bounce_limit
op_assign
id|BLK_BOUNCE_HIGH
suffix:semicolon
r_if
c_cond
(paren
id|SHpnt-&gt;highmem_io
op_logical_and
(paren
id|SDpnt-&gt;type
op_eq
id|TYPE_DISK
)paren
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|PCI_DMA_BUS_IS_PHYS
)paren
multiline_comment|/* Platforms with virtual-DMA translation&n; &t;&t;&t; * hardware have no practical limit.&n;&t;&t;&t; */
id|bounce_limit
op_assign
id|BLK_BOUNCE_ANY
suffix:semicolon
r_else
id|bounce_limit
op_assign
id|SHpnt-&gt;pci_dev-&gt;dma_mask
suffix:semicolon
)brace
id|blk_queue_bounce_limit
c_func
(paren
id|q
comma
id|bounce_limit
)paren
suffix:semicolon
)brace
eof
