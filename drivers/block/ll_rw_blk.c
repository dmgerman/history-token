multiline_comment|/*&n; *  linux/drivers/block/ll_rw_blk.c&n; *&n; * Copyright (C) 1991, 1992 Linus Torvalds&n; * Copyright (C) 1994,      Karl Keyte: Added support for disk statistics&n; * Elevator latency, (C) 2000  Andrea Arcangeli &lt;andrea@suse.de&gt; SuSE&n; * Queue request tables / lock, selectable elevator, Jens Axboe &lt;axboe@suse.de&gt;&n; * kernel-doc documentation started by NeilBrown &lt;neilb@cse.unsw.edu.au&gt; -  July2000&n; * bio rewrite, highmem i/o, etc, Jens Axboe &lt;axboe@suse.de&gt; - may 2001&n; */
multiline_comment|/*&n; * This handles all read/write requests to block devices&n; */
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/module.h&gt;
macro_line|#include &lt;linux/backing-dev.h&gt;
macro_line|#include &lt;linux/bio.h&gt;
macro_line|#include &lt;linux/blkdev.h&gt;
macro_line|#include &lt;linux/highmem.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/string.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/bootmem.h&gt;&t;/* for max_pfn/max_low_pfn */
macro_line|#include &lt;linux/completion.h&gt;
macro_line|#include &lt;linux/slab.h&gt;
macro_line|#include &lt;linux/swap.h&gt;
macro_line|#include &lt;linux/writeback.h&gt;
multiline_comment|/*&n; * for max sense size&n; */
macro_line|#include &lt;scsi/scsi_cmnd.h&gt;
r_static
r_void
id|blk_unplug_work
c_func
(paren
r_void
op_star
id|data
)paren
suffix:semicolon
r_static
r_void
id|blk_unplug_timeout
c_func
(paren
r_int
r_int
id|data
)paren
suffix:semicolon
multiline_comment|/*&n; * For the allocated request tables&n; */
DECL|variable|request_cachep
r_static
id|kmem_cache_t
op_star
id|request_cachep
suffix:semicolon
multiline_comment|/*&n; * For queue allocation&n; */
DECL|variable|requestq_cachep
r_static
id|kmem_cache_t
op_star
id|requestq_cachep
suffix:semicolon
multiline_comment|/*&n; * For io context allocations&n; */
DECL|variable|iocontext_cachep
r_static
id|kmem_cache_t
op_star
id|iocontext_cachep
suffix:semicolon
DECL|variable|congestion_wqh
r_static
id|wait_queue_head_t
id|congestion_wqh
(braket
l_int|2
)braket
op_assign
(brace
id|__WAIT_QUEUE_HEAD_INITIALIZER
c_func
(paren
id|congestion_wqh
(braket
l_int|0
)braket
)paren
comma
id|__WAIT_QUEUE_HEAD_INITIALIZER
c_func
(paren
id|congestion_wqh
(braket
l_int|1
)braket
)paren
)brace
suffix:semicolon
multiline_comment|/*&n; * Controlling structure to kblockd&n; */
DECL|variable|kblockd_workqueue
r_static
r_struct
id|workqueue_struct
op_star
id|kblockd_workqueue
suffix:semicolon
DECL|variable|blk_max_low_pfn
DECL|variable|blk_max_pfn
r_int
r_int
id|blk_max_low_pfn
comma
id|blk_max_pfn
suffix:semicolon
DECL|variable|blk_max_low_pfn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_max_low_pfn
)paren
suffix:semicolon
DECL|variable|blk_max_pfn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_max_pfn
)paren
suffix:semicolon
multiline_comment|/* Amount of time in which a process may batch requests */
DECL|macro|BLK_BATCH_TIME
mdefine_line|#define BLK_BATCH_TIME&t;(HZ/50UL)
multiline_comment|/* Number of requests a &quot;batching&quot; process may submit */
DECL|macro|BLK_BATCH_REQ
mdefine_line|#define BLK_BATCH_REQ&t;32
multiline_comment|/*&n; * Return the threshold (number of used requests) at which the queue is&n; * considered to be congested.  It include a little hysteresis to keep the&n; * context switch rate down.&n; */
DECL|function|queue_congestion_on_threshold
r_static
r_inline
r_int
id|queue_congestion_on_threshold
c_func
(paren
r_struct
id|request_queue
op_star
id|q
)paren
(brace
r_return
id|q-&gt;nr_congestion_on
suffix:semicolon
)brace
multiline_comment|/*&n; * The threshold at which a queue is considered to be uncongested&n; */
DECL|function|queue_congestion_off_threshold
r_static
r_inline
r_int
id|queue_congestion_off_threshold
c_func
(paren
r_struct
id|request_queue
op_star
id|q
)paren
(brace
r_return
id|q-&gt;nr_congestion_off
suffix:semicolon
)brace
DECL|function|blk_queue_congestion_threshold
r_static
r_void
id|blk_queue_congestion_threshold
c_func
(paren
r_struct
id|request_queue
op_star
id|q
)paren
(brace
r_int
id|nr
suffix:semicolon
id|nr
op_assign
id|q-&gt;nr_requests
op_minus
(paren
id|q-&gt;nr_requests
op_div
l_int|8
)paren
op_plus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|nr
OG
id|q-&gt;nr_requests
)paren
id|nr
op_assign
id|q-&gt;nr_requests
suffix:semicolon
id|q-&gt;nr_congestion_on
op_assign
id|nr
suffix:semicolon
id|nr
op_assign
id|q-&gt;nr_requests
op_minus
(paren
id|q-&gt;nr_requests
op_div
l_int|8
)paren
op_minus
(paren
id|q-&gt;nr_requests
op_div
l_int|16
)paren
op_minus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|nr
OL
l_int|1
)paren
id|nr
op_assign
l_int|1
suffix:semicolon
id|q-&gt;nr_congestion_off
op_assign
id|nr
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just exitted congestion.  Note this in the global counter of&n; * congested queues, and wake up anyone who was waiting for requests to be&n; * put back.&n; */
DECL|function|clear_queue_congested
r_static
r_void
id|clear_queue_congested
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
id|wait_queue_head_t
op_star
id|wqh
op_assign
op_amp
id|congestion_wqh
(braket
id|rw
)braket
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_congested
suffix:colon
id|BDI_read_congested
suffix:semicolon
id|clear_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
suffix:semicolon
id|smp_mb__after_clear_bit
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|waitqueue_active
c_func
(paren
id|wqh
)paren
)paren
id|wake_up
c_func
(paren
id|wqh
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just entered congestion.  Flag that in the queue&squot;s VM-visible&n; * state flags and increment the global gounter of congested queues.&n; */
DECL|function|set_queue_congested
r_static
r_void
id|set_queue_congested
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_congested
suffix:colon
id|BDI_read_congested
suffix:semicolon
id|set_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_get_backing_dev_info - get the address of a queue&squot;s backing_dev_info&n; * @bdev:&t;device&n; *&n; * Locates the passed device&squot;s request queue and returns the address of its&n; * backing_dev_info&n; *&n; * Will return NULL if the request queue cannot be located.&n; */
DECL|function|blk_get_backing_dev_info
r_struct
id|backing_dev_info
op_star
id|blk_get_backing_dev_info
c_func
(paren
r_struct
id|block_device
op_star
id|bdev
)paren
(brace
r_struct
id|backing_dev_info
op_star
id|ret
op_assign
l_int|NULL
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
id|bdev_get_queue
c_func
(paren
id|bdev
)paren
suffix:semicolon
r_if
c_cond
(paren
id|q
)paren
id|ret
op_assign
op_amp
id|q-&gt;backing_dev_info
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|variable|blk_get_backing_dev_info
id|EXPORT_SYMBOL
c_func
(paren
id|blk_get_backing_dev_info
)paren
suffix:semicolon
DECL|function|blk_queue_activity_fn
r_void
id|blk_queue_activity_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|activity_fn
op_star
id|fn
comma
r_void
op_star
id|data
)paren
(brace
id|q-&gt;activity_fn
op_assign
id|fn
suffix:semicolon
id|q-&gt;activity_data
op_assign
id|data
suffix:semicolon
)brace
DECL|variable|blk_queue_activity_fn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_activity_fn
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_prep_rq - set a prepare_request function for queue&n; * @q:&t;&t;queue&n; * @pfn:&t;prepare_request function&n; *&n; * It&squot;s possible for a queue to register a prepare_request callback which&n; * is invoked before the request is handed to the request_fn. The goal of&n; * the function is to prepare a request for I/O, it can be used to build a&n; * cdb from the request data for instance.&n; *&n; */
DECL|function|blk_queue_prep_rq
r_void
id|blk_queue_prep_rq
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|prep_rq_fn
op_star
id|pfn
)paren
(brace
id|q-&gt;prep_rq_fn
op_assign
id|pfn
suffix:semicolon
)brace
DECL|variable|blk_queue_prep_rq
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_prep_rq
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_merge_bvec - set a merge_bvec function for queue&n; * @q:&t;&t;queue&n; * @mbfn:&t;merge_bvec_fn&n; *&n; * Usually queues have static limitations on the max sectors or segments that&n; * we can put in a request. Stacking drivers may have some settings that&n; * are dynamic, and thus we have to query the queue whether it is ok to&n; * add a new bio_vec to a bio at a given offset or not. If the block device&n; * has such limitations, it needs to register a merge_bvec_fn to control&n; * the size of bio&squot;s sent to it. Note that a block device *must* allow a&n; * single page to be added to an empty bio. The block device driver may want&n; * to use the bio_split() function to deal with these bio&squot;s. By default&n; * no merge_bvec_fn is defined for a queue, and only the fixed limits are&n; * honored.&n; */
DECL|function|blk_queue_merge_bvec
r_void
id|blk_queue_merge_bvec
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|merge_bvec_fn
op_star
id|mbfn
)paren
(brace
id|q-&gt;merge_bvec_fn
op_assign
id|mbfn
suffix:semicolon
)brace
DECL|variable|blk_queue_merge_bvec
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_merge_bvec
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_make_request - define an alternate make_request function for a device&n; * @q:  the request queue for the device to be affected&n; * @mfn: the alternate make_request function&n; *&n; * Description:&n; *    The normal way for &amp;struct bios to be passed to a device&n; *    driver is for them to be collected into requests on a request&n; *    queue, and then to allow the device driver to select requests&n; *    off that queue when it is ready.  This works well for many block&n; *    devices. However some block devices (typically virtual devices&n; *    such as md or lvm) do not benefit from the processing on the&n; *    request queue, and are served best by having the requests passed&n; *    directly to them.  This can be achieved by providing a function&n; *    to blk_queue_make_request().&n; *&n; * Caveat:&n; *    The driver that does this *must* be able to deal appropriately&n; *    with buffers in &quot;highmemory&quot;. This can be accomplished by either calling&n; *    __bio_kmap_atomic() to get a temporary kernel mapping, or by calling&n; *    blk_queue_bounce() to create a buffer in normal memory.&n; **/
DECL|function|blk_queue_make_request
r_void
id|blk_queue_make_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|make_request_fn
op_star
id|mfn
)paren
(brace
multiline_comment|/*&n;&t; * set defaults&n;&t; */
id|q-&gt;nr_requests
op_assign
id|BLKDEV_MAX_RQ
suffix:semicolon
id|q-&gt;max_phys_segments
op_assign
id|MAX_PHYS_SEGMENTS
suffix:semicolon
id|q-&gt;max_hw_segments
op_assign
id|MAX_HW_SEGMENTS
suffix:semicolon
id|q-&gt;make_request_fn
op_assign
id|mfn
suffix:semicolon
id|q-&gt;backing_dev_info.ra_pages
op_assign
(paren
id|VM_MAX_READAHEAD
op_star
l_int|1024
)paren
op_div
id|PAGE_CACHE_SIZE
suffix:semicolon
id|q-&gt;backing_dev_info.state
op_assign
l_int|0
suffix:semicolon
id|q-&gt;backing_dev_info.memory_backed
op_assign
l_int|0
suffix:semicolon
id|blk_queue_max_sectors
c_func
(paren
id|q
comma
id|MAX_SECTORS
)paren
suffix:semicolon
id|blk_queue_hardsect_size
c_func
(paren
id|q
comma
l_int|512
)paren
suffix:semicolon
id|blk_queue_dma_alignment
c_func
(paren
id|q
comma
l_int|511
)paren
suffix:semicolon
id|blk_queue_congestion_threshold
c_func
(paren
id|q
)paren
suffix:semicolon
id|q-&gt;nr_batching
op_assign
id|BLK_BATCH_REQ
suffix:semicolon
id|q-&gt;unplug_thresh
op_assign
l_int|4
suffix:semicolon
multiline_comment|/* hmm */
id|q-&gt;unplug_delay
op_assign
(paren
l_int|3
op_star
id|HZ
)paren
op_div
l_int|1000
suffix:semicolon
multiline_comment|/* 3 milliseconds */
r_if
c_cond
(paren
id|q-&gt;unplug_delay
op_eq
l_int|0
)paren
id|q-&gt;unplug_delay
op_assign
l_int|1
suffix:semicolon
id|INIT_WORK
c_func
(paren
op_amp
id|q-&gt;unplug_work
comma
id|blk_unplug_work
comma
id|q
)paren
suffix:semicolon
id|q-&gt;unplug_timer.function
op_assign
id|blk_unplug_timeout
suffix:semicolon
id|q-&gt;unplug_timer.data
op_assign
(paren
r_int
r_int
)paren
id|q
suffix:semicolon
multiline_comment|/*&n;&t; * by default assume old behaviour and bounce for any highmem page&n;&t; */
id|blk_queue_bounce_limit
c_func
(paren
id|q
comma
id|BLK_BOUNCE_HIGH
)paren
suffix:semicolon
id|blk_queue_activity_fn
c_func
(paren
id|q
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|q-&gt;drain_list
)paren
suffix:semicolon
)brace
DECL|variable|blk_queue_make_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_make_request
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_ordered - does this queue support ordered writes&n; * @q:     the request queue&n; * @flag:  see below&n; *&n; * Description:&n; *   For journalled file systems, doing ordered writes on a commit&n; *   block instead of explicitly doing wait_on_buffer (which is bad&n; *   for performance) can be a big win. Block drivers supporting this&n; *   feature should call this function and indicate so.&n; *&n; **/
DECL|function|blk_queue_ordered
r_void
id|blk_queue_ordered
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|flag
)paren
(brace
r_if
c_cond
(paren
id|flag
)paren
id|set_bit
c_func
(paren
id|QUEUE_FLAG_ORDERED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
r_else
id|clear_bit
c_func
(paren
id|QUEUE_FLAG_ORDERED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_queue_ordered
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_ordered
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_issue_flush_fn - set function for issuing a flush&n; * @q:     the request queue&n; * @iff:   the function to be called issuing the flush&n; *&n; * Description:&n; *   If a driver supports issuing a flush command, the support is notified&n; *   to the block layer by defining it through this call.&n; *&n; **/
DECL|function|blk_queue_issue_flush_fn
r_void
id|blk_queue_issue_flush_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|issue_flush_fn
op_star
id|iff
)paren
(brace
id|q-&gt;issue_flush_fn
op_assign
id|iff
suffix:semicolon
)brace
DECL|variable|blk_queue_issue_flush_fn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_issue_flush_fn
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_bounce_limit - set bounce buffer limit for queue&n; * @q:  the request queue for the device&n; * @dma_addr:   bus address limit&n; *&n; * Description:&n; *    Different hardware can have different requirements as to what pages&n; *    it can do I/O directly to. A low level driver can call&n; *    blk_queue_bounce_limit to have lower memory pages allocated as bounce&n; *    buffers for doing I/O to pages residing above @page. By default&n; *    the block layer sets this to the highest numbered &quot;low&quot; memory page.&n; **/
DECL|function|blk_queue_bounce_limit
r_void
id|blk_queue_bounce_limit
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|u64
id|dma_addr
)paren
(brace
r_int
r_int
id|bounce_pfn
op_assign
id|dma_addr
op_rshift
id|PAGE_SHIFT
suffix:semicolon
multiline_comment|/*&n;&t; * set appropriate bounce gfp mask -- unfortunately we don&squot;t have a&n;&t; * full 4GB zone, so we have to resort to low memory for any bounces.&n;&t; * ISA has its own &lt; 16MB zone.&n;&t; */
r_if
c_cond
(paren
id|bounce_pfn
OL
id|blk_max_low_pfn
)paren
(brace
id|BUG_ON
c_func
(paren
id|dma_addr
OL
id|BLK_BOUNCE_ISA
)paren
suffix:semicolon
id|init_emergency_isa_pool
c_func
(paren
)paren
suffix:semicolon
id|q-&gt;bounce_gfp
op_assign
id|GFP_NOIO
op_or
id|GFP_DMA
suffix:semicolon
)brace
r_else
id|q-&gt;bounce_gfp
op_assign
id|GFP_NOIO
suffix:semicolon
id|q-&gt;bounce_pfn
op_assign
id|bounce_pfn
suffix:semicolon
)brace
DECL|variable|blk_queue_bounce_limit
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_bounce_limit
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_max_sectors - set max sectors for a request for this queue&n; * @q:  the request queue for the device&n; * @max_sectors:  max sectors in the usual 512b unit&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the size of&n; *    received requests.&n; **/
DECL|function|blk_queue_max_sectors
r_void
id|blk_queue_max_sectors
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_sectors
)paren
(brace
r_if
c_cond
(paren
(paren
id|max_sectors
op_lshift
l_int|9
)paren
OL
id|PAGE_CACHE_SIZE
)paren
(brace
id|max_sectors
op_assign
l_int|1
op_lshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|9
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_sectors
)paren
suffix:semicolon
)brace
id|q-&gt;max_sectors
op_assign
id|q-&gt;max_hw_sectors
op_assign
id|max_sectors
suffix:semicolon
)brace
DECL|variable|blk_queue_max_sectors
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_sectors
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_max_phys_segments - set max phys segments for a request for this queue&n; * @q:  the request queue for the device&n; * @max_segments:  max number of segments&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the number of&n; *    physical data segments in a request.  This would be the largest sized&n; *    scatter list the driver could handle.&n; **/
DECL|function|blk_queue_max_phys_segments
r_void
id|blk_queue_max_phys_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_segments
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|max_segments
)paren
(brace
id|max_segments
op_assign
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_segments
)paren
suffix:semicolon
)brace
id|q-&gt;max_phys_segments
op_assign
id|max_segments
suffix:semicolon
)brace
DECL|variable|blk_queue_max_phys_segments
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_phys_segments
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_max_hw_segments - set max hw segments for a request for this queue&n; * @q:  the request queue for the device&n; * @max_segments:  max number of segments&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the number of&n; *    hw data segments in a request.  This would be the largest number of&n; *    address/length pairs the host adapter can actually give as once&n; *    to the device.&n; **/
DECL|function|blk_queue_max_hw_segments
r_void
id|blk_queue_max_hw_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_segments
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|max_segments
)paren
(brace
id|max_segments
op_assign
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_segments
)paren
suffix:semicolon
)brace
id|q-&gt;max_hw_segments
op_assign
id|max_segments
suffix:semicolon
)brace
DECL|variable|blk_queue_max_hw_segments
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_hw_segments
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_max_segment_size - set max segment size for blk_rq_map_sg&n; * @q:  the request queue for the device&n; * @max_size:  max size of segment in bytes&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the size of a&n; *    coalesced segment&n; **/
DECL|function|blk_queue_max_segment_size
r_void
id|blk_queue_max_segment_size
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_size
)paren
(brace
r_if
c_cond
(paren
id|max_size
OL
id|PAGE_CACHE_SIZE
)paren
(brace
id|max_size
op_assign
id|PAGE_CACHE_SIZE
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_size
)paren
suffix:semicolon
)brace
id|q-&gt;max_segment_size
op_assign
id|max_size
suffix:semicolon
)brace
DECL|variable|blk_queue_max_segment_size
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_segment_size
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_hardsect_size - set hardware sector size for the queue&n; * @q:  the request queue for the device&n; * @size:  the hardware sector size, in bytes&n; *&n; * Description:&n; *   This should typically be set to the lowest possible sector size&n; *   that the hardware can operate on (possible without reverting to&n; *   even internal read-modify-write operations). Usually the default&n; *   of 512 covers most hardware.&n; **/
DECL|function|blk_queue_hardsect_size
r_void
id|blk_queue_hardsect_size
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|size
)paren
(brace
id|q-&gt;hardsect_size
op_assign
id|size
suffix:semicolon
)brace
DECL|variable|blk_queue_hardsect_size
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_hardsect_size
)paren
suffix:semicolon
multiline_comment|/*&n; * Returns the minimum that is _not_ zero, unless both are zero.&n; */
DECL|macro|min_not_zero
mdefine_line|#define min_not_zero(l, r) (l == 0) ? r : ((r == 0) ? l : min(l, r))
multiline_comment|/**&n; * blk_queue_stack_limits - inherit underlying queue limits for stacked drivers&n; * @t:&t;the stacking driver (top)&n; * @b:  the underlying device (bottom)&n; **/
DECL|function|blk_queue_stack_limits
r_void
id|blk_queue_stack_limits
c_func
(paren
id|request_queue_t
op_star
id|t
comma
id|request_queue_t
op_star
id|b
)paren
(brace
multiline_comment|/* zero is &quot;infinity&quot; */
id|t-&gt;max_sectors
op_assign
id|t-&gt;max_hw_sectors
op_assign
id|min_not_zero
c_func
(paren
id|t-&gt;max_sectors
comma
id|b-&gt;max_sectors
)paren
suffix:semicolon
id|t-&gt;max_phys_segments
op_assign
id|min
c_func
(paren
id|t-&gt;max_phys_segments
comma
id|b-&gt;max_phys_segments
)paren
suffix:semicolon
id|t-&gt;max_hw_segments
op_assign
id|min
c_func
(paren
id|t-&gt;max_hw_segments
comma
id|b-&gt;max_hw_segments
)paren
suffix:semicolon
id|t-&gt;max_segment_size
op_assign
id|min
c_func
(paren
id|t-&gt;max_segment_size
comma
id|b-&gt;max_segment_size
)paren
suffix:semicolon
id|t-&gt;hardsect_size
op_assign
id|max
c_func
(paren
id|t-&gt;hardsect_size
comma
id|b-&gt;hardsect_size
)paren
suffix:semicolon
)brace
DECL|variable|blk_queue_stack_limits
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_stack_limits
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_segment_boundary - set boundary rules for segment merging&n; * @q:  the request queue for the device&n; * @mask:  the memory boundary mask&n; **/
DECL|function|blk_queue_segment_boundary
r_void
id|blk_queue_segment_boundary
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|mask
)paren
(brace
r_if
c_cond
(paren
id|mask
OL
id|PAGE_CACHE_SIZE
op_minus
l_int|1
)paren
(brace
id|mask
op_assign
id|PAGE_CACHE_SIZE
op_minus
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %lx&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|mask
)paren
suffix:semicolon
)brace
id|q-&gt;seg_boundary_mask
op_assign
id|mask
suffix:semicolon
)brace
DECL|variable|blk_queue_segment_boundary
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_segment_boundary
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_dma_alignment - set dma length and memory alignment&n; * @q:     the request queue for the device&n; * @mask:  alignment mask&n; *&n; * description:&n; *    set required memory and length aligment for direct dma transactions.&n; *    this is used when buiding direct io requests for the queue.&n; *&n; **/
DECL|function|blk_queue_dma_alignment
r_void
id|blk_queue_dma_alignment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|mask
)paren
(brace
id|q-&gt;dma_alignment
op_assign
id|mask
suffix:semicolon
)brace
DECL|variable|blk_queue_dma_alignment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_dma_alignment
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_find_tag - find a request by its tag and queue&n; *&n; * @q:&t; The request queue for the device&n; * @tag: The tag of the request&n; *&n; * Notes:&n; *    Should be used when a device returns a tag and you want to match&n; *    it with a request.&n; *&n; *    no locks need be held.&n; **/
DECL|function|blk_queue_find_tag
r_struct
id|request
op_star
id|blk_queue_find_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|tag
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bqt
op_eq
l_int|NULL
op_logical_or
id|tag
op_ge
id|bqt-&gt;real_max_depth
)paren
)paren
r_return
l_int|NULL
suffix:semicolon
r_return
id|bqt-&gt;tag_index
(braket
id|tag
)braket
suffix:semicolon
)brace
DECL|variable|blk_queue_find_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_find_tag
)paren
suffix:semicolon
multiline_comment|/**&n; * __blk_queue_free_tags - release tag maintenance info&n; * @q:  the request queue for the device&n; *&n; *  Notes:&n; *    blk_cleanup_queue() will take care of calling this function, if tagging&n; *    has been used. So there&squot;s no need to call this directly.&n; **/
DECL|function|__blk_queue_free_tags
r_static
r_void
id|__blk_queue_free_tags
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|bqt
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|atomic_dec_and_test
c_func
(paren
op_amp
id|bqt-&gt;refcnt
)paren
)paren
(brace
id|BUG_ON
c_func
(paren
id|bqt-&gt;busy
)paren
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|bqt-&gt;busy_list
)paren
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|bqt-&gt;tag_index
)paren
suffix:semicolon
id|bqt-&gt;tag_index
op_assign
l_int|NULL
suffix:semicolon
id|kfree
c_func
(paren
id|bqt-&gt;tag_map
)paren
suffix:semicolon
id|bqt-&gt;tag_map
op_assign
l_int|NULL
suffix:semicolon
id|kfree
c_func
(paren
id|bqt
)paren
suffix:semicolon
)brace
id|q-&gt;queue_tags
op_assign
l_int|NULL
suffix:semicolon
id|q-&gt;queue_flags
op_and_assign
op_complement
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_QUEUED
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_free_tags - release tag maintenance info&n; * @q:  the request queue for the device&n; *&n; *  Notes:&n; *&t;This is used to disabled tagged queuing to a device, yet leave&n; *&t;queue in function.&n; **/
DECL|function|blk_queue_free_tags
r_void
id|blk_queue_free_tags
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|clear_bit
c_func
(paren
id|QUEUE_FLAG_QUEUED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_queue_free_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_free_tags
)paren
suffix:semicolon
r_static
r_int
DECL|function|init_tag_map
id|init_tag_map
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|blk_queue_tag
op_star
id|tags
comma
r_int
id|depth
)paren
(brace
r_int
id|bits
comma
id|i
suffix:semicolon
r_struct
id|request
op_star
op_star
id|tag_index
suffix:semicolon
r_int
r_int
op_star
id|tag_map
suffix:semicolon
r_if
c_cond
(paren
id|depth
OG
id|q-&gt;nr_requests
op_star
l_int|2
)paren
(brace
id|depth
op_assign
id|q-&gt;nr_requests
op_star
l_int|2
suffix:semicolon
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;%s: adjusted depth to %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|depth
)paren
suffix:semicolon
)brace
id|tag_index
op_assign
id|kmalloc
c_func
(paren
id|depth
op_star
r_sizeof
(paren
r_struct
id|request
op_star
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tag_index
)paren
r_goto
id|fail
suffix:semicolon
id|bits
op_assign
(paren
id|depth
op_div
id|BLK_TAGS_PER_LONG
)paren
op_plus
l_int|1
suffix:semicolon
id|tag_map
op_assign
id|kmalloc
c_func
(paren
id|bits
op_star
r_sizeof
(paren
r_int
r_int
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tag_map
)paren
r_goto
id|fail
suffix:semicolon
id|memset
c_func
(paren
id|tag_index
comma
l_int|0
comma
id|depth
op_star
r_sizeof
(paren
r_struct
id|request
op_star
)paren
)paren
suffix:semicolon
id|memset
c_func
(paren
id|tag_map
comma
l_int|0
comma
id|bits
op_star
r_sizeof
(paren
r_int
r_int
)paren
)paren
suffix:semicolon
id|tags-&gt;max_depth
op_assign
id|depth
suffix:semicolon
id|tags-&gt;real_max_depth
op_assign
id|bits
op_star
id|BITS_PER_LONG
suffix:semicolon
id|tags-&gt;tag_index
op_assign
id|tag_index
suffix:semicolon
id|tags-&gt;tag_map
op_assign
id|tag_map
suffix:semicolon
multiline_comment|/*&n;&t; * set the upper bits if the depth isn&squot;t a multiple of the word size&n;&t; */
r_for
c_loop
(paren
id|i
op_assign
id|depth
suffix:semicolon
id|i
OL
id|bits
op_star
id|BLK_TAGS_PER_LONG
suffix:semicolon
id|i
op_increment
)paren
id|__set_bit
c_func
(paren
id|i
comma
id|tag_map
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|fail
suffix:colon
id|kfree
c_func
(paren
id|tag_index
)paren
suffix:semicolon
r_return
op_minus
id|ENOMEM
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_init_tags - initialize the queue tag info&n; * @q:  the request queue for the device&n; * @depth:  the maximum queue depth supported&n; **/
DECL|function|blk_queue_init_tags
r_int
id|blk_queue_init_tags
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|depth
comma
r_struct
id|blk_queue_tag
op_star
id|tags
)paren
(brace
r_int
id|rc
suffix:semicolon
id|BUG_ON
c_func
(paren
id|tags
op_logical_and
id|q-&gt;queue_tags
op_logical_and
id|tags
op_ne
id|q-&gt;queue_tags
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tags
op_logical_and
op_logical_neg
id|q-&gt;queue_tags
)paren
(brace
id|tags
op_assign
id|kmalloc
c_func
(paren
r_sizeof
(paren
r_struct
id|blk_queue_tag
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tags
)paren
r_goto
id|fail
suffix:semicolon
r_if
c_cond
(paren
id|init_tag_map
c_func
(paren
id|q
comma
id|tags
comma
id|depth
)paren
)paren
r_goto
id|fail
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|tags-&gt;busy_list
)paren
suffix:semicolon
id|tags-&gt;busy
op_assign
l_int|0
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|tags-&gt;refcnt
comma
l_int|1
)paren
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|q-&gt;queue_tags
)paren
(brace
r_if
c_cond
(paren
(paren
id|rc
op_assign
id|blk_queue_resize_tags
c_func
(paren
id|q
comma
id|depth
)paren
)paren
)paren
r_return
id|rc
suffix:semicolon
id|set_bit
c_func
(paren
id|QUEUE_FLAG_QUEUED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_else
id|atomic_inc
c_func
(paren
op_amp
id|tags-&gt;refcnt
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * assign it, all done&n;&t; */
id|q-&gt;queue_tags
op_assign
id|tags
suffix:semicolon
id|q-&gt;queue_flags
op_or_assign
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_QUEUED
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|fail
suffix:colon
id|kfree
c_func
(paren
id|tags
)paren
suffix:semicolon
r_return
op_minus
id|ENOMEM
suffix:semicolon
)brace
DECL|variable|blk_queue_init_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_init_tags
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_resize_tags - change the queueing depth&n; * @q:  the request queue for the device&n; * @new_depth: the new max command queueing depth&n; *&n; *  Notes:&n; *    Must be called with the queue lock held.&n; **/
DECL|function|blk_queue_resize_tags
r_int
id|blk_queue_resize_tags
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|new_depth
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_struct
id|request
op_star
op_star
id|tag_index
suffix:semicolon
r_int
r_int
op_star
id|tag_map
suffix:semicolon
r_int
id|bits
comma
id|max_depth
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|bqt
)paren
r_return
op_minus
id|ENXIO
suffix:semicolon
multiline_comment|/*&n;&t; * don&squot;t bother sizing down&n;&t; */
r_if
c_cond
(paren
id|new_depth
op_le
id|bqt-&gt;real_max_depth
)paren
(brace
id|bqt-&gt;max_depth
op_assign
id|new_depth
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * save the old state info, so we can copy it back&n;&t; */
id|tag_index
op_assign
id|bqt-&gt;tag_index
suffix:semicolon
id|tag_map
op_assign
id|bqt-&gt;tag_map
suffix:semicolon
id|max_depth
op_assign
id|bqt-&gt;real_max_depth
suffix:semicolon
r_if
c_cond
(paren
id|init_tag_map
c_func
(paren
id|q
comma
id|bqt
comma
id|new_depth
)paren
)paren
r_return
op_minus
id|ENOMEM
suffix:semicolon
id|memcpy
c_func
(paren
id|bqt-&gt;tag_index
comma
id|tag_index
comma
id|max_depth
op_star
r_sizeof
(paren
r_struct
id|request
op_star
)paren
)paren
suffix:semicolon
id|bits
op_assign
id|max_depth
op_div
id|BLK_TAGS_PER_LONG
suffix:semicolon
id|memcpy
c_func
(paren
id|bqt-&gt;tag_map
comma
id|tag_map
comma
id|bits
op_star
r_sizeof
(paren
r_int
r_int
)paren
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|tag_index
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|tag_map
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|variable|blk_queue_resize_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_resize_tags
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_end_tag - end tag operations for a request&n; * @q:  the request queue for the device&n; * @rq: the request that has completed&n; *&n; *  Description:&n; *    Typically called when end_that_request_first() returns 0, meaning&n; *    all transfers have been done for a request. It&squot;s important to call&n; *    this function before end_that_request_last(), as that will put the&n; *    request back on the free list thus corrupting the internal tag list.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_end_tag
r_void
id|blk_queue_end_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_int
id|tag
op_assign
id|rq-&gt;tag
suffix:semicolon
id|BUG_ON
c_func
(paren
id|tag
op_eq
op_minus
l_int|1
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|tag
op_ge
id|bqt-&gt;real_max_depth
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|__test_and_clear_bit
c_func
(paren
id|tag
comma
id|bqt-&gt;tag_map
)paren
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;attempt to clear non-busy tag (%d)&bslash;n&quot;
comma
id|tag
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_QUEUED
suffix:semicolon
id|rq-&gt;tag
op_assign
op_minus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_eq
l_int|NULL
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;tag %d is missing&bslash;n&quot;
comma
id|tag
)paren
suffix:semicolon
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_assign
l_int|NULL
suffix:semicolon
id|bqt-&gt;busy
op_decrement
suffix:semicolon
)brace
DECL|variable|blk_queue_end_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_end_tag
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_start_tag - find a free tag and assign it&n; * @q:  the request queue for the device&n; * @rq:  the block request that needs tagging&n; *&n; *  Description:&n; *    This can either be used as a stand-alone helper, or possibly be&n; *    assigned as the queue &amp;prep_rq_fn (in which case &amp;struct request&n; *    automagically gets a tag assigned). Note that this function&n; *    assumes that any type of request can be queued! if this is not&n; *    true for your device, you must check the request type before&n; *    calling this function.  The request will also be removed from&n; *    the request queue, so it&squot;s the drivers responsibility to readd&n; *    it if it should need to be restarted for some reason.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_start_tag
r_int
id|blk_queue_start_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_int
r_int
op_star
id|map
op_assign
id|bqt-&gt;tag_map
suffix:semicolon
r_int
id|tag
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
(paren
id|rq-&gt;flags
op_amp
id|REQ_QUEUED
)paren
)paren
)paren
(brace
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;request %p for device [%s] already tagged %d&quot;
comma
id|rq
comma
id|rq-&gt;rq_disk
ques
c_cond
id|rq-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
comma
id|rq-&gt;tag
)paren
suffix:semicolon
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
r_for
c_loop
(paren
id|map
op_assign
id|bqt-&gt;tag_map
suffix:semicolon
op_star
id|map
op_eq
op_minus
l_int|1UL
suffix:semicolon
id|map
op_increment
)paren
(brace
id|tag
op_add_assign
id|BLK_TAGS_PER_LONG
suffix:semicolon
r_if
c_cond
(paren
id|tag
op_ge
id|bqt-&gt;max_depth
)paren
r_return
l_int|1
suffix:semicolon
)brace
id|tag
op_add_assign
id|ffz
c_func
(paren
op_star
id|map
)paren
suffix:semicolon
id|__set_bit
c_func
(paren
id|tag
comma
id|bqt-&gt;tag_map
)paren
suffix:semicolon
id|rq-&gt;flags
op_or_assign
id|REQ_QUEUED
suffix:semicolon
id|rq-&gt;tag
op_assign
id|tag
suffix:semicolon
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_assign
id|rq
suffix:semicolon
id|blkdev_dequeue_request
c_func
(paren
id|rq
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|rq-&gt;queuelist
comma
op_amp
id|bqt-&gt;busy_list
)paren
suffix:semicolon
id|bqt-&gt;busy
op_increment
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|variable|blk_queue_start_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_start_tag
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_queue_invalidate_tags - invalidate all pending tags&n; * @q:  the request queue for the device&n; *&n; *  Description:&n; *   Hardware conditions may dictate a need to stop all pending requests.&n; *   In this case, we will safely clear the block side of the tag queue and&n; *   readd all requests to the request queue in the right order.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_invalidate_tags
r_void
id|blk_queue_invalidate_tags
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_struct
id|list_head
op_star
id|tmp
comma
op_star
id|n
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|tmp
comma
id|n
comma
op_amp
id|bqt-&gt;busy_list
)paren
(brace
id|rq
op_assign
id|list_entry_rq
c_func
(paren
id|tmp
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;tag
op_eq
op_minus
l_int|1
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;bad tag found on list&bslash;n&quot;
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_QUEUED
suffix:semicolon
)brace
r_else
id|blk_queue_end_tag
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_STARTED
suffix:semicolon
id|__elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
id|ELEVATOR_INSERT_BACK
comma
l_int|0
)paren
suffix:semicolon
)brace
)brace
DECL|variable|blk_queue_invalidate_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_invalidate_tags
)paren
suffix:semicolon
DECL|variable|rq_flags
r_static
r_char
op_star
id|rq_flags
(braket
)braket
op_assign
(brace
l_string|&quot;REQ_RW&quot;
comma
l_string|&quot;REQ_FAILFAST&quot;
comma
l_string|&quot;REQ_SOFTBARRIER&quot;
comma
l_string|&quot;REQ_HARDBARRIER&quot;
comma
l_string|&quot;REQ_CMD&quot;
comma
l_string|&quot;REQ_NOMERGE&quot;
comma
l_string|&quot;REQ_STARTED&quot;
comma
l_string|&quot;REQ_DONTPREP&quot;
comma
l_string|&quot;REQ_QUEUED&quot;
comma
l_string|&quot;REQ_PC&quot;
comma
l_string|&quot;REQ_BLOCK_PC&quot;
comma
l_string|&quot;REQ_SENSE&quot;
comma
l_string|&quot;REQ_FAILED&quot;
comma
l_string|&quot;REQ_QUIET&quot;
comma
l_string|&quot;REQ_SPECIAL&quot;
comma
l_string|&quot;REQ_DRIVE_CMD&quot;
comma
l_string|&quot;REQ_DRIVE_TASK&quot;
comma
l_string|&quot;REQ_DRIVE_TASKFILE&quot;
comma
l_string|&quot;REQ_PREEMPT&quot;
comma
l_string|&quot;REQ_PM_SUSPEND&quot;
comma
l_string|&quot;REQ_PM_RESUME&quot;
comma
l_string|&quot;REQ_PM_SHUTDOWN&quot;
comma
)brace
suffix:semicolon
DECL|function|blk_dump_rq_flags
r_void
id|blk_dump_rq_flags
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_char
op_star
id|msg
)paren
(brace
r_int
id|bit
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: dev %s: flags = &quot;
comma
id|msg
comma
id|rq-&gt;rq_disk
ques
c_cond
id|rq-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
)paren
suffix:semicolon
id|bit
op_assign
l_int|0
suffix:semicolon
r_do
(brace
r_if
c_cond
(paren
id|rq-&gt;flags
op_amp
(paren
l_int|1
op_lshift
id|bit
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%s &quot;
comma
id|rq_flags
(braket
id|bit
)braket
)paren
suffix:semicolon
id|bit
op_increment
suffix:semicolon
)brace
r_while
c_loop
(paren
id|bit
OL
id|__REQ_NR_BITS
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;&bslash;nsector %llu, nr/cnr %lu/%u&bslash;n&quot;
comma
(paren
r_int
r_int
r_int
)paren
id|rq-&gt;sector
comma
id|rq-&gt;nr_sectors
comma
id|rq-&gt;current_nr_sectors
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;bio %p, biotail %p, buffer %p, data %p, len %u&bslash;n&quot;
comma
id|rq-&gt;bio
comma
id|rq-&gt;biotail
comma
id|rq-&gt;buffer
comma
id|rq-&gt;data
comma
id|rq-&gt;data_len
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;flags
op_amp
(paren
id|REQ_BLOCK_PC
op_or
id|REQ_PC
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;cdb: &quot;
)paren
suffix:semicolon
r_for
c_loop
(paren
id|bit
op_assign
l_int|0
suffix:semicolon
id|bit
OL
r_sizeof
(paren
id|rq-&gt;cmd
)paren
suffix:semicolon
id|bit
op_increment
)paren
id|printk
c_func
(paren
l_string|&quot;%02x &quot;
comma
id|rq-&gt;cmd
(braket
id|bit
)braket
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
)paren
suffix:semicolon
)brace
)brace
DECL|variable|blk_dump_rq_flags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_dump_rq_flags
)paren
suffix:semicolon
DECL|function|blk_recount_segments
r_void
id|blk_recount_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|bio_vec
op_star
id|bv
comma
op_star
id|bvprv
op_assign
l_int|NULL
suffix:semicolon
r_int
id|i
comma
id|nr_phys_segs
comma
id|nr_hw_segs
comma
id|seg_size
comma
id|hw_seg_size
comma
id|cluster
suffix:semicolon
r_int
id|high
comma
id|highprv
op_assign
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio-&gt;bi_io_vec
)paren
)paren
r_return
suffix:semicolon
id|cluster
op_assign
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
id|hw_seg_size
op_assign
id|seg_size
op_assign
id|nr_phys_segs
op_assign
id|nr_hw_segs
op_assign
l_int|0
suffix:semicolon
id|bio_for_each_segment
c_func
(paren
id|bv
comma
id|bio
comma
id|i
)paren
(brace
multiline_comment|/*&n;&t;&t; * the trick here is making sure that a high page is never&n;&t;&t; * considered part of another segment, since that might&n;&t;&t; * change with the bounce page.&n;&t;&t; */
id|high
op_assign
id|page_to_pfn
c_func
(paren
id|bv-&gt;bv_page
)paren
op_ge
id|q-&gt;bounce_pfn
suffix:semicolon
r_if
c_cond
(paren
id|high
op_logical_or
id|highprv
)paren
r_goto
id|new_hw_segment
suffix:semicolon
r_if
c_cond
(paren
id|cluster
)paren
(brace
r_if
c_cond
(paren
id|seg_size
op_plus
id|bv-&gt;bv_len
OG
id|q-&gt;max_segment_size
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bv
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bvprv
comma
id|bv
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
id|BIOVEC_VIRT_OVERSIZE
c_func
(paren
id|hw_seg_size
op_plus
id|bv-&gt;bv_len
)paren
)paren
r_goto
id|new_hw_segment
suffix:semicolon
id|seg_size
op_add_assign
id|bv-&gt;bv_len
suffix:semicolon
id|hw_seg_size
op_add_assign
id|bv-&gt;bv_len
suffix:semicolon
id|bvprv
op_assign
id|bv
suffix:semicolon
r_continue
suffix:semicolon
)brace
id|new_segment
suffix:colon
r_if
c_cond
(paren
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bv
)paren
op_logical_and
op_logical_neg
id|BIOVEC_VIRT_OVERSIZE
c_func
(paren
id|hw_seg_size
op_plus
id|bv-&gt;bv_len
)paren
)paren
(brace
id|hw_seg_size
op_add_assign
id|bv-&gt;bv_len
suffix:semicolon
)brace
r_else
(brace
id|new_hw_segment
suffix:colon
r_if
c_cond
(paren
id|hw_seg_size
OG
id|bio-&gt;bi_hw_front_size
)paren
id|bio-&gt;bi_hw_front_size
op_assign
id|hw_seg_size
suffix:semicolon
id|hw_seg_size
op_assign
id|BIOVEC_VIRT_START_SIZE
c_func
(paren
id|bv
)paren
op_plus
id|bv-&gt;bv_len
suffix:semicolon
id|nr_hw_segs
op_increment
suffix:semicolon
)brace
id|nr_phys_segs
op_increment
suffix:semicolon
id|bvprv
op_assign
id|bv
suffix:semicolon
id|seg_size
op_assign
id|bv-&gt;bv_len
suffix:semicolon
id|highprv
op_assign
id|high
suffix:semicolon
)brace
r_if
c_cond
(paren
id|hw_seg_size
OG
id|bio-&gt;bi_hw_back_size
)paren
id|bio-&gt;bi_hw_back_size
op_assign
id|hw_seg_size
suffix:semicolon
r_if
c_cond
(paren
id|nr_hw_segs
op_eq
l_int|1
op_logical_and
id|hw_seg_size
OG
id|bio-&gt;bi_hw_front_size
)paren
id|bio-&gt;bi_hw_front_size
op_assign
id|hw_seg_size
suffix:semicolon
id|bio-&gt;bi_phys_segments
op_assign
id|nr_phys_segs
suffix:semicolon
id|bio-&gt;bi_hw_segments
op_assign
id|nr_hw_segs
suffix:semicolon
id|bio-&gt;bi_flags
op_or_assign
(paren
l_int|1
op_lshift
id|BIO_SEG_VALID
)paren
suffix:semicolon
)brace
DECL|function|blk_phys_contig_segment
r_int
id|blk_phys_contig_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
comma
r_struct
id|bio
op_star
id|nxt
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|nxt
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|bio-&gt;bi_size
op_plus
id|nxt-&gt;bi_size
OG
id|q-&gt;max_segment_size
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * bio and nxt are contigous in memory, check if the queue allows&n;&t; * these two to be merged into one&n;&t; */
r_if
c_cond
(paren
id|BIO_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bio
comma
id|nxt
)paren
)paren
r_return
l_int|1
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|variable|blk_phys_contig_segment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_phys_contig_segment
)paren
suffix:semicolon
DECL|function|blk_hw_contig_segment
r_int
id|blk_hw_contig_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
comma
r_struct
id|bio
op_star
id|nxt
)paren
(brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|bio
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|nxt
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|nxt
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|nxt
)paren
)paren
op_logical_or
id|BIOVEC_VIRT_OVERSIZE
c_func
(paren
id|bio-&gt;bi_hw_front_size
op_plus
id|bio-&gt;bi_hw_back_size
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|bio-&gt;bi_size
op_plus
id|nxt-&gt;bi_size
OG
id|q-&gt;max_segment_size
)paren
r_return
l_int|0
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|variable|blk_hw_contig_segment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_hw_contig_segment
)paren
suffix:semicolon
multiline_comment|/*&n; * map a request to scatterlist, return number of sg entries setup. Caller&n; * must make sure sg can hold rq-&gt;nr_phys_segments entries&n; */
DECL|function|blk_rq_map_sg
r_int
id|blk_rq_map_sg
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
comma
r_struct
id|scatterlist
op_star
id|sg
)paren
(brace
r_struct
id|bio_vec
op_star
id|bvec
comma
op_star
id|bvprv
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_int
id|nsegs
comma
id|i
comma
id|cluster
suffix:semicolon
id|nsegs
op_assign
l_int|0
suffix:semicolon
id|cluster
op_assign
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * for each bio in rq&n;&t; */
id|bvprv
op_assign
l_int|NULL
suffix:semicolon
id|rq_for_each_bio
c_func
(paren
id|bio
comma
id|rq
)paren
(brace
multiline_comment|/*&n;&t;&t; * for each segment in bio&n;&t;&t; */
id|bio_for_each_segment
c_func
(paren
id|bvec
comma
id|bio
comma
id|i
)paren
(brace
r_int
id|nbytes
op_assign
id|bvec-&gt;bv_len
suffix:semicolon
r_if
c_cond
(paren
id|bvprv
op_logical_and
id|cluster
)paren
(brace
r_if
c_cond
(paren
id|sg
(braket
id|nsegs
op_minus
l_int|1
)braket
dot
id|length
op_plus
id|nbytes
OG
id|q-&gt;max_segment_size
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bvec
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bvprv
comma
id|bvec
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
id|sg
(braket
id|nsegs
op_minus
l_int|1
)braket
dot
id|length
op_add_assign
id|nbytes
suffix:semicolon
)brace
r_else
(brace
id|new_segment
suffix:colon
id|memset
c_func
(paren
op_amp
id|sg
(braket
id|nsegs
)braket
comma
l_int|0
comma
r_sizeof
(paren
r_struct
id|scatterlist
)paren
)paren
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|page
op_assign
id|bvec-&gt;bv_page
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|length
op_assign
id|nbytes
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|offset
op_assign
id|bvec-&gt;bv_offset
suffix:semicolon
id|nsegs
op_increment
suffix:semicolon
)brace
id|bvprv
op_assign
id|bvec
suffix:semicolon
)brace
multiline_comment|/* segments in bio */
)brace
multiline_comment|/* bios in rq */
r_return
id|nsegs
suffix:semicolon
)brace
DECL|variable|blk_rq_map_sg
id|EXPORT_SYMBOL
c_func
(paren
id|blk_rq_map_sg
)paren
suffix:semicolon
multiline_comment|/*&n; * the standard queue merge functions, can be overridden with device&n; * specific ones if so desired&n; */
DECL|function|ll_new_mergeable
r_static
r_inline
r_int
id|ll_new_mergeable
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_phys_segs
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_phys_segments
op_plus
id|nr_phys_segs
OG
id|q-&gt;max_phys_segments
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_if
c_cond
(paren
id|req
op_eq
id|q-&gt;last_merge
)paren
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * A hw segment is just getting larger, bump just the phys&n;&t; * counter.&n;&t; */
id|req-&gt;nr_phys_segments
op_add_assign
id|nr_phys_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|ll_new_hw_segment
r_static
r_inline
r_int
id|ll_new_hw_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_hw_segs
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_int
id|nr_phys_segs
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_plus
id|nr_hw_segs
OG
id|q-&gt;max_hw_segments
op_logical_or
id|req-&gt;nr_phys_segments
op_plus
id|nr_phys_segs
OG
id|q-&gt;max_phys_segments
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_if
c_cond
(paren
id|req
op_eq
id|q-&gt;last_merge
)paren
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * This will form the start of a new hw segment.  Bump both&n;&t; * counters.&n;&t; */
id|req-&gt;nr_hw_segments
op_add_assign
id|nr_hw_segs
suffix:semicolon
id|req-&gt;nr_phys_segments
op_add_assign
id|nr_phys_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|ll_back_merge_fn
r_static
r_int
id|ll_back_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|len
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_if
c_cond
(paren
id|req
op_eq
id|q-&gt;last_merge
)paren
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|req-&gt;biotail
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|req-&gt;biotail
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|bio
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|len
op_assign
id|req-&gt;biotail-&gt;bi_hw_back_size
op_plus
id|bio-&gt;bi_hw_front_size
suffix:semicolon
r_if
c_cond
(paren
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|req-&gt;biotail
)paren
comma
id|__BVEC_START
c_func
(paren
id|bio
)paren
)paren
op_logical_and
op_logical_neg
id|BIOVEC_VIRT_OVERSIZE
c_func
(paren
id|len
)paren
)paren
(brace
r_int
id|mergeable
op_assign
id|ll_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|mergeable
)paren
(brace
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_eq
l_int|1
)paren
id|req-&gt;bio-&gt;bi_hw_front_size
op_assign
id|len
suffix:semicolon
r_if
c_cond
(paren
id|bio-&gt;bi_hw_segments
op_eq
l_int|1
)paren
id|bio-&gt;bi_hw_back_size
op_assign
id|len
suffix:semicolon
)brace
r_return
id|mergeable
suffix:semicolon
)brace
r_return
id|ll_new_hw_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
DECL|function|ll_front_merge_fn
r_static
r_int
id|ll_front_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|len
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_if
c_cond
(paren
id|req
op_eq
id|q-&gt;last_merge
)paren
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
id|len
op_assign
id|bio-&gt;bi_hw_back_size
op_plus
id|req-&gt;bio-&gt;bi_hw_front_size
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|bio
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio_flagged
c_func
(paren
id|req-&gt;bio
comma
id|BIO_SEG_VALID
)paren
)paren
)paren
id|blk_recount_segments
c_func
(paren
id|q
comma
id|req-&gt;bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|req-&gt;bio
)paren
)paren
op_logical_and
op_logical_neg
id|BIOVEC_VIRT_OVERSIZE
c_func
(paren
id|len
)paren
)paren
(brace
r_int
id|mergeable
op_assign
id|ll_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|mergeable
)paren
(brace
r_if
c_cond
(paren
id|bio-&gt;bi_hw_segments
op_eq
l_int|1
)paren
id|bio-&gt;bi_hw_front_size
op_assign
id|len
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_eq
l_int|1
)paren
id|req-&gt;biotail-&gt;bi_hw_back_size
op_assign
id|len
suffix:semicolon
)brace
r_return
id|mergeable
suffix:semicolon
)brace
r_return
id|ll_new_hw_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
DECL|function|ll_merge_requests_fn
r_static
r_int
id|ll_merge_requests_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|request
op_star
id|next
)paren
(brace
r_int
id|total_phys_segments
op_assign
id|req-&gt;nr_phys_segments
op_plus
id|next-&gt;nr_phys_segments
suffix:semicolon
r_int
id|total_hw_segments
op_assign
id|req-&gt;nr_hw_segments
op_plus
id|next-&gt;nr_hw_segments
suffix:semicolon
multiline_comment|/*&n;&t; * First check if the either of the requests are re-queued&n;&t; * requests.  Can&squot;t merge them if they are.&n;&t; */
r_if
c_cond
(paren
id|req-&gt;special
op_logical_or
id|next-&gt;special
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * Will it become to large?&n;&t; */
r_if
c_cond
(paren
(paren
id|req-&gt;nr_sectors
op_plus
id|next-&gt;nr_sectors
)paren
OG
id|q-&gt;max_sectors
)paren
r_return
l_int|0
suffix:semicolon
id|total_phys_segments
op_assign
id|req-&gt;nr_phys_segments
op_plus
id|next-&gt;nr_phys_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_phys_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
id|total_phys_segments
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|total_phys_segments
OG
id|q-&gt;max_phys_segments
)paren
r_return
l_int|0
suffix:semicolon
id|total_hw_segments
op_assign
id|req-&gt;nr_hw_segments
op_plus
id|next-&gt;nr_hw_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_hw_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
(brace
r_int
id|len
op_assign
id|req-&gt;biotail-&gt;bi_hw_back_size
op_plus
id|next-&gt;bio-&gt;bi_hw_front_size
suffix:semicolon
multiline_comment|/*&n;&t;&t; * propagate the combined length to the end of the requests&n;&t;&t; */
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_eq
l_int|1
)paren
id|req-&gt;bio-&gt;bi_hw_front_size
op_assign
id|len
suffix:semicolon
r_if
c_cond
(paren
id|next-&gt;nr_hw_segments
op_eq
l_int|1
)paren
id|next-&gt;biotail-&gt;bi_hw_back_size
op_assign
id|len
suffix:semicolon
id|total_hw_segments
op_decrement
suffix:semicolon
)brace
r_if
c_cond
(paren
id|total_hw_segments
OG
id|q-&gt;max_hw_segments
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/* Merge is OK... */
id|req-&gt;nr_phys_segments
op_assign
id|total_phys_segments
suffix:semicolon
id|req-&gt;nr_hw_segments
op_assign
id|total_hw_segments
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
multiline_comment|/*&n; * &quot;plug&quot; the device if there are no outstanding requests: this will&n; * force the transfer to start only after we have put all the requests&n; * on the list.&n; *&n; * This is called with interrupts off and no requests on the queue and&n; * with the queue lock held.&n; */
DECL|function|blk_plug_device
r_void
id|blk_plug_device
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|WARN_ON
c_func
(paren
op_logical_neg
id|irqs_disabled
c_func
(paren
)paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * don&squot;t plug a stopped queue, it must be paired with blk_start_queue()&n;&t; * which will restart the queueing&n;&t; */
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_and_set_bit
c_func
(paren
id|QUEUE_FLAG_PLUGGED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
id|mod_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
comma
id|jiffies
op_plus
id|q-&gt;unplug_delay
)paren
suffix:semicolon
)brace
DECL|variable|blk_plug_device
id|EXPORT_SYMBOL
c_func
(paren
id|blk_plug_device
)paren
suffix:semicolon
multiline_comment|/*&n; * remove the queue from the plugged list, if present. called with&n; * queue lock held and interrupts disabled.&n; */
DECL|function|blk_remove_plug
r_int
id|blk_remove_plug
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|WARN_ON
c_func
(paren
op_logical_neg
id|irqs_disabled
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_and_clear_bit
c_func
(paren
id|QUEUE_FLAG_PLUGGED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
r_return
l_int|0
suffix:semicolon
id|del_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|variable|blk_remove_plug
id|EXPORT_SYMBOL
c_func
(paren
id|blk_remove_plug
)paren
suffix:semicolon
multiline_comment|/*&n; * remove the plug and let it rip..&n; */
DECL|function|__generic_unplug_device
r_void
id|__generic_unplug_device
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|blk_remove_plug
c_func
(paren
id|q
)paren
)paren
r_return
suffix:semicolon
multiline_comment|/*&n;&t; * was plugged, fire request_fn if queue has stuff to do&n;&t; */
r_if
c_cond
(paren
id|elv_next_request
c_func
(paren
id|q
)paren
)paren
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
DECL|variable|__generic_unplug_device
id|EXPORT_SYMBOL
c_func
(paren
id|__generic_unplug_device
)paren
suffix:semicolon
multiline_comment|/**&n; * generic_unplug_device - fire a request queue&n; * @q:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   Linux uses plugging to build bigger requests queues before letting&n; *   the device have at them. If a queue is plugged, the I/O scheduler&n; *   is still adding and merging requests on the queue. Once the queue&n; *   gets unplugged, the request_fn defined for the queue is invoked and&n; *   transfers started.&n; **/
DECL|function|generic_unplug_device
r_void
id|generic_unplug_device
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
)brace
DECL|variable|generic_unplug_device
id|EXPORT_SYMBOL
c_func
(paren
id|generic_unplug_device
)paren
suffix:semicolon
DECL|function|blk_backing_dev_unplug
r_static
r_void
id|blk_backing_dev_unplug
c_func
(paren
r_struct
id|backing_dev_info
op_star
id|bdi
comma
r_struct
id|page
op_star
id|page
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|bdi-&gt;unplug_io_data
suffix:semicolon
multiline_comment|/*&n;&t; * devices don&squot;t necessarily have an -&gt;unplug_fn defined&n;&t; */
r_if
c_cond
(paren
id|q-&gt;unplug_fn
)paren
id|q
op_member_access_from_pointer
id|unplug_fn
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
DECL|function|blk_unplug_work
r_static
r_void
id|blk_unplug_work
c_func
(paren
r_void
op_star
id|data
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|data
suffix:semicolon
id|q
op_member_access_from_pointer
id|unplug_fn
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
DECL|function|blk_unplug_timeout
r_static
r_void
id|blk_unplug_timeout
c_func
(paren
r_int
r_int
id|data
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
(paren
id|request_queue_t
op_star
)paren
id|data
suffix:semicolon
id|kblockd_schedule_work
c_func
(paren
op_amp
id|q-&gt;unplug_work
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_start_queue - restart a previously stopped queue&n; * @q:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   blk_start_queue() will clear the stop flag on the queue, and call&n; *   the request_fn for the queue if it was in a stopped state when&n; *   entered. Also see blk_stop_queue(). Queue lock must be held.&n; **/
DECL|function|blk_start_queue
r_void
id|blk_start_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|clear_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * one level of recursion is ok and is much faster than kicking&n;&t; * the unplug handling&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|test_and_set_bit
c_func
(paren
id|QUEUE_FLAG_REENTER
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
(brace
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|clear_bit
c_func
(paren
id|QUEUE_FLAG_REENTER
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
)brace
r_else
(brace
id|blk_plug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|kblockd_schedule_work
c_func
(paren
op_amp
id|q-&gt;unplug_work
)paren
suffix:semicolon
)brace
)brace
DECL|variable|blk_start_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_start_queue
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_stop_queue - stop a queue&n; * @q:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   The Linux block layer assumes that a block driver will consume all&n; *   entries on the request queue when the request_fn strategy is called.&n; *   Often this will not happen, because of hardware limitations (queue&n; *   depth settings). If a device driver gets a &squot;queue full&squot; response,&n; *   or if it simply chooses not to queue more I/O at one point, it can&n; *   call this function to prevent the request_fn from being called until&n; *   the driver has signalled it&squot;s ready to go again. This happens by calling&n; *   blk_start_queue() to restart queue operations. Queue lock must be held.&n; **/
DECL|function|blk_stop_queue
r_void
id|blk_stop_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|blk_remove_plug
c_func
(paren
id|q
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_stop_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_stop_queue
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_sync_queue - cancel any pending callbacks on a queue&n; * @q: the queue&n; *&n; * Description:&n; *     The block layer may perform asynchronous callback activity&n; *     on a queue, such as calling the unplug function after a timeout.&n; *     A block device may call blk_sync_queue to ensure that any&n; *     such activity is cancelled, thus allowing it to release resources&n; *     the the callbacks might use. The caller must already have made sure&n; *     that its -&gt;make_request_fn will not re-add plugging prior to calling&n; *     this function.&n; *&n; */
DECL|function|blk_sync_queue
r_void
id|blk_sync_queue
c_func
(paren
r_struct
id|request_queue
op_star
id|q
)paren
(brace
id|del_timer_sync
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
id|kblockd_flush
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|variable|blk_sync_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_sync_queue
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_run_queue - run a single device queue&n; * @q:&t;The queue to run&n; */
DECL|function|blk_run_queue
r_void
id|blk_run_queue
c_func
(paren
r_struct
id|request_queue
op_star
id|q
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|blk_remove_plug
c_func
(paren
id|q
)paren
suffix:semicolon
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_run_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_run_queue
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_cleanup_queue: - release a &amp;request_queue_t when it is no longer needed&n; * @q:    the request queue to be released&n; *&n; * Description:&n; *     blk_cleanup_queue is the pair to blk_init_queue() or&n; *     blk_queue_make_request().  It should be called when a request queue is&n; *     being released; typically when a block device is being de-registered.&n; *     Currently, its primary task it to free all the &amp;struct request&n; *     structures that were allocated to the queue and the queue itself.&n; *&n; * Caveat:&n; *     Hopefully the low level driver will have finished any&n; *     outstanding requests first...&n; **/
DECL|function|blk_cleanup_queue
r_void
id|blk_cleanup_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|atomic_dec_and_test
c_func
(paren
op_amp
id|q-&gt;refcnt
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|q-&gt;elevator
)paren
id|elevator_exit
c_func
(paren
id|q-&gt;elevator
)paren
suffix:semicolon
id|blk_sync_queue
c_func
(paren
id|q
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;rq_pool
)paren
id|mempool_destroy
c_func
(paren
id|rl-&gt;rq_pool
)paren
suffix:semicolon
r_if
c_cond
(paren
id|q-&gt;queue_tags
)paren
id|__blk_queue_free_tags
c_func
(paren
id|q
)paren
suffix:semicolon
id|kmem_cache_free
c_func
(paren
id|requestq_cachep
comma
id|q
)paren
suffix:semicolon
)brace
DECL|variable|blk_cleanup_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_cleanup_queue
)paren
suffix:semicolon
DECL|function|blk_init_free_list
r_static
r_int
id|blk_init_free_list
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
id|rl-&gt;count
(braket
id|READ
)braket
op_assign
id|rl-&gt;count
(braket
id|WRITE
)braket
op_assign
l_int|0
suffix:semicolon
id|init_waitqueue_head
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|READ
)braket
)paren
suffix:semicolon
id|init_waitqueue_head
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|WRITE
)braket
)paren
suffix:semicolon
id|init_waitqueue_head
c_func
(paren
op_amp
id|rl-&gt;drain
)paren
suffix:semicolon
id|rl-&gt;rq_pool
op_assign
id|mempool_create
c_func
(paren
id|BLKDEV_MIN_RQ
comma
id|mempool_alloc_slab
comma
id|mempool_free_slab
comma
id|request_cachep
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rl-&gt;rq_pool
)paren
r_return
op_minus
id|ENOMEM
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_static
r_int
id|__make_request
c_func
(paren
id|request_queue_t
op_star
comma
r_struct
id|bio
op_star
)paren
suffix:semicolon
DECL|function|blk_alloc_queue
id|request_queue_t
op_star
id|blk_alloc_queue
c_func
(paren
r_int
id|gfp_mask
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|kmem_cache_alloc
c_func
(paren
id|requestq_cachep
comma
id|gfp_mask
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
)paren
r_return
l_int|NULL
suffix:semicolon
id|memset
c_func
(paren
id|q
comma
l_int|0
comma
r_sizeof
(paren
op_star
id|q
)paren
)paren
suffix:semicolon
id|init_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|q-&gt;refcnt
comma
l_int|1
)paren
suffix:semicolon
id|q-&gt;backing_dev_info.unplug_io_fn
op_assign
id|blk_backing_dev_unplug
suffix:semicolon
id|q-&gt;backing_dev_info.unplug_io_data
op_assign
id|q
suffix:semicolon
r_return
id|q
suffix:semicolon
)brace
DECL|variable|blk_alloc_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_alloc_queue
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_init_queue  - prepare a request queue for use with a block device&n; * @rfn:  The function to be called to process requests that have been&n; *        placed on the queue.&n; * @lock: Request queue spin lock&n; *&n; * Description:&n; *    If a block device wishes to use the standard request handling procedures,&n; *    which sorts requests and coalesces adjacent requests, then it must&n; *    call blk_init_queue().  The function @rfn will be called when there&n; *    are requests on the queue that need to be processed.  If the device&n; *    supports plugging, then @rfn may not be called immediately when requests&n; *    are available on the queue, but may be called at some time later instead.&n; *    Plugged queues are generally unplugged when a buffer belonging to one&n; *    of the requests on the queue is needed, or due to memory pressure.&n; *&n; *    @rfn is not required, or even expected, to remove all requests off the&n; *    queue, but only as many as it can handle at a time.  If it does leave&n; *    requests on the queue, it is responsible for arranging that the requests&n; *    get dealt with eventually.&n; *&n; *    The queue spin lock must be held while manipulating the requests on the&n; *    request queue.&n; *&n; *    Function returns a pointer to the initialized request queue, or NULL if&n; *    it didn&squot;t succeed.&n; *&n; * Note:&n; *    blk_init_queue() must be paired with a blk_cleanup_queue() call&n; *    when the block device is deactivated (such as at module unload).&n; **/
DECL|function|blk_init_queue
id|request_queue_t
op_star
id|blk_init_queue
c_func
(paren
id|request_fn_proc
op_star
id|rfn
comma
id|spinlock_t
op_star
id|lock
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|blk_alloc_queue
c_func
(paren
id|GFP_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
)paren
r_return
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|blk_init_free_list
c_func
(paren
id|q
)paren
)paren
r_goto
id|out_init
suffix:semicolon
id|q-&gt;request_fn
op_assign
id|rfn
suffix:semicolon
id|q-&gt;back_merge_fn
op_assign
id|ll_back_merge_fn
suffix:semicolon
id|q-&gt;front_merge_fn
op_assign
id|ll_front_merge_fn
suffix:semicolon
id|q-&gt;merge_requests_fn
op_assign
id|ll_merge_requests_fn
suffix:semicolon
id|q-&gt;prep_rq_fn
op_assign
l_int|NULL
suffix:semicolon
id|q-&gt;unplug_fn
op_assign
id|generic_unplug_device
suffix:semicolon
id|q-&gt;queue_flags
op_assign
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
id|q-&gt;queue_lock
op_assign
id|lock
suffix:semicolon
id|blk_queue_segment_boundary
c_func
(paren
id|q
comma
l_int|0xffffffff
)paren
suffix:semicolon
id|blk_queue_make_request
c_func
(paren
id|q
comma
id|__make_request
)paren
suffix:semicolon
id|blk_queue_max_segment_size
c_func
(paren
id|q
comma
id|MAX_SEGMENT_SIZE
)paren
suffix:semicolon
id|blk_queue_max_hw_segments
c_func
(paren
id|q
comma
id|MAX_HW_SEGMENTS
)paren
suffix:semicolon
id|blk_queue_max_phys_segments
c_func
(paren
id|q
comma
id|MAX_PHYS_SEGMENTS
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * all done&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|elevator_init
c_func
(paren
id|q
comma
l_int|NULL
)paren
)paren
(brace
id|blk_queue_congestion_threshold
c_func
(paren
id|q
)paren
suffix:semicolon
r_return
id|q
suffix:semicolon
)brace
id|blk_cleanup_queue
c_func
(paren
id|q
)paren
suffix:semicolon
id|out_init
suffix:colon
id|kmem_cache_free
c_func
(paren
id|requestq_cachep
comma
id|q
)paren
suffix:semicolon
r_return
l_int|NULL
suffix:semicolon
)brace
DECL|variable|blk_init_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_init_queue
)paren
suffix:semicolon
DECL|function|blk_get_queue
r_int
id|blk_get_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|test_bit
c_func
(paren
id|QUEUE_FLAG_DEAD
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
(brace
id|atomic_inc
c_func
(paren
op_amp
id|q-&gt;refcnt
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_return
l_int|1
suffix:semicolon
)brace
DECL|variable|blk_get_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_get_queue
)paren
suffix:semicolon
DECL|function|blk_free_request
r_static
r_inline
r_void
id|blk_free_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
id|elv_put_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|mempool_free
c_func
(paren
id|rq
comma
id|q-&gt;rq.rq_pool
)paren
suffix:semicolon
)brace
DECL|function|blk_alloc_request
r_static
r_inline
r_struct
id|request
op_star
id|blk_alloc_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
comma
r_int
id|gfp_mask
)paren
(brace
r_struct
id|request
op_star
id|rq
op_assign
id|mempool_alloc
c_func
(paren
id|q-&gt;rq.rq_pool
comma
id|gfp_mask
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
)paren
r_return
l_int|NULL
suffix:semicolon
multiline_comment|/*&n;&t; * first three bits are identical in rq-&gt;flags and bio-&gt;bi_rw,&n;&t; * see bio.h and blkdev.h&n;&t; */
id|rq-&gt;flags
op_assign
id|rw
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|elv_set_request
c_func
(paren
id|q
comma
id|rq
comma
id|gfp_mask
)paren
)paren
r_return
id|rq
suffix:semicolon
id|mempool_free
c_func
(paren
id|rq
comma
id|q-&gt;rq.rq_pool
)paren
suffix:semicolon
r_return
l_int|NULL
suffix:semicolon
)brace
multiline_comment|/*&n; * ioc_batching returns true if the ioc is a valid batching request and&n; * should be given priority access to a request.&n; */
DECL|function|ioc_batching
r_static
r_inline
r_int
id|ioc_batching
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|io_context
op_star
id|ioc
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|ioc
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * Make sure the process is able to allocate at least 1 request&n;&t; * even if the batch times out, otherwise we could theoretically&n;&t; * lose wakeups.&n;&t; */
r_return
id|ioc-&gt;nr_batch_requests
op_eq
id|q-&gt;nr_batching
op_logical_or
(paren
id|ioc-&gt;nr_batch_requests
OG
l_int|0
op_logical_and
id|time_before
c_func
(paren
id|jiffies
comma
id|ioc-&gt;last_waited
op_plus
id|BLK_BATCH_TIME
)paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * ioc_set_batching sets ioc to be a new &quot;batcher&quot; if it is not one. This&n; * will cause the process to be a &quot;batcher&quot; on all queues in the system. This&n; * is the behaviour we want though - once it gets a wakeup it should be given&n; * a nice run.&n; */
DECL|function|ioc_set_batching
r_void
id|ioc_set_batching
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|io_context
op_star
id|ioc
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|ioc
op_logical_or
id|ioc_batching
c_func
(paren
id|q
comma
id|ioc
)paren
)paren
r_return
suffix:semicolon
id|ioc-&gt;nr_batch_requests
op_assign
id|q-&gt;nr_batching
suffix:semicolon
id|ioc-&gt;last_waited
op_assign
id|jiffies
suffix:semicolon
)brace
multiline_comment|/*&n; * A request has just been released.  Account for it, update the full and&n; * congestion status, wake up any waiters.   Called under q-&gt;queue_lock.&n; */
DECL|function|freed_request
r_static
r_void
id|freed_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
id|rl-&gt;count
(braket
id|rw
)braket
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|rw
)braket
OL
id|queue_congestion_off_threshold
c_func
(paren
id|q
)paren
)paren
id|clear_queue_congested
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|rw
)braket
op_plus
l_int|1
op_le
id|q-&gt;nr_requests
)paren
(brace
id|smp_mb
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|waitqueue_active
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|rw
)braket
)paren
)paren
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|rw
)braket
)paren
suffix:semicolon
id|blk_clear_queue_full
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|waitqueue_active
c_func
(paren
op_amp
id|rl-&gt;drain
)paren
)paren
op_logical_and
op_logical_neg
id|rl-&gt;count
(braket
id|READ
)braket
op_logical_and
op_logical_neg
id|rl-&gt;count
(braket
id|WRITE
)braket
)paren
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;drain
)paren
suffix:semicolon
)brace
DECL|macro|blkdev_free_rq
mdefine_line|#define blkdev_free_rq(list) list_entry((list)-&gt;next, struct request, queuelist)
multiline_comment|/*&n; * Get a free request, queue_lock must not be held&n; */
DECL|function|get_request
r_static
r_struct
id|request
op_star
id|get_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
comma
r_int
id|gfp_mask
)paren
(brace
r_struct
id|request
op_star
id|rq
op_assign
l_int|NULL
suffix:semicolon
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
r_struct
id|io_context
op_star
id|ioc
op_assign
id|get_io_context
c_func
(paren
id|gfp_mask
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_DRAIN
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
)paren
r_goto
id|out
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|rw
)braket
op_plus
l_int|1
op_ge
id|q-&gt;nr_requests
)paren
(brace
multiline_comment|/*&n;&t;&t; * The queue will fill after this allocation, so set it as&n;&t;&t; * full, and mark this process as &quot;batching&quot;. This process&n;&t;&t; * will be allowed to complete a batch of requests, others&n;&t;&t; * will be blocked.&n;&t;&t; */
r_if
c_cond
(paren
op_logical_neg
id|blk_queue_full
c_func
(paren
id|q
comma
id|rw
)paren
)paren
(brace
id|ioc_set_batching
c_func
(paren
id|q
comma
id|ioc
)paren
suffix:semicolon
id|blk_set_queue_full
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
)brace
)brace
r_switch
c_cond
(paren
id|elv_may_queue
c_func
(paren
id|q
comma
id|rw
)paren
)paren
(brace
r_case
id|ELV_MQUEUE_NO
suffix:colon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
r_case
id|ELV_MQUEUE_MAY
suffix:colon
r_break
suffix:semicolon
r_case
id|ELV_MQUEUE_MUST
suffix:colon
r_goto
id|get_rq
suffix:semicolon
)brace
r_if
c_cond
(paren
id|blk_queue_full
c_func
(paren
id|q
comma
id|rw
)paren
op_logical_and
op_logical_neg
id|ioc_batching
c_func
(paren
id|q
comma
id|ioc
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t; * The queue is full and the allocating process is not a&n;&t;&t; * &quot;batcher&quot;, and not exempted by the IO scheduler&n;&t;&t; */
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
)brace
id|get_rq
suffix:colon
id|rl-&gt;count
(braket
id|rw
)braket
op_increment
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|rw
)braket
op_ge
id|queue_congestion_on_threshold
c_func
(paren
id|q
)paren
)paren
id|set_queue_congested
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|rq
op_assign
id|blk_alloc_request
c_func
(paren
id|q
comma
id|rw
comma
id|gfp_mask
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
)paren
(brace
multiline_comment|/*&n;&t;&t; * Allocation failed presumably due to memory. Undo anything&n;&t;&t; * we might have messed up.&n;&t;&t; *&n;&t;&t; * Allocating task should really be put onto the front of the&n;&t;&t; * wait queue, but this is pretty rare.&n;&t;&t; */
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|freed_request
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
)brace
r_if
c_cond
(paren
id|ioc_batching
c_func
(paren
id|q
comma
id|ioc
)paren
)paren
id|ioc-&gt;nr_batch_requests
op_decrement
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;errors
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;rq_status
op_assign
id|RQ_ACTIVE
suffix:semicolon
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;buffer
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;ref_count
op_assign
l_int|1
suffix:semicolon
id|rq-&gt;q
op_assign
id|q
suffix:semicolon
id|rq-&gt;rl
op_assign
id|rl
suffix:semicolon
id|rq-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;special
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;data_len
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;data
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;sense
op_assign
l_int|NULL
suffix:semicolon
id|out
suffix:colon
id|put_io_context
c_func
(paren
id|ioc
)paren
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
multiline_comment|/*&n; * No available requests for this queue, unplug the device and wait for some&n; * requests to become available.&n; */
DECL|function|get_request_wait
r_static
r_struct
id|request
op_star
id|get_request_wait
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
r_do
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
id|prepare_to_wait_exclusive
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|rw
)braket
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
id|rq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
comma
id|GFP_NOIO
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
)paren
(brace
r_struct
id|io_context
op_star
id|ioc
suffix:semicolon
id|io_schedule
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * After sleeping, we become a &quot;batching&quot; process and&n;&t;&t;&t; * will be able to allocate at least one request, and&n;&t;&t;&t; * up to a big batch of them for a small period time.&n;&t;&t;&t; * See ioc_batching, ioc_set_batching&n;&t;&t;&t; */
id|ioc
op_assign
id|get_io_context
c_func
(paren
id|GFP_NOIO
)paren
suffix:semicolon
id|ioc_set_batching
c_func
(paren
id|q
comma
id|ioc
)paren
suffix:semicolon
id|put_io_context
c_func
(paren
id|ioc
)paren
suffix:semicolon
)brace
id|finish_wait
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|rw
)braket
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
op_logical_neg
id|rq
)paren
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
DECL|function|blk_get_request
r_struct
id|request
op_star
id|blk_get_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
comma
r_int
id|gfp_mask
)paren
(brace
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|BUG_ON
c_func
(paren
id|rw
op_ne
id|READ
op_logical_and
id|rw
op_ne
id|WRITE
)paren
suffix:semicolon
r_if
c_cond
(paren
id|gfp_mask
op_amp
id|__GFP_WAIT
)paren
id|rq
op_assign
id|get_request_wait
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_else
id|rq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
comma
id|gfp_mask
)paren
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
DECL|variable|blk_get_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_get_request
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_requeue_request - put a request back on queue&n; * @q:&t;&t;request queue where request should be inserted&n; * @rq:&t;&t;request to be inserted&n; *&n; * Description:&n; *    Drivers often keep queueing requests until the hardware cannot accept&n; *    more, when that condition happens we need to put the request back&n; *    on the queue. Must be called with queue lock held.&n; */
DECL|function|blk_requeue_request
r_void
id|blk_requeue_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_if
c_cond
(paren
id|blk_rq_tagged
c_func
(paren
id|rq
)paren
)paren
id|blk_queue_end_tag
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|elv_requeue_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
)brace
DECL|variable|blk_requeue_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_requeue_request
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_insert_request - insert a special request in to a request queue&n; * @q:&t;&t;request queue where request should be inserted&n; * @rq:&t;&t;request to be inserted&n; * @at_head:&t;insert request at head or tail of queue&n; * @data:&t;private data&n; * @reinsert:&t;true if request it a reinsertion of previously processed one&n; *&n; * Description:&n; *    Many block devices need to execute commands asynchronously, so they don&squot;t&n; *    block the whole kernel from preemption during request execution.  This is&n; *    accomplished normally by inserting aritficial requests tagged as&n; *    REQ_SPECIAL in to the corresponding request queue, and letting them be&n; *    scheduled for actual execution by the request queue.&n; *&n; *    We have the option of inserting the head or the tail of the queue.&n; *    Typically we use the tail for new ioctls and so forth.  We use the head&n; *    of the queue for things like a QUEUE_FULL message from a device, or a&n; *    host that is unable to accept a particular command.&n; */
DECL|function|blk_insert_request
r_void
id|blk_insert_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
comma
r_int
id|at_head
comma
r_void
op_star
id|data
comma
r_int
id|reinsert
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
multiline_comment|/*&n;&t; * tell I/O scheduler that this isn&squot;t a regular read/write (ie it&n;&t; * must not attempt merges on this) and that it acts as a soft&n;&t; * barrier&n;&t; */
id|rq-&gt;flags
op_or_assign
id|REQ_SPECIAL
op_or
id|REQ_SOFTBARRIER
suffix:semicolon
id|rq-&gt;special
op_assign
id|data
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * If command is tagged, release the tag&n;&t; */
r_if
c_cond
(paren
id|reinsert
)paren
id|blk_requeue_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
r_else
(brace
r_int
id|where
op_assign
id|ELEVATOR_INSERT_BACK
suffix:semicolon
r_if
c_cond
(paren
id|at_head
)paren
id|where
op_assign
id|ELEVATOR_INSERT_FRONT
suffix:semicolon
r_if
c_cond
(paren
id|blk_rq_tagged
c_func
(paren
id|rq
)paren
)paren
id|blk_queue_end_tag
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|drive_stat_acct
c_func
(paren
id|rq
comma
id|rq-&gt;nr_sectors
comma
l_int|1
)paren
suffix:semicolon
id|__elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
id|where
comma
l_int|0
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|blk_queue_plugged
c_func
(paren
id|q
)paren
)paren
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
r_else
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_insert_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_insert_request
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_rq_map_user - map user data to a request, for REQ_BLOCK_PC usage&n; * @q:&t;&t;request queue where request should be inserted&n; * @rw:&t;&t;READ or WRITE data&n; * @ubuf:&t;the user buffer&n; * @len:&t;length of user data&n; *&n; * Description:&n; *    Data will be mapped directly for zero copy io, if possible. Otherwise&n; *    a kernel bounce buffer is used.&n; *&n; *    A matching blk_rq_unmap_user() must be issued at the end of io, while&n; *    still in process context.&n; *&n; *    Note: The mapped bio may need to be bounced through blk_queue_bounce()&n; *    before being submitted to the device, as pages mapped may be out of&n; *    reach. It&squot;s the callers responsibility to make sure this happens. The&n; *    original bio must be passed back in to blk_rq_unmap_user() for proper&n; *    unmapping.&n; */
DECL|function|blk_rq_map_user
r_struct
id|request
op_star
id|blk_rq_map_user
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
comma
r_void
id|__user
op_star
id|ubuf
comma
r_int
r_int
id|len
)paren
(brace
r_int
r_int
id|uaddr
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_if
c_cond
(paren
id|len
OG
(paren
id|q-&gt;max_sectors
op_lshift
l_int|9
)paren
)paren
r_return
id|ERR_PTR
c_func
(paren
op_minus
id|EINVAL
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
op_logical_neg
id|len
op_logical_and
id|ubuf
)paren
op_logical_or
(paren
id|len
op_logical_and
op_logical_neg
id|ubuf
)paren
)paren
r_return
id|ERR_PTR
c_func
(paren
op_minus
id|EINVAL
)paren
suffix:semicolon
id|rq
op_assign
id|blk_get_request
c_func
(paren
id|q
comma
id|rw
comma
id|__GFP_WAIT
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
)paren
r_return
id|ERR_PTR
c_func
(paren
op_minus
id|ENOMEM
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * if alignment requirement is satisfied, map in user pages for&n;&t; * direct dma. else, set up kernel bounce buffers&n;&t; */
id|uaddr
op_assign
(paren
r_int
r_int
)paren
id|ubuf
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
(paren
id|uaddr
op_amp
id|queue_dma_alignment
c_func
(paren
id|q
)paren
)paren
op_logical_and
op_logical_neg
(paren
id|len
op_amp
id|queue_dma_alignment
c_func
(paren
id|q
)paren
)paren
)paren
id|bio
op_assign
id|bio_map_user
c_func
(paren
id|q
comma
l_int|NULL
comma
id|uaddr
comma
id|len
comma
id|rw
op_eq
id|READ
)paren
suffix:semicolon
r_else
id|bio
op_assign
id|bio_copy_user
c_func
(paren
id|q
comma
id|uaddr
comma
id|len
comma
id|rw
op_eq
id|READ
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|IS_ERR
c_func
(paren
id|bio
)paren
)paren
(brace
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
id|bio
suffix:semicolon
id|blk_rq_bio_prep
c_func
(paren
id|q
comma
id|rq
comma
id|bio
)paren
suffix:semicolon
id|rq-&gt;buffer
op_assign
id|rq-&gt;data
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;data_len
op_assign
id|len
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * bio is the err-ptr&n;&t; */
id|blk_put_request
c_func
(paren
id|rq
)paren
suffix:semicolon
r_return
(paren
r_struct
id|request
op_star
)paren
id|bio
suffix:semicolon
)brace
DECL|variable|blk_rq_map_user
id|EXPORT_SYMBOL
c_func
(paren
id|blk_rq_map_user
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_rq_unmap_user - unmap a request with user data&n; * @rq:&t;&t;request to be unmapped&n; * @ubuf:&t;user buffer&n; * @ulen:&t;length of user buffer&n; *&n; * Description:&n; *    Unmap a request previously mapped by blk_rq_map_user().&n; */
DECL|function|blk_rq_unmap_user
r_int
id|blk_rq_unmap_user
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_struct
id|bio
op_star
id|bio
comma
r_int
r_int
id|ulen
)paren
(brace
r_int
id|ret
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|bio
)paren
(brace
r_if
c_cond
(paren
id|bio_flagged
c_func
(paren
id|bio
comma
id|BIO_USER_MAPPED
)paren
)paren
id|bio_unmap_user
c_func
(paren
id|bio
)paren
suffix:semicolon
r_else
id|ret
op_assign
id|bio_uncopy_user
c_func
(paren
id|bio
)paren
suffix:semicolon
)brace
id|blk_put_request
c_func
(paren
id|rq
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|variable|blk_rq_unmap_user
id|EXPORT_SYMBOL
c_func
(paren
id|blk_rq_unmap_user
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_execute_rq - insert a request into queue for execution&n; * @q:&t;&t;queue to insert the request in&n; * @bd_disk:&t;matching gendisk&n; * @rq:&t;&t;request to insert&n; *&n; * Description:&n; *    Insert a fully prepared request at the back of the io scheduler queue&n; *    for execution.&n; */
DECL|function|blk_execute_rq
r_int
id|blk_execute_rq
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|gendisk
op_star
id|bd_disk
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
id|DECLARE_COMPLETION
c_func
(paren
id|wait
)paren
suffix:semicolon
r_char
id|sense
(braket
id|SCSI_SENSE_BUFFERSIZE
)braket
suffix:semicolon
r_int
id|err
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;rq_disk
op_assign
id|bd_disk
suffix:semicolon
multiline_comment|/*&n;&t; * we need an extra reference to the request, so we can look at&n;&t; * it after io completion&n;&t; */
id|rq-&gt;ref_count
op_increment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;sense
)paren
(brace
id|memset
c_func
(paren
id|sense
comma
l_int|0
comma
r_sizeof
(paren
id|sense
)paren
)paren
suffix:semicolon
id|rq-&gt;sense
op_assign
id|sense
suffix:semicolon
id|rq-&gt;sense_len
op_assign
l_int|0
suffix:semicolon
)brace
id|rq-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;waiting
)paren
id|rq-&gt;waiting
op_assign
op_amp
id|wait
suffix:semicolon
id|elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
id|ELEVATOR_INSERT_BACK
comma
l_int|1
)paren
suffix:semicolon
id|generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|wait_for_completion
c_func
(paren
id|rq-&gt;waiting
)paren
suffix:semicolon
id|rq-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;errors
)paren
id|err
op_assign
op_minus
id|EIO
suffix:semicolon
r_return
id|err
suffix:semicolon
)brace
DECL|variable|blk_execute_rq
id|EXPORT_SYMBOL
c_func
(paren
id|blk_execute_rq
)paren
suffix:semicolon
multiline_comment|/**&n; * blkdev_issue_flush - queue a flush&n; * @bdev:&t;blockdev to issue flush for&n; * @error_sector:&t;error sector&n; *&n; * Description:&n; *    Issue a flush for the block device in question. Caller can supply&n; *    room for storing the error offset in case of a flush error, if they&n; *    wish to.  Caller must run wait_for_completion() on its own.&n; */
DECL|function|blkdev_issue_flush
r_int
id|blkdev_issue_flush
c_func
(paren
r_struct
id|block_device
op_star
id|bdev
comma
id|sector_t
op_star
id|error_sector
)paren
(brace
id|request_queue_t
op_star
id|q
suffix:semicolon
r_if
c_cond
(paren
id|bdev-&gt;bd_disk
op_eq
l_int|NULL
)paren
r_return
op_minus
id|ENXIO
suffix:semicolon
id|q
op_assign
id|bdev_get_queue
c_func
(paren
id|bdev
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
)paren
r_return
op_minus
id|ENXIO
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q-&gt;issue_flush_fn
)paren
r_return
op_minus
id|EOPNOTSUPP
suffix:semicolon
r_return
id|q
op_member_access_from_pointer
id|issue_flush_fn
c_func
(paren
id|q
comma
id|bdev-&gt;bd_disk
comma
id|error_sector
)paren
suffix:semicolon
)brace
DECL|variable|blkdev_issue_flush
id|EXPORT_SYMBOL
c_func
(paren
id|blkdev_issue_flush
)paren
suffix:semicolon
multiline_comment|/**&n; * blkdev_scsi_issue_flush_fn - issue flush for SCSI devices&n; * @q:&t;&t;device queue&n; * @disk:&t;gendisk&n; * @error_sector:&t;error offset&n; *&n; * Description:&n; *    Devices understanding the SCSI command set, can use this function as&n; *    a helper for issuing a cache flush. Note: driver is required to store&n; *    the error offset (in case of error flushing) in -&gt;sector of struct&n; *    request.&n; */
DECL|function|blkdev_scsi_issue_flush_fn
r_int
id|blkdev_scsi_issue_flush_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|gendisk
op_star
id|disk
comma
id|sector_t
op_star
id|error_sector
)paren
(brace
r_struct
id|request
op_star
id|rq
op_assign
id|blk_get_request
c_func
(paren
id|q
comma
id|WRITE
comma
id|__GFP_WAIT
)paren
suffix:semicolon
r_int
id|ret
suffix:semicolon
id|rq-&gt;flags
op_or_assign
id|REQ_BLOCK_PC
op_or
id|REQ_SOFTBARRIER
suffix:semicolon
id|rq-&gt;sector
op_assign
l_int|0
suffix:semicolon
id|memset
c_func
(paren
id|rq-&gt;cmd
comma
l_int|0
comma
r_sizeof
(paren
id|rq-&gt;cmd
)paren
)paren
suffix:semicolon
id|rq-&gt;cmd
(braket
l_int|0
)braket
op_assign
l_int|0x35
suffix:semicolon
id|rq-&gt;cmd_len
op_assign
l_int|12
suffix:semicolon
id|rq-&gt;data
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;data_len
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;timeout
op_assign
l_int|60
op_star
id|HZ
suffix:semicolon
id|ret
op_assign
id|blk_execute_rq
c_func
(paren
id|q
comma
id|disk
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ret
op_logical_and
id|error_sector
)paren
op_star
id|error_sector
op_assign
id|rq-&gt;sector
suffix:semicolon
id|blk_put_request
c_func
(paren
id|rq
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|variable|blkdev_scsi_issue_flush_fn
id|EXPORT_SYMBOL
c_func
(paren
id|blkdev_scsi_issue_flush_fn
)paren
suffix:semicolon
DECL|function|drive_stat_acct
r_void
id|drive_stat_acct
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_int
id|nr_sectors
comma
r_int
id|new_io
)paren
(brace
r_int
id|rw
op_assign
id|rq_data_dir
c_func
(paren
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|blk_fs_request
c_func
(paren
id|rq
)paren
op_logical_or
op_logical_neg
id|rq-&gt;rq_disk
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|rw
op_eq
id|READ
)paren
(brace
id|__disk_stat_add
c_func
(paren
id|rq-&gt;rq_disk
comma
id|read_sectors
comma
id|nr_sectors
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_io
)paren
id|__disk_stat_inc
c_func
(paren
id|rq-&gt;rq_disk
comma
id|read_merges
)paren
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|rw
op_eq
id|WRITE
)paren
(brace
id|__disk_stat_add
c_func
(paren
id|rq-&gt;rq_disk
comma
id|write_sectors
comma
id|nr_sectors
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_io
)paren
id|__disk_stat_inc
c_func
(paren
id|rq-&gt;rq_disk
comma
id|write_merges
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|new_io
)paren
(brace
id|disk_round_stats
c_func
(paren
id|rq-&gt;rq_disk
)paren
suffix:semicolon
id|rq-&gt;rq_disk-&gt;in_flight
op_increment
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * add-request adds a request to the linked list.&n; * queue lock is held and interrupts disabled, as we muck with the&n; * request queue list.&n; */
DECL|function|add_request
r_static
r_inline
r_void
id|add_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
)paren
(brace
id|drive_stat_acct
c_func
(paren
id|req
comma
id|req-&gt;nr_sectors
comma
l_int|1
)paren
suffix:semicolon
r_if
c_cond
(paren
id|q-&gt;activity_fn
)paren
id|q
op_member_access_from_pointer
id|activity_fn
c_func
(paren
id|q-&gt;activity_data
comma
id|rq_data_dir
c_func
(paren
id|req
)paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * elevator indicated where it wants this request to be&n;&t; * inserted at elevator_merge time&n;&t; */
id|__elv_add_request
c_func
(paren
id|q
comma
id|req
comma
id|ELEVATOR_INSERT_SORT
comma
l_int|0
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * disk_round_stats()&t;- Round off the performance stats on a struct&n; * disk_stats.&n; *&n; * The average IO queue length and utilisation statistics are maintained&n; * by observing the current state of the queue length and the amount of&n; * time it has been in this state for.&n; *&n; * Normally, that accounting is done on IO completion, but that can result&n; * in more than a second&squot;s worth of IO being accounted for within any one&n; * second, leading to &gt;100% utilisation.  To deal with that, we call this&n; * function to do a round-off before returning the results when reading&n; * /proc/diskstats.  This accounts immediately for all queue usage up to&n; * the current jiffies and restarts the counters again.&n; */
DECL|function|disk_round_stats
r_void
id|disk_round_stats
c_func
(paren
r_struct
id|gendisk
op_star
id|disk
)paren
(brace
r_int
r_int
id|now
op_assign
id|jiffies
suffix:semicolon
id|__disk_stat_add
c_func
(paren
id|disk
comma
id|time_in_queue
comma
id|disk-&gt;in_flight
op_star
(paren
id|now
op_minus
id|disk-&gt;stamp
)paren
)paren
suffix:semicolon
id|disk-&gt;stamp
op_assign
id|now
suffix:semicolon
r_if
c_cond
(paren
id|disk-&gt;in_flight
)paren
id|__disk_stat_add
c_func
(paren
id|disk
comma
id|io_ticks
comma
(paren
id|now
op_minus
id|disk-&gt;stamp_idle
)paren
)paren
suffix:semicolon
id|disk-&gt;stamp_idle
op_assign
id|now
suffix:semicolon
)brace
multiline_comment|/*&n; * queue lock must be held&n; */
DECL|function|__blk_put_request
r_void
id|__blk_put_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
id|req-&gt;rl
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|q
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_decrement
id|req-&gt;ref_count
)paren
)paren
r_return
suffix:semicolon
id|req-&gt;rq_status
op_assign
id|RQ_INACTIVE
suffix:semicolon
id|req-&gt;q
op_assign
l_int|NULL
suffix:semicolon
id|req-&gt;rl
op_assign
l_int|NULL
suffix:semicolon
multiline_comment|/*&n;&t; * Request may not have originated from ll_rw_blk. if not,&n;&t; * it didn&squot;t come out of our reserved rq pools&n;&t; */
r_if
c_cond
(paren
id|rl
)paren
(brace
r_int
id|rw
op_assign
id|rq_data_dir
c_func
(paren
id|req
)paren
suffix:semicolon
id|elv_completed_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|req-&gt;queuelist
)paren
)paren
suffix:semicolon
id|blk_free_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
id|freed_request
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
)brace
)brace
DECL|function|blk_put_request
r_void
id|blk_put_request
c_func
(paren
r_struct
id|request
op_star
id|req
)paren
(brace
multiline_comment|/*&n;&t; * if req-&gt;rl isn&squot;t set, this request didnt originate from the&n;&t; * block layer, so it&squot;s safe to just disregard it&n;&t; */
r_if
c_cond
(paren
id|req-&gt;rl
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
id|req-&gt;q
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|__blk_put_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
)brace
DECL|variable|blk_put_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_put_request
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_congestion_wait - wait for a queue to become uncongested&n; * @rw: READ or WRITE&n; * @timeout: timeout in jiffies&n; *&n; * Waits for up to @timeout jiffies for a queue (any queue) to exit congestion.&n; * If no queues are congested then just wait for the next request to be&n; * returned.&n; */
DECL|function|blk_congestion_wait
r_int
id|blk_congestion_wait
c_func
(paren
r_int
id|rw
comma
r_int
id|timeout
)paren
(brace
r_int
id|ret
suffix:semicolon
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
id|wait_queue_head_t
op_star
id|wqh
op_assign
op_amp
id|congestion_wqh
(braket
id|rw
)braket
suffix:semicolon
id|prepare_to_wait
c_func
(paren
id|wqh
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
id|ret
op_assign
id|io_schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|finish_wait
c_func
(paren
id|wqh
comma
op_amp
id|wait
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|variable|blk_congestion_wait
id|EXPORT_SYMBOL
c_func
(paren
id|blk_congestion_wait
)paren
suffix:semicolon
multiline_comment|/*&n; * Has to be called with the request spinlock acquired&n; */
DECL|function|attempt_merge
r_static
r_int
id|attempt_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|request
op_star
id|next
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
op_logical_or
op_logical_neg
id|rq_mergeable
c_func
(paren
id|next
)paren
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * not contigious&n;&t; */
r_if
c_cond
(paren
id|req-&gt;sector
op_plus
id|req-&gt;nr_sectors
op_ne
id|next-&gt;sector
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
op_ne
id|rq_data_dir
c_func
(paren
id|next
)paren
op_logical_or
id|req-&gt;rq_disk
op_ne
id|next-&gt;rq_disk
op_logical_or
id|next-&gt;waiting
op_logical_or
id|next-&gt;special
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * If we are allowed to merge, then append bio list&n;&t; * from next to rq and release next. merge_requests_fn&n;&t; * will have updated segment counts, update sector&n;&t; * counts here.&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|q
op_member_access_from_pointer
id|merge_requests_fn
c_func
(paren
id|q
comma
id|req
comma
id|next
)paren
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * At this point we have either done a back merge&n;&t; * or front merge. We need the smaller start_time of&n;&t; * the merged requests to be the current request&n;&t; * for accounting purposes.&n;&t; */
r_if
c_cond
(paren
id|time_after
c_func
(paren
id|req-&gt;start_time
comma
id|next-&gt;start_time
)paren
)paren
id|req-&gt;start_time
op_assign
id|next-&gt;start_time
suffix:semicolon
id|req-&gt;biotail-&gt;bi_next
op_assign
id|next-&gt;bio
suffix:semicolon
id|req-&gt;biotail
op_assign
id|next-&gt;biotail
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|next-&gt;hard_nr_sectors
suffix:semicolon
id|elv_merge_requests
c_func
(paren
id|q
comma
id|req
comma
id|next
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;rq_disk
)paren
(brace
id|disk_round_stats
c_func
(paren
id|req-&gt;rq_disk
)paren
suffix:semicolon
id|req-&gt;rq_disk-&gt;in_flight
op_decrement
suffix:semicolon
)brace
id|__blk_put_request
c_func
(paren
id|q
comma
id|next
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|attempt_back_merge
r_static
r_inline
r_int
id|attempt_back_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|request
op_star
id|next
op_assign
id|elv_latter_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|next
)paren
r_return
id|attempt_merge
c_func
(paren
id|q
comma
id|rq
comma
id|next
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|attempt_front_merge
r_static
r_inline
r_int
id|attempt_front_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|request
op_star
id|prev
op_assign
id|elv_former_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|prev
)paren
r_return
id|attempt_merge
c_func
(paren
id|q
comma
id|prev
comma
id|rq
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_attempt_remerge  - attempt to remerge active head with next request&n; * @q:    The &amp;request_queue_t belonging to the device&n; * @rq:   The head request (usually)&n; *&n; * Description:&n; *    For head-active devices, the queue can easily be unplugged so quickly&n; *    that proper merging is not done on the front request. This may hurt&n; *    performance greatly for some devices. The block layer cannot safely&n; *    do merging on that first request for these queues, but the driver can&n; *    call this function and make it happen any way. Only the driver knows&n; *    when it is safe to do so.&n; **/
DECL|function|blk_attempt_remerge
r_void
id|blk_attempt_remerge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|attempt_back_merge
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|variable|blk_attempt_remerge
id|EXPORT_SYMBOL
c_func
(paren
id|blk_attempt_remerge
)paren
suffix:semicolon
multiline_comment|/*&n; * Non-locking blk_attempt_remerge variant.&n; */
DECL|function|__blk_attempt_remerge
r_void
id|__blk_attempt_remerge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
id|attempt_back_merge
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
)brace
DECL|variable|__blk_attempt_remerge
id|EXPORT_SYMBOL
c_func
(paren
id|__blk_attempt_remerge
)paren
suffix:semicolon
DECL|function|__make_request
r_static
r_int
id|__make_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|request
op_star
id|req
comma
op_star
id|freereq
op_assign
l_int|NULL
suffix:semicolon
r_int
id|el_ret
comma
id|rw
comma
id|nr_sectors
comma
id|cur_nr_sectors
comma
id|barrier
comma
id|err
suffix:semicolon
id|sector_t
id|sector
suffix:semicolon
id|sector
op_assign
id|bio-&gt;bi_sector
suffix:semicolon
id|nr_sectors
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|cur_nr_sectors
op_assign
id|bio_cur_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|rw
op_assign
id|bio_data_dir
c_func
(paren
id|bio
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * low level driver can indicate that it wants pages above a&n;&t; * certain limit bounced to low memory (ie for highmem, or even&n;&t; * ISA dma in theory)&n;&t; */
id|blk_queue_bounce
c_func
(paren
id|q
comma
op_amp
id|bio
)paren
suffix:semicolon
id|spin_lock_prefetch
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|barrier
op_assign
id|bio_barrier
c_func
(paren
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|barrier
op_logical_and
op_logical_neg
(paren
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_ORDERED
)paren
)paren
)paren
(brace
id|err
op_assign
op_minus
id|EOPNOTSUPP
suffix:semicolon
r_goto
id|end_io
suffix:semicolon
)brace
id|again
suffix:colon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|elv_queue_empty
c_func
(paren
id|q
)paren
)paren
(brace
id|blk_plug_device
c_func
(paren
id|q
)paren
suffix:semicolon
r_goto
id|get_rq
suffix:semicolon
)brace
r_if
c_cond
(paren
id|barrier
)paren
r_goto
id|get_rq
suffix:semicolon
id|el_ret
op_assign
id|elv_merge
c_func
(paren
id|q
comma
op_amp
id|req
comma
id|bio
)paren
suffix:semicolon
r_switch
c_cond
(paren
id|el_ret
)paren
(brace
r_case
id|ELEVATOR_BACK_MERGE
suffix:colon
id|BUG_ON
c_func
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
op_member_access_from_pointer
id|back_merge_fn
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
)paren
r_break
suffix:semicolon
id|req-&gt;biotail-&gt;bi_next
op_assign
id|bio
suffix:semicolon
id|req-&gt;biotail
op_assign
id|bio
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
id|drive_stat_acct
c_func
(paren
id|req
comma
id|nr_sectors
comma
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|attempt_back_merge
c_func
(paren
id|q
comma
id|req
)paren
)paren
id|elv_merged_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
r_case
id|ELEVATOR_FRONT_MERGE
suffix:colon
id|BUG_ON
c_func
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
op_member_access_from_pointer
id|front_merge_fn
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
)paren
r_break
suffix:semicolon
id|bio-&gt;bi_next
op_assign
id|req-&gt;bio
suffix:semicolon
id|req-&gt;bio
op_assign
id|bio
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * may not be valid. if the low level driver said&n;&t;&t;&t; * it didn&squot;t need a bounce buffer then it better&n;&t;&t;&t; * not touch req-&gt;buffer either...&n;&t;&t;&t; */
id|req-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
id|req-&gt;current_nr_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;hard_cur_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;sector
op_assign
id|req-&gt;hard_sector
op_assign
id|sector
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
id|drive_stat_acct
c_func
(paren
id|req
comma
id|nr_sectors
comma
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|attempt_front_merge
c_func
(paren
id|q
comma
id|req
)paren
)paren
id|elv_merged_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
multiline_comment|/*&n;&t;&t; * elevator says don&squot;t/can&squot;t merge. get new request&n;&t;&t; */
r_case
id|ELEVATOR_NO_MERGE
suffix:colon
r_break
suffix:semicolon
r_default
suffix:colon
id|printk
c_func
(paren
l_string|&quot;elevator returned crap (%d)&bslash;n&quot;
comma
id|el_ret
)paren
suffix:semicolon
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Grab a free request from the freelist - if that is empty, check&n;&t; * if we are doing read ahead and abort instead of blocking for&n;&t; * a free slot.&n;&t; */
id|get_rq
suffix:colon
r_if
c_cond
(paren
id|freereq
)paren
(brace
id|req
op_assign
id|freereq
suffix:semicolon
id|freereq
op_assign
l_int|NULL
suffix:semicolon
)brace
r_else
(brace
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|freereq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
comma
id|GFP_ATOMIC
)paren
)paren
op_eq
l_int|NULL
)paren
(brace
multiline_comment|/*&n;&t;&t;&t; * READA bit set&n;&t;&t;&t; */
id|err
op_assign
op_minus
id|EWOULDBLOCK
suffix:semicolon
r_if
c_cond
(paren
id|bio_rw_ahead
c_func
(paren
id|bio
)paren
)paren
r_goto
id|end_io
suffix:semicolon
id|freereq
op_assign
id|get_request_wait
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
)brace
r_goto
id|again
suffix:semicolon
)brace
id|req-&gt;flags
op_or_assign
id|REQ_CMD
suffix:semicolon
multiline_comment|/*&n;&t; * inherit FAILFAST from bio (for read-ahead, and explicit FAILFAST)&n;&t; */
r_if
c_cond
(paren
id|bio_rw_ahead
c_func
(paren
id|bio
)paren
op_logical_or
id|bio_failfast
c_func
(paren
id|bio
)paren
)paren
id|req-&gt;flags
op_or_assign
id|REQ_FAILFAST
suffix:semicolon
multiline_comment|/*&n;&t; * REQ_BARRIER implies no merging, but lets make it explicit&n;&t; */
r_if
c_cond
(paren
id|barrier
)paren
id|req-&gt;flags
op_or_assign
(paren
id|REQ_HARDBARRIER
op_or
id|REQ_NOMERGE
)paren
suffix:semicolon
id|req-&gt;errors
op_assign
l_int|0
suffix:semicolon
id|req-&gt;hard_sector
op_assign
id|req-&gt;sector
op_assign
id|sector
suffix:semicolon
id|req-&gt;hard_nr_sectors
op_assign
id|req-&gt;nr_sectors
op_assign
id|nr_sectors
suffix:semicolon
id|req-&gt;current_nr_sectors
op_assign
id|req-&gt;hard_cur_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;nr_phys_segments
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|req-&gt;nr_hw_segments
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|req-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
multiline_comment|/* see -&gt;buffer comment above */
id|req-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
id|req-&gt;bio
op_assign
id|req-&gt;biotail
op_assign
id|bio
suffix:semicolon
id|req-&gt;rq_disk
op_assign
id|bio-&gt;bi_bdev-&gt;bd_disk
suffix:semicolon
id|req-&gt;start_time
op_assign
id|jiffies
suffix:semicolon
id|add_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
id|out
suffix:colon
r_if
c_cond
(paren
id|freereq
)paren
id|__blk_put_request
c_func
(paren
id|q
comma
id|freereq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|bio_sync
c_func
(paren
id|bio
)paren
)paren
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|end_io
suffix:colon
id|bio_endio
c_func
(paren
id|bio
comma
id|nr_sectors
op_lshift
l_int|9
comma
id|err
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * If bio-&gt;bi_dev is a partition, remap the location&n; */
DECL|function|blk_partition_remap
r_static
r_inline
r_void
id|blk_partition_remap
c_func
(paren
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|block_device
op_star
id|bdev
op_assign
id|bio-&gt;bi_bdev
suffix:semicolon
r_if
c_cond
(paren
id|bdev
op_ne
id|bdev-&gt;bd_contains
)paren
(brace
r_struct
id|hd_struct
op_star
id|p
op_assign
id|bdev-&gt;bd_part
suffix:semicolon
r_switch
c_cond
(paren
id|bio-&gt;bi_rw
)paren
(brace
r_case
id|READ
suffix:colon
id|p-&gt;read_sectors
op_add_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|p-&gt;reads
op_increment
suffix:semicolon
r_break
suffix:semicolon
r_case
id|WRITE
suffix:colon
id|p-&gt;write_sectors
op_add_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|p-&gt;writes
op_increment
suffix:semicolon
r_break
suffix:semicolon
)brace
id|bio-&gt;bi_sector
op_add_assign
id|p-&gt;start_sect
suffix:semicolon
id|bio-&gt;bi_bdev
op_assign
id|bdev-&gt;bd_contains
suffix:semicolon
)brace
)brace
DECL|function|blk_finish_queue_drain
r_void
id|blk_finish_queue_drain
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|clear_bit
c_func
(paren
id|QUEUE_FLAG_DRAIN
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|q-&gt;drain_list
)paren
)paren
(brace
id|rq
op_assign
id|list_entry_rq
c_func
(paren
id|q-&gt;drain_list.next
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|__elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
id|ELEVATOR_INSERT_BACK
comma
l_int|1
)paren
suffix:semicolon
)brace
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
l_int|0
)braket
)paren
suffix:semicolon
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
l_int|1
)braket
)paren
suffix:semicolon
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;drain
)paren
suffix:semicolon
)brace
DECL|function|wait_drain
r_static
r_int
id|wait_drain
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request_list
op_star
id|rl
comma
r_int
id|dispatch
)paren
(brace
r_int
id|wait
op_assign
id|rl-&gt;count
(braket
id|READ
)braket
op_plus
id|rl-&gt;count
(braket
id|WRITE
)braket
suffix:semicolon
r_if
c_cond
(paren
id|dispatch
)paren
id|wait
op_add_assign
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|q-&gt;queue_head
)paren
suffix:semicolon
r_return
id|wait
suffix:semicolon
)brace
multiline_comment|/*&n; * We rely on the fact that only requests allocated through blk_alloc_request()&n; * have io scheduler private data structures associated with them. Any other&n; * type of request (allocated on stack or through kmalloc()) should not go&n; * to the io scheduler core, but be attached to the queue head instead.&n; */
DECL|function|blk_wait_queue_drained
r_void
id|blk_wait_queue_drained
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|wait_dispatch
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|QUEUE_FLAG_DRAIN
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
r_while
c_loop
(paren
id|wait_drain
c_func
(paren
id|q
comma
id|rl
comma
id|wait_dispatch
)paren
)paren
(brace
id|prepare_to_wait
c_func
(paren
op_amp
id|rl-&gt;drain
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
r_if
c_cond
(paren
id|wait_drain
c_func
(paren
id|q
comma
id|rl
comma
id|wait_dispatch
)paren
)paren
(brace
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|io_schedule
c_func
(paren
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
)brace
id|finish_wait
c_func
(paren
op_amp
id|rl-&gt;drain
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * block waiting for the io scheduler being started again.&n; */
DECL|function|block_wait_queue_running
r_static
r_inline
r_void
id|block_wait_queue_running
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
r_while
c_loop
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_DRAIN
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
id|prepare_to_wait_exclusive
c_func
(paren
op_amp
id|rl-&gt;drain
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * re-check the condition. avoids using prepare_to_wait()&n;&t;&t; * in the fast path (queue is running)&n;&t;&t; */
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_DRAIN
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
id|io_schedule
c_func
(paren
)paren
suffix:semicolon
id|finish_wait
c_func
(paren
op_amp
id|rl-&gt;drain
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/**&n; * generic_make_request: hand a buffer to its device driver for I/O&n; * @bio:  The bio describing the location in memory and on the device.&n; *&n; * generic_make_request() is used to make I/O requests of block&n; * devices. It is passed a &amp;struct bio, which describes the I/O that needs&n; * to be done.&n; *&n; * generic_make_request() does not return any status.  The&n; * success/failure status of the request, along with notification of&n; * completion, is delivered asynchronously through the bio-&gt;bi_end_io&n; * function described (one day) else where.&n; *&n; * The caller of generic_make_request must make sure that bi_io_vec&n; * are set to describe the memory buffer, and that bi_dev and bi_sector are&n; * set to describe the device address, and the&n; * bi_end_io and optionally bi_private are set to describe how&n; * completion notification should be signaled.&n; *&n; * generic_make_request and the drivers it calls may use bi_next if this&n; * bio happens to be merged with someone else, and may change bi_dev and&n; * bi_sector for remaps as it sees fit.  So the values of these fields&n; * should NOT be depended on after the call to generic_make_request.&n; */
DECL|function|generic_make_request
r_void
id|generic_make_request
c_func
(paren
r_struct
id|bio
op_star
id|bio
)paren
(brace
id|request_queue_t
op_star
id|q
suffix:semicolon
id|sector_t
id|maxsector
suffix:semicolon
r_int
id|ret
comma
id|nr_sectors
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|might_sleep
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Test device or partition size, when known. */
id|maxsector
op_assign
id|bio-&gt;bi_bdev-&gt;bd_inode-&gt;i_size
op_rshift
l_int|9
suffix:semicolon
r_if
c_cond
(paren
id|maxsector
)paren
(brace
id|sector_t
id|sector
op_assign
id|bio-&gt;bi_sector
suffix:semicolon
r_if
c_cond
(paren
id|maxsector
OL
id|nr_sectors
op_logical_or
id|maxsector
op_minus
id|nr_sectors
OL
id|sector
)paren
(brace
r_char
id|b
(braket
id|BDEVNAME_SIZE
)braket
suffix:semicolon
multiline_comment|/* This may well happen - the kernel calls&n;&t;&t;&t; * bread() without checking the size of the&n;&t;&t;&t; * device, e.g., when mounting a device. */
id|printk
c_func
(paren
id|KERN_INFO
l_string|&quot;attempt to access beyond end of device&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
id|KERN_INFO
l_string|&quot;%s: rw=%ld, want=%Lu, limit=%Lu&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
comma
id|b
)paren
comma
id|bio-&gt;bi_rw
comma
(paren
r_int
r_int
r_int
)paren
id|sector
op_plus
id|nr_sectors
comma
(paren
r_int
r_int
)paren
id|maxsector
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|BIO_EOF
comma
op_amp
id|bio-&gt;bi_flags
)paren
suffix:semicolon
r_goto
id|end_io
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * Resolve the mapping until finished. (drivers are&n;&t; * still free to implement/resolve their own stacking&n;&t; * by explicitly returning 0)&n;&t; *&n;&t; * NOTE: we don&squot;t repeat the blk_size check for each new device.&n;&t; * Stacking drivers are expected to know what they are doing.&n;&t; */
r_do
(brace
r_char
id|b
(braket
id|BDEVNAME_SIZE
)braket
suffix:semicolon
id|q
op_assign
id|bdev_get_queue
c_func
(paren
id|bio-&gt;bi_bdev
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
)paren
(brace
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;generic_make_request: Trying to access &quot;
l_string|&quot;nonexistent block-device %s (%Lu)&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
comma
id|b
)paren
comma
(paren
r_int
r_int
)paren
id|bio-&gt;bi_sector
)paren
suffix:semicolon
id|end_io
suffix:colon
id|bio_endio
c_func
(paren
id|bio
comma
id|bio-&gt;bi_size
comma
op_minus
id|EIO
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_hw_sectors
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;bio too big device %s (%u &gt; %u)&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
comma
id|b
)paren
comma
id|bio_sectors
c_func
(paren
id|bio
)paren
comma
id|q-&gt;max_hw_sectors
)paren
suffix:semicolon
r_goto
id|end_io
suffix:semicolon
)brace
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_DEAD
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
r_goto
id|end_io
suffix:semicolon
id|block_wait_queue_running
c_func
(paren
id|q
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * If this device has partitions, remap block n&n;&t;&t; * of partition p to block n+start(p) of the disk.&n;&t;&t; */
id|blk_partition_remap
c_func
(paren
id|bio
)paren
suffix:semicolon
id|ret
op_assign
id|q
op_member_access_from_pointer
id|make_request_fn
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
id|ret
)paren
suffix:semicolon
)brace
DECL|variable|generic_make_request
id|EXPORT_SYMBOL
c_func
(paren
id|generic_make_request
)paren
suffix:semicolon
multiline_comment|/**&n; * submit_bio: submit a bio to the block device layer for I/O&n; * @rw: whether to %READ or %WRITE, or maybe to %READA (read ahead)&n; * @bio: The &amp;struct bio which describes the I/O&n; *&n; * submit_bio() is very similar in purpose to generic_make_request(), and&n; * uses that function to do most of the work. Both are fairly rough&n; * interfaces, @bio must be presetup and ready for I/O.&n; *&n; */
DECL|function|submit_bio
r_void
id|submit_bio
c_func
(paren
r_int
id|rw
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|count
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
op_logical_neg
id|bio-&gt;bi_size
)paren
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
op_logical_neg
id|bio-&gt;bi_io_vec
)paren
suffix:semicolon
id|bio-&gt;bi_rw
op_assign
id|rw
suffix:semicolon
r_if
c_cond
(paren
id|rw
op_amp
id|WRITE
)paren
id|mod_page_state
c_func
(paren
id|pgpgout
comma
id|count
)paren
suffix:semicolon
r_else
id|mod_page_state
c_func
(paren
id|pgpgin
comma
id|count
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|block_dump
)paren
)paren
(brace
r_char
id|b
(braket
id|BDEVNAME_SIZE
)braket
suffix:semicolon
id|printk
c_func
(paren
id|KERN_DEBUG
l_string|&quot;%s(%d): %s block %Lu on %s&bslash;n&quot;
comma
id|current-&gt;comm
comma
id|current-&gt;pid
comma
(paren
id|rw
op_amp
id|WRITE
)paren
ques
c_cond
l_string|&quot;WRITE&quot;
suffix:colon
l_string|&quot;READ&quot;
comma
(paren
r_int
r_int
r_int
)paren
id|bio-&gt;bi_sector
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
comma
id|b
)paren
)paren
suffix:semicolon
)brace
id|generic_make_request
c_func
(paren
id|bio
)paren
suffix:semicolon
)brace
DECL|variable|submit_bio
id|EXPORT_SYMBOL
c_func
(paren
id|submit_bio
)paren
suffix:semicolon
DECL|function|blk_recalc_rq_segments
r_void
id|blk_recalc_rq_segments
c_func
(paren
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|bio
op_star
id|bio
comma
op_star
id|prevbio
op_assign
l_int|NULL
suffix:semicolon
r_int
id|nr_phys_segs
comma
id|nr_hw_segs
suffix:semicolon
r_int
r_int
id|phys_size
comma
id|hw_size
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
id|rq-&gt;q
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;bio
)paren
r_return
suffix:semicolon
id|phys_size
op_assign
id|hw_size
op_assign
id|nr_phys_segs
op_assign
id|nr_hw_segs
op_assign
l_int|0
suffix:semicolon
id|rq_for_each_bio
c_func
(paren
id|bio
comma
id|rq
)paren
(brace
multiline_comment|/* Force bio hw/phys segs to be recalculated. */
id|bio-&gt;bi_flags
op_and_assign
op_complement
(paren
l_int|1
op_lshift
id|BIO_SEG_VALID
)paren
suffix:semicolon
id|nr_phys_segs
op_add_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|nr_hw_segs
op_add_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|prevbio
)paren
(brace
r_int
id|pseg
op_assign
id|phys_size
op_plus
id|prevbio-&gt;bi_size
op_plus
id|bio-&gt;bi_size
suffix:semicolon
r_int
id|hseg
op_assign
id|hw_size
op_plus
id|prevbio-&gt;bi_size
op_plus
id|bio-&gt;bi_size
suffix:semicolon
r_if
c_cond
(paren
id|blk_phys_contig_segment
c_func
(paren
id|q
comma
id|prevbio
comma
id|bio
)paren
op_logical_and
id|pseg
op_le
id|q-&gt;max_segment_size
)paren
(brace
id|nr_phys_segs
op_decrement
suffix:semicolon
id|phys_size
op_add_assign
id|prevbio-&gt;bi_size
op_plus
id|bio-&gt;bi_size
suffix:semicolon
)brace
r_else
id|phys_size
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|blk_hw_contig_segment
c_func
(paren
id|q
comma
id|prevbio
comma
id|bio
)paren
op_logical_and
id|hseg
op_le
id|q-&gt;max_segment_size
)paren
(brace
id|nr_hw_segs
op_decrement
suffix:semicolon
id|hw_size
op_add_assign
id|prevbio-&gt;bi_size
op_plus
id|bio-&gt;bi_size
suffix:semicolon
)brace
r_else
id|hw_size
op_assign
l_int|0
suffix:semicolon
)brace
id|prevbio
op_assign
id|bio
suffix:semicolon
)brace
id|rq-&gt;nr_phys_segments
op_assign
id|nr_phys_segs
suffix:semicolon
id|rq-&gt;nr_hw_segments
op_assign
id|nr_hw_segs
suffix:semicolon
)brace
DECL|function|blk_recalc_rq_sectors
r_void
id|blk_recalc_rq_sectors
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_int
id|nsect
)paren
(brace
r_if
c_cond
(paren
id|blk_fs_request
c_func
(paren
id|rq
)paren
)paren
(brace
id|rq-&gt;hard_sector
op_add_assign
id|nsect
suffix:semicolon
id|rq-&gt;hard_nr_sectors
op_sub_assign
id|nsect
suffix:semicolon
multiline_comment|/*&n;&t;&t; * Move the I/O submission pointers ahead if required.&n;&t;&t; */
r_if
c_cond
(paren
(paren
id|rq-&gt;nr_sectors
op_ge
id|rq-&gt;hard_nr_sectors
)paren
op_logical_and
(paren
id|rq-&gt;sector
op_le
id|rq-&gt;hard_sector
)paren
)paren
(brace
id|rq-&gt;sector
op_assign
id|rq-&gt;hard_sector
suffix:semicolon
id|rq-&gt;nr_sectors
op_assign
id|rq-&gt;hard_nr_sectors
suffix:semicolon
id|rq-&gt;hard_cur_sectors
op_assign
id|bio_cur_sectors
c_func
(paren
id|rq-&gt;bio
)paren
suffix:semicolon
id|rq-&gt;current_nr_sectors
op_assign
id|rq-&gt;hard_cur_sectors
suffix:semicolon
id|rq-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|rq-&gt;bio
)paren
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t; * if total number of sectors is less than the first segment&n;&t;&t; * size, something has gone terribly wrong&n;&t;&t; */
r_if
c_cond
(paren
id|rq-&gt;nr_sectors
OL
id|rq-&gt;current_nr_sectors
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;blk: request botched&bslash;n&quot;
)paren
suffix:semicolon
id|rq-&gt;nr_sectors
op_assign
id|rq-&gt;current_nr_sectors
suffix:semicolon
)brace
)brace
)brace
DECL|function|__end_that_request_first
r_static
r_int
id|__end_that_request_first
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_bytes
)paren
(brace
r_int
id|total_bytes
comma
id|bio_nbytes
comma
id|error
comma
id|next_idx
op_assign
l_int|0
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
multiline_comment|/*&n;&t; * extend uptodate bool to allow &lt; 0 value to be direct io error&n;&t; */
id|error
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|end_io_error
c_func
(paren
id|uptodate
)paren
)paren
id|error
op_assign
op_logical_neg
id|uptodate
ques
c_cond
op_minus
id|EIO
suffix:colon
id|uptodate
suffix:semicolon
multiline_comment|/*&n;&t; * for a REQ_BLOCK_PC request, we want to carry any eventual&n;&t; * sense key with us all the way through&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|blk_pc_request
c_func
(paren
id|req
)paren
)paren
id|req-&gt;errors
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|uptodate
)paren
(brace
r_if
c_cond
(paren
id|blk_fs_request
c_func
(paren
id|req
)paren
op_logical_and
op_logical_neg
(paren
id|req-&gt;flags
op_amp
id|REQ_QUIET
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;end_request: I/O error, dev %s, sector %llu&bslash;n&quot;
comma
id|req-&gt;rq_disk
ques
c_cond
id|req-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
comma
(paren
r_int
r_int
r_int
)paren
id|req-&gt;sector
)paren
suffix:semicolon
)brace
id|total_bytes
op_assign
id|bio_nbytes
op_assign
l_int|0
suffix:semicolon
r_while
c_loop
(paren
(paren
id|bio
op_assign
id|req-&gt;bio
)paren
op_ne
l_int|NULL
)paren
(brace
r_int
id|nbytes
suffix:semicolon
r_if
c_cond
(paren
id|nr_bytes
op_ge
id|bio-&gt;bi_size
)paren
(brace
id|req-&gt;bio
op_assign
id|bio-&gt;bi_next
suffix:semicolon
id|nbytes
op_assign
id|bio-&gt;bi_size
suffix:semicolon
id|bio_endio
c_func
(paren
id|bio
comma
id|nbytes
comma
id|error
)paren
suffix:semicolon
id|next_idx
op_assign
l_int|0
suffix:semicolon
id|bio_nbytes
op_assign
l_int|0
suffix:semicolon
)brace
r_else
(brace
r_int
id|idx
op_assign
id|bio-&gt;bi_idx
op_plus
id|next_idx
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bio-&gt;bi_idx
op_ge
id|bio-&gt;bi_vcnt
)paren
)paren
(brace
id|blk_dump_rq_flags
c_func
(paren
id|req
comma
l_string|&quot;__end_that&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: bio idx %d &gt;= vcnt %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|bio-&gt;bi_idx
comma
id|bio-&gt;bi_vcnt
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
id|nbytes
op_assign
id|bio_iovec_idx
c_func
(paren
id|bio
comma
id|idx
)paren
op_member_access_from_pointer
id|bv_len
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
id|nbytes
OG
id|bio-&gt;bi_size
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * not a complete bvec done&n;&t;&t;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|nbytes
OG
id|nr_bytes
)paren
)paren
(brace
id|bio_nbytes
op_add_assign
id|nr_bytes
suffix:semicolon
id|total_bytes
op_add_assign
id|nr_bytes
suffix:semicolon
r_break
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t;&t; * advance to the next vector&n;&t;&t;&t; */
id|next_idx
op_increment
suffix:semicolon
id|bio_nbytes
op_add_assign
id|nbytes
suffix:semicolon
)brace
id|total_bytes
op_add_assign
id|nbytes
suffix:semicolon
id|nr_bytes
op_sub_assign
id|nbytes
suffix:semicolon
r_if
c_cond
(paren
(paren
id|bio
op_assign
id|req-&gt;bio
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t;&t; * end more in this run, or just return &squot;not-done&squot;&n;&t;&t;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|nr_bytes
op_le
l_int|0
)paren
)paren
r_break
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * completely done&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|req-&gt;bio
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * if the request wasn&squot;t completed, update state&n;&t; */
r_if
c_cond
(paren
id|bio_nbytes
)paren
(brace
id|bio_endio
c_func
(paren
id|bio
comma
id|bio_nbytes
comma
id|error
)paren
suffix:semicolon
id|bio-&gt;bi_idx
op_add_assign
id|next_idx
suffix:semicolon
id|bio_iovec
c_func
(paren
id|bio
)paren
op_member_access_from_pointer
id|bv_offset
op_add_assign
id|nr_bytes
suffix:semicolon
id|bio_iovec
c_func
(paren
id|bio
)paren
op_member_access_from_pointer
id|bv_len
op_sub_assign
id|nr_bytes
suffix:semicolon
)brace
id|blk_recalc_rq_sectors
c_func
(paren
id|req
comma
id|total_bytes
op_rshift
l_int|9
)paren
suffix:semicolon
id|blk_recalc_rq_segments
c_func
(paren
id|req
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
multiline_comment|/**&n; * end_that_request_first - end I/O on a request&n; * @req:      the request being processed&n; * @uptodate: 1 for success, 0 for I/O error, &lt; 0 for specific error&n; * @nr_sectors: number of sectors to end I/O on&n; *&n; * Description:&n; *     Ends I/O on a number of sectors attached to @req, and sets it up&n; *     for the next range of segments (if any) in the cluster.&n; *&n; * Return:&n; *     0 - we are done with this request, call end_that_request_last()&n; *     1 - still buffers pending for this request&n; **/
DECL|function|end_that_request_first
r_int
id|end_that_request_first
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_sectors
)paren
(brace
r_return
id|__end_that_request_first
c_func
(paren
id|req
comma
id|uptodate
comma
id|nr_sectors
op_lshift
l_int|9
)paren
suffix:semicolon
)brace
DECL|variable|end_that_request_first
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_first
)paren
suffix:semicolon
multiline_comment|/**&n; * end_that_request_chunk - end I/O on a request&n; * @req:      the request being processed&n; * @uptodate: 1 for success, 0 for I/O error, &lt; 0 for specific error&n; * @nr_bytes: number of bytes to complete&n; *&n; * Description:&n; *     Ends I/O on a number of bytes attached to @req, and sets it up&n; *     for the next range of segments (if any). Like end_that_request_first(),&n; *     but deals with bytes instead of sectors.&n; *&n; * Return:&n; *     0 - we are done with this request, call end_that_request_last()&n; *     1 - still buffers pending for this request&n; **/
DECL|function|end_that_request_chunk
r_int
id|end_that_request_chunk
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_bytes
)paren
(brace
r_return
id|__end_that_request_first
c_func
(paren
id|req
comma
id|uptodate
comma
id|nr_bytes
)paren
suffix:semicolon
)brace
DECL|variable|end_that_request_chunk
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_chunk
)paren
suffix:semicolon
multiline_comment|/*&n; * queue lock must be held&n; */
DECL|function|end_that_request_last
r_void
id|end_that_request_last
c_func
(paren
r_struct
id|request
op_star
id|req
)paren
(brace
r_struct
id|gendisk
op_star
id|disk
op_assign
id|req-&gt;rq_disk
suffix:semicolon
r_struct
id|completion
op_star
id|waiting
op_assign
id|req-&gt;waiting
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|laptop_mode
)paren
op_logical_and
id|blk_fs_request
c_func
(paren
id|req
)paren
)paren
id|laptop_io_completion
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|disk
op_logical_and
id|blk_fs_request
c_func
(paren
id|req
)paren
)paren
(brace
r_int
r_int
id|duration
op_assign
id|jiffies
op_minus
id|req-&gt;start_time
suffix:semicolon
r_switch
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
)paren
(brace
r_case
id|WRITE
suffix:colon
id|__disk_stat_inc
c_func
(paren
id|disk
comma
id|writes
)paren
suffix:semicolon
id|__disk_stat_add
c_func
(paren
id|disk
comma
id|write_ticks
comma
id|duration
)paren
suffix:semicolon
r_break
suffix:semicolon
r_case
id|READ
suffix:colon
id|__disk_stat_inc
c_func
(paren
id|disk
comma
id|reads
)paren
suffix:semicolon
id|__disk_stat_add
c_func
(paren
id|disk
comma
id|read_ticks
comma
id|duration
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
id|disk_round_stats
c_func
(paren
id|disk
)paren
suffix:semicolon
id|disk-&gt;in_flight
op_decrement
suffix:semicolon
)brace
id|__blk_put_request
c_func
(paren
id|req-&gt;q
comma
id|req
)paren
suffix:semicolon
multiline_comment|/* Do this LAST! The structure may be freed immediately afterwards */
r_if
c_cond
(paren
id|waiting
)paren
id|complete
c_func
(paren
id|waiting
)paren
suffix:semicolon
)brace
DECL|variable|end_that_request_last
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_last
)paren
suffix:semicolon
DECL|function|end_request
r_void
id|end_request
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|end_that_request_first
c_func
(paren
id|req
comma
id|uptodate
comma
id|req-&gt;hard_cur_sectors
)paren
)paren
(brace
id|add_disk_randomness
c_func
(paren
id|req-&gt;rq_disk
)paren
suffix:semicolon
id|blkdev_dequeue_request
c_func
(paren
id|req
)paren
suffix:semicolon
id|end_that_request_last
c_func
(paren
id|req
)paren
suffix:semicolon
)brace
)brace
DECL|variable|end_request
id|EXPORT_SYMBOL
c_func
(paren
id|end_request
)paren
suffix:semicolon
DECL|function|blk_rq_bio_prep
r_void
id|blk_rq_bio_prep
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
multiline_comment|/* first three bits are identical in rq-&gt;flags and bio-&gt;bi_rw */
id|rq-&gt;flags
op_or_assign
(paren
id|bio-&gt;bi_rw
op_amp
l_int|7
)paren
suffix:semicolon
id|rq-&gt;nr_phys_segments
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|rq-&gt;nr_hw_segments
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|rq-&gt;current_nr_sectors
op_assign
id|bio_cur_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|rq-&gt;hard_cur_sectors
op_assign
id|rq-&gt;current_nr_sectors
suffix:semicolon
id|rq-&gt;hard_nr_sectors
op_assign
id|rq-&gt;nr_sectors
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|rq-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
id|bio
suffix:semicolon
)brace
DECL|variable|blk_rq_bio_prep
id|EXPORT_SYMBOL
c_func
(paren
id|blk_rq_bio_prep
)paren
suffix:semicolon
DECL|function|kblockd_schedule_work
r_int
id|kblockd_schedule_work
c_func
(paren
r_struct
id|work_struct
op_star
id|work
)paren
(brace
r_return
id|queue_work
c_func
(paren
id|kblockd_workqueue
comma
id|work
)paren
suffix:semicolon
)brace
DECL|variable|kblockd_schedule_work
id|EXPORT_SYMBOL
c_func
(paren
id|kblockd_schedule_work
)paren
suffix:semicolon
DECL|function|kblockd_flush
r_void
id|kblockd_flush
c_func
(paren
r_void
)paren
(brace
id|flush_workqueue
c_func
(paren
id|kblockd_workqueue
)paren
suffix:semicolon
)brace
DECL|variable|kblockd_flush
id|EXPORT_SYMBOL
c_func
(paren
id|kblockd_flush
)paren
suffix:semicolon
DECL|function|blk_dev_init
r_int
id|__init
id|blk_dev_init
c_func
(paren
r_void
)paren
(brace
id|kblockd_workqueue
op_assign
id|create_workqueue
c_func
(paren
l_string|&quot;kblockd&quot;
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|kblockd_workqueue
)paren
id|panic
c_func
(paren
l_string|&quot;Failed to create kblockd&bslash;n&quot;
)paren
suffix:semicolon
id|request_cachep
op_assign
id|kmem_cache_create
c_func
(paren
l_string|&quot;blkdev_requests&quot;
comma
r_sizeof
(paren
r_struct
id|request
)paren
comma
l_int|0
comma
id|SLAB_PANIC
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
id|requestq_cachep
op_assign
id|kmem_cache_create
c_func
(paren
l_string|&quot;blkdev_queue&quot;
comma
r_sizeof
(paren
id|request_queue_t
)paren
comma
l_int|0
comma
id|SLAB_PANIC
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
id|iocontext_cachep
op_assign
id|kmem_cache_create
c_func
(paren
l_string|&quot;blkdev_ioc&quot;
comma
r_sizeof
(paren
r_struct
id|io_context
)paren
comma
l_int|0
comma
id|SLAB_PANIC
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
id|blk_max_low_pfn
op_assign
id|max_low_pfn
suffix:semicolon
id|blk_max_pfn
op_assign
id|max_pfn
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * IO Context helper functions&n; */
DECL|function|put_io_context
r_void
id|put_io_context
c_func
(paren
r_struct
id|io_context
op_star
id|ioc
)paren
(brace
r_if
c_cond
(paren
id|ioc
op_eq
l_int|NULL
)paren
r_return
suffix:semicolon
id|BUG_ON
c_func
(paren
id|atomic_read
c_func
(paren
op_amp
id|ioc-&gt;refcount
)paren
op_eq
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
id|atomic_dec_and_test
c_func
(paren
op_amp
id|ioc-&gt;refcount
)paren
)paren
(brace
r_if
c_cond
(paren
id|ioc-&gt;aic
op_logical_and
id|ioc-&gt;aic-&gt;dtor
)paren
id|ioc-&gt;aic
op_member_access_from_pointer
id|dtor
c_func
(paren
id|ioc-&gt;aic
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ioc-&gt;cic
op_logical_and
id|ioc-&gt;cic-&gt;dtor
)paren
id|ioc-&gt;cic
op_member_access_from_pointer
id|dtor
c_func
(paren
id|ioc-&gt;cic
)paren
suffix:semicolon
id|kmem_cache_free
c_func
(paren
id|iocontext_cachep
comma
id|ioc
)paren
suffix:semicolon
)brace
)brace
DECL|variable|put_io_context
id|EXPORT_SYMBOL
c_func
(paren
id|put_io_context
)paren
suffix:semicolon
multiline_comment|/* Called by the exitting task */
DECL|function|exit_io_context
r_void
id|exit_io_context
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_struct
id|io_context
op_star
id|ioc
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|ioc
op_assign
id|current-&gt;io_context
suffix:semicolon
id|current-&gt;io_context
op_assign
l_int|NULL
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ioc-&gt;aic
op_logical_and
id|ioc-&gt;aic
op_member_access_from_pointer
m_exit
)paren
id|ioc-&gt;aic
op_member_access_from_pointer
m_exit
(paren
id|ioc-&gt;aic
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ioc-&gt;cic
op_logical_and
id|ioc-&gt;cic
op_member_access_from_pointer
m_exit
)paren
id|ioc-&gt;cic
op_member_access_from_pointer
m_exit
(paren
id|ioc-&gt;cic
)paren
suffix:semicolon
id|put_io_context
c_func
(paren
id|ioc
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * If the current task has no IO context then create one and initialise it.&n; * If it does have a context, take a ref on it.&n; *&n; * This is always called in the context of the task which submitted the I/O.&n; * But weird things happen, so we disable local interrupts to ensure exclusive&n; * access to *current.&n; */
DECL|function|get_io_context
r_struct
id|io_context
op_star
id|get_io_context
c_func
(paren
r_int
id|gfp_flags
)paren
(brace
r_struct
id|task_struct
op_star
id|tsk
op_assign
id|current
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
r_struct
id|io_context
op_star
id|ret
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|ret
op_assign
id|tsk-&gt;io_context
suffix:semicolon
r_if
c_cond
(paren
id|ret
)paren
r_goto
id|out
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
id|ret
op_assign
id|kmem_cache_alloc
c_func
(paren
id|iocontext_cachep
comma
id|gfp_flags
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ret
)paren
(brace
id|atomic_set
c_func
(paren
op_amp
id|ret-&gt;refcount
comma
l_int|1
)paren
suffix:semicolon
id|ret-&gt;pid
op_assign
id|tsk-&gt;pid
suffix:semicolon
id|ret-&gt;last_waited
op_assign
id|jiffies
suffix:semicolon
multiline_comment|/* doesn&squot;t matter... */
id|ret-&gt;nr_batch_requests
op_assign
l_int|0
suffix:semicolon
multiline_comment|/* because this is 0 */
id|ret-&gt;aic
op_assign
l_int|NULL
suffix:semicolon
id|ret-&gt;cic
op_assign
l_int|NULL
suffix:semicolon
id|spin_lock_init
c_func
(paren
op_amp
id|ret-&gt;lock
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * very unlikely, someone raced with us in setting up the task&n;&t;&t; * io context. free new context and just grab a reference.&n;&t;&t; */
r_if
c_cond
(paren
op_logical_neg
id|tsk-&gt;io_context
)paren
id|tsk-&gt;io_context
op_assign
id|ret
suffix:semicolon
r_else
(brace
id|kmem_cache_free
c_func
(paren
id|iocontext_cachep
comma
id|ret
)paren
suffix:semicolon
id|ret
op_assign
id|tsk-&gt;io_context
suffix:semicolon
)brace
id|out
suffix:colon
id|atomic_inc
c_func
(paren
op_amp
id|ret-&gt;refcount
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
DECL|variable|get_io_context
id|EXPORT_SYMBOL
c_func
(paren
id|get_io_context
)paren
suffix:semicolon
DECL|function|copy_io_context
r_void
id|copy_io_context
c_func
(paren
r_struct
id|io_context
op_star
op_star
id|pdst
comma
r_struct
id|io_context
op_star
op_star
id|psrc
)paren
(brace
r_struct
id|io_context
op_star
id|src
op_assign
op_star
id|psrc
suffix:semicolon
r_struct
id|io_context
op_star
id|dst
op_assign
op_star
id|pdst
suffix:semicolon
r_if
c_cond
(paren
id|src
)paren
(brace
id|BUG_ON
c_func
(paren
id|atomic_read
c_func
(paren
op_amp
id|src-&gt;refcount
)paren
op_eq
l_int|0
)paren
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|src-&gt;refcount
)paren
suffix:semicolon
id|put_io_context
c_func
(paren
id|dst
)paren
suffix:semicolon
op_star
id|pdst
op_assign
id|src
suffix:semicolon
)brace
)brace
DECL|variable|copy_io_context
id|EXPORT_SYMBOL
c_func
(paren
id|copy_io_context
)paren
suffix:semicolon
DECL|function|swap_io_context
r_void
id|swap_io_context
c_func
(paren
r_struct
id|io_context
op_star
op_star
id|ioc1
comma
r_struct
id|io_context
op_star
op_star
id|ioc2
)paren
(brace
r_struct
id|io_context
op_star
id|temp
suffix:semicolon
id|temp
op_assign
op_star
id|ioc1
suffix:semicolon
op_star
id|ioc1
op_assign
op_star
id|ioc2
suffix:semicolon
op_star
id|ioc2
op_assign
id|temp
suffix:semicolon
)brace
DECL|variable|swap_io_context
id|EXPORT_SYMBOL
c_func
(paren
id|swap_io_context
)paren
suffix:semicolon
multiline_comment|/*&n; * sysfs parts below&n; */
DECL|struct|queue_sysfs_entry
r_struct
id|queue_sysfs_entry
(brace
DECL|member|attr
r_struct
id|attribute
id|attr
suffix:semicolon
DECL|member|show
id|ssize_t
(paren
op_star
id|show
)paren
(paren
r_struct
id|request_queue
op_star
comma
r_char
op_star
)paren
suffix:semicolon
DECL|member|store
id|ssize_t
(paren
op_star
id|store
)paren
(paren
r_struct
id|request_queue
op_star
comma
r_const
r_char
op_star
comma
r_int
)paren
suffix:semicolon
)brace
suffix:semicolon
r_static
id|ssize_t
DECL|function|queue_var_show
id|queue_var_show
c_func
(paren
r_int
r_int
id|var
comma
r_char
op_star
id|page
)paren
(brace
r_return
id|sprintf
c_func
(paren
id|page
comma
l_string|&quot;%d&bslash;n&quot;
comma
id|var
)paren
suffix:semicolon
)brace
r_static
id|ssize_t
DECL|function|queue_var_store
id|queue_var_store
c_func
(paren
r_int
r_int
op_star
id|var
comma
r_const
r_char
op_star
id|page
comma
r_int
id|count
)paren
(brace
r_char
op_star
id|p
op_assign
(paren
r_char
op_star
)paren
id|page
suffix:semicolon
op_star
id|var
op_assign
id|simple_strtoul
c_func
(paren
id|p
comma
op_amp
id|p
comma
l_int|10
)paren
suffix:semicolon
r_return
id|count
suffix:semicolon
)brace
DECL|function|queue_requests_show
r_static
id|ssize_t
id|queue_requests_show
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_char
op_star
id|page
)paren
(brace
r_return
id|queue_var_show
c_func
(paren
id|q-&gt;nr_requests
comma
(paren
id|page
)paren
)paren
suffix:semicolon
)brace
r_static
id|ssize_t
DECL|function|queue_requests_store
id|queue_requests_store
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_const
r_char
op_star
id|page
comma
r_int
id|count
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
suffix:semicolon
r_int
id|ret
op_assign
id|queue_var_store
c_func
(paren
op_amp
id|q-&gt;nr_requests
comma
id|page
comma
id|count
)paren
suffix:semicolon
r_if
c_cond
(paren
id|q-&gt;nr_requests
OL
id|BLKDEV_MIN_RQ
)paren
id|q-&gt;nr_requests
op_assign
id|BLKDEV_MIN_RQ
suffix:semicolon
id|blk_queue_congestion_threshold
c_func
(paren
id|q
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|READ
)braket
op_ge
id|queue_congestion_on_threshold
c_func
(paren
id|q
)paren
)paren
id|set_queue_congested
c_func
(paren
id|q
comma
id|READ
)paren
suffix:semicolon
r_else
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|READ
)braket
OL
id|queue_congestion_off_threshold
c_func
(paren
id|q
)paren
)paren
id|clear_queue_congested
c_func
(paren
id|q
comma
id|READ
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|WRITE
)braket
op_ge
id|queue_congestion_on_threshold
c_func
(paren
id|q
)paren
)paren
id|set_queue_congested
c_func
(paren
id|q
comma
id|WRITE
)paren
suffix:semicolon
r_else
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|WRITE
)braket
OL
id|queue_congestion_off_threshold
c_func
(paren
id|q
)paren
)paren
id|clear_queue_congested
c_func
(paren
id|q
comma
id|WRITE
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|READ
)braket
op_ge
id|q-&gt;nr_requests
)paren
(brace
id|blk_set_queue_full
c_func
(paren
id|q
comma
id|READ
)paren
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|READ
)braket
op_plus
l_int|1
op_le
id|q-&gt;nr_requests
)paren
(brace
id|blk_clear_queue_full
c_func
(paren
id|q
comma
id|READ
)paren
suffix:semicolon
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|READ
)braket
)paren
suffix:semicolon
)brace
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|WRITE
)braket
op_ge
id|q-&gt;nr_requests
)paren
(brace
id|blk_set_queue_full
c_func
(paren
id|q
comma
id|WRITE
)paren
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|rl-&gt;count
(braket
id|WRITE
)braket
op_plus
l_int|1
op_le
id|q-&gt;nr_requests
)paren
(brace
id|blk_clear_queue_full
c_func
(paren
id|q
comma
id|WRITE
)paren
suffix:semicolon
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
(braket
id|WRITE
)braket
)paren
suffix:semicolon
)brace
r_return
id|ret
suffix:semicolon
)brace
DECL|function|queue_ra_show
r_static
id|ssize_t
id|queue_ra_show
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_char
op_star
id|page
)paren
(brace
r_int
id|ra_kb
op_assign
id|q-&gt;backing_dev_info.ra_pages
op_lshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
r_return
id|queue_var_show
c_func
(paren
id|ra_kb
comma
(paren
id|page
)paren
)paren
suffix:semicolon
)brace
r_static
id|ssize_t
DECL|function|queue_ra_store
id|queue_ra_store
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_const
r_char
op_star
id|page
comma
r_int
id|count
)paren
(brace
r_int
r_int
id|ra_kb
suffix:semicolon
id|ssize_t
id|ret
op_assign
id|queue_var_store
c_func
(paren
op_amp
id|ra_kb
comma
id|page
comma
id|count
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ra_kb
OG
(paren
id|q-&gt;max_sectors
op_rshift
l_int|1
)paren
)paren
id|ra_kb
op_assign
(paren
id|q-&gt;max_sectors
op_rshift
l_int|1
)paren
suffix:semicolon
id|q-&gt;backing_dev_info.ra_pages
op_assign
id|ra_kb
op_rshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|function|queue_max_sectors_show
r_static
id|ssize_t
id|queue_max_sectors_show
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_char
op_star
id|page
)paren
(brace
r_int
id|max_sectors_kb
op_assign
id|q-&gt;max_sectors
op_rshift
l_int|1
suffix:semicolon
r_return
id|queue_var_show
c_func
(paren
id|max_sectors_kb
comma
(paren
id|page
)paren
)paren
suffix:semicolon
)brace
r_static
id|ssize_t
DECL|function|queue_max_sectors_store
id|queue_max_sectors_store
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_const
r_char
op_star
id|page
comma
r_int
id|count
)paren
(brace
r_int
r_int
id|max_sectors_kb
comma
id|max_hw_sectors_kb
op_assign
id|q-&gt;max_hw_sectors
op_rshift
l_int|1
comma
id|page_kb
op_assign
l_int|1
op_lshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
id|ssize_t
id|ret
op_assign
id|queue_var_store
c_func
(paren
op_amp
id|max_sectors_kb
comma
id|page
comma
id|count
)paren
suffix:semicolon
r_int
id|ra_kb
suffix:semicolon
r_if
c_cond
(paren
id|max_sectors_kb
OG
id|max_hw_sectors_kb
op_logical_or
id|max_sectors_kb
OL
id|page_kb
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
multiline_comment|/*&n;&t; * Take the queue lock to update the readahead and max_sectors&n;&t; * values synchronously:&n;&t; */
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Trim readahead window as well, if necessary:&n;&t; */
id|ra_kb
op_assign
id|q-&gt;backing_dev_info.ra_pages
op_lshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ra_kb
OG
id|max_sectors_kb
)paren
id|q-&gt;backing_dev_info.ra_pages
op_assign
id|max_sectors_kb
op_rshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
id|q-&gt;max_sectors
op_assign
id|max_sectors_kb
op_lshift
l_int|1
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
DECL|function|queue_max_hw_sectors_show
r_static
id|ssize_t
id|queue_max_hw_sectors_show
c_func
(paren
r_struct
id|request_queue
op_star
id|q
comma
r_char
op_star
id|page
)paren
(brace
r_int
id|max_hw_sectors_kb
op_assign
id|q-&gt;max_hw_sectors
op_rshift
l_int|1
suffix:semicolon
r_return
id|queue_var_show
c_func
(paren
id|max_hw_sectors_kb
comma
(paren
id|page
)paren
)paren
suffix:semicolon
)brace
DECL|variable|queue_requests_entry
r_static
r_struct
id|queue_sysfs_entry
id|queue_requests_entry
op_assign
(brace
dot
id|attr
op_assign
(brace
dot
id|name
op_assign
l_string|&quot;nr_requests&quot;
comma
dot
id|mode
op_assign
id|S_IRUGO
op_or
id|S_IWUSR
)brace
comma
dot
id|show
op_assign
id|queue_requests_show
comma
dot
id|store
op_assign
id|queue_requests_store
comma
)brace
suffix:semicolon
DECL|variable|queue_ra_entry
r_static
r_struct
id|queue_sysfs_entry
id|queue_ra_entry
op_assign
(brace
dot
id|attr
op_assign
(brace
dot
id|name
op_assign
l_string|&quot;read_ahead_kb&quot;
comma
dot
id|mode
op_assign
id|S_IRUGO
op_or
id|S_IWUSR
)brace
comma
dot
id|show
op_assign
id|queue_ra_show
comma
dot
id|store
op_assign
id|queue_ra_store
comma
)brace
suffix:semicolon
DECL|variable|queue_max_sectors_entry
r_static
r_struct
id|queue_sysfs_entry
id|queue_max_sectors_entry
op_assign
(brace
dot
id|attr
op_assign
(brace
dot
id|name
op_assign
l_string|&quot;max_sectors_kb&quot;
comma
dot
id|mode
op_assign
id|S_IRUGO
op_or
id|S_IWUSR
)brace
comma
dot
id|show
op_assign
id|queue_max_sectors_show
comma
dot
id|store
op_assign
id|queue_max_sectors_store
comma
)brace
suffix:semicolon
DECL|variable|queue_max_hw_sectors_entry
r_static
r_struct
id|queue_sysfs_entry
id|queue_max_hw_sectors_entry
op_assign
(brace
dot
id|attr
op_assign
(brace
dot
id|name
op_assign
l_string|&quot;max_hw_sectors_kb&quot;
comma
dot
id|mode
op_assign
id|S_IRUGO
)brace
comma
dot
id|show
op_assign
id|queue_max_hw_sectors_show
comma
)brace
suffix:semicolon
DECL|variable|queue_iosched_entry
r_static
r_struct
id|queue_sysfs_entry
id|queue_iosched_entry
op_assign
(brace
dot
id|attr
op_assign
(brace
dot
id|name
op_assign
l_string|&quot;scheduler&quot;
comma
dot
id|mode
op_assign
id|S_IRUGO
op_or
id|S_IWUSR
)brace
comma
dot
id|show
op_assign
id|elv_iosched_show
comma
dot
id|store
op_assign
id|elv_iosched_store
comma
)brace
suffix:semicolon
DECL|variable|default_attrs
r_static
r_struct
id|attribute
op_star
id|default_attrs
(braket
)braket
op_assign
(brace
op_amp
id|queue_requests_entry.attr
comma
op_amp
id|queue_ra_entry.attr
comma
op_amp
id|queue_max_hw_sectors_entry.attr
comma
op_amp
id|queue_max_sectors_entry.attr
comma
op_amp
id|queue_iosched_entry.attr
comma
l_int|NULL
comma
)brace
suffix:semicolon
DECL|macro|to_queue
mdefine_line|#define to_queue(atr) container_of((atr), struct queue_sysfs_entry, attr)
r_static
id|ssize_t
DECL|function|queue_attr_show
id|queue_attr_show
c_func
(paren
r_struct
id|kobject
op_star
id|kobj
comma
r_struct
id|attribute
op_star
id|attr
comma
r_char
op_star
id|page
)paren
(brace
r_struct
id|queue_sysfs_entry
op_star
id|entry
op_assign
id|to_queue
c_func
(paren
id|attr
)paren
suffix:semicolon
r_struct
id|request_queue
op_star
id|q
suffix:semicolon
id|q
op_assign
id|container_of
c_func
(paren
id|kobj
comma
r_struct
id|request_queue
comma
id|kobj
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|entry-&gt;show
)paren
r_return
l_int|0
suffix:semicolon
r_return
id|entry
op_member_access_from_pointer
id|show
c_func
(paren
id|q
comma
id|page
)paren
suffix:semicolon
)brace
r_static
id|ssize_t
DECL|function|queue_attr_store
id|queue_attr_store
c_func
(paren
r_struct
id|kobject
op_star
id|kobj
comma
r_struct
id|attribute
op_star
id|attr
comma
r_const
r_char
op_star
id|page
comma
r_int
id|length
)paren
(brace
r_struct
id|queue_sysfs_entry
op_star
id|entry
op_assign
id|to_queue
c_func
(paren
id|attr
)paren
suffix:semicolon
r_struct
id|request_queue
op_star
id|q
suffix:semicolon
id|q
op_assign
id|container_of
c_func
(paren
id|kobj
comma
r_struct
id|request_queue
comma
id|kobj
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|entry-&gt;store
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
r_return
id|entry
op_member_access_from_pointer
id|store
c_func
(paren
id|q
comma
id|page
comma
id|length
)paren
suffix:semicolon
)brace
DECL|variable|queue_sysfs_ops
r_static
r_struct
id|sysfs_ops
id|queue_sysfs_ops
op_assign
(brace
dot
id|show
op_assign
id|queue_attr_show
comma
dot
id|store
op_assign
id|queue_attr_store
comma
)brace
suffix:semicolon
DECL|variable|queue_ktype
r_struct
id|kobj_type
id|queue_ktype
op_assign
(brace
dot
id|sysfs_ops
op_assign
op_amp
id|queue_sysfs_ops
comma
dot
id|default_attrs
op_assign
id|default_attrs
comma
)brace
suffix:semicolon
DECL|function|blk_register_queue
r_int
id|blk_register_queue
c_func
(paren
r_struct
id|gendisk
op_star
id|disk
)paren
(brace
r_int
id|ret
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
id|disk-&gt;queue
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
op_logical_or
op_logical_neg
id|q-&gt;request_fn
)paren
r_return
op_minus
id|ENXIO
suffix:semicolon
id|q-&gt;kobj.parent
op_assign
id|kobject_get
c_func
(paren
op_amp
id|disk-&gt;kobj
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q-&gt;kobj.parent
)paren
r_return
op_minus
id|EBUSY
suffix:semicolon
id|snprintf
c_func
(paren
id|q-&gt;kobj.name
comma
id|KOBJ_NAME_LEN
comma
l_string|&quot;%s&quot;
comma
l_string|&quot;queue&quot;
)paren
suffix:semicolon
id|q-&gt;kobj.ktype
op_assign
op_amp
id|queue_ktype
suffix:semicolon
id|ret
op_assign
id|kobject_register
c_func
(paren
op_amp
id|q-&gt;kobj
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ret
OL
l_int|0
)paren
r_return
id|ret
suffix:semicolon
id|ret
op_assign
id|elv_register_queue
c_func
(paren
id|q
)paren
suffix:semicolon
r_if
c_cond
(paren
id|ret
)paren
(brace
id|kobject_unregister
c_func
(paren
op_amp
id|q-&gt;kobj
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|blk_unregister_queue
r_void
id|blk_unregister_queue
c_func
(paren
r_struct
id|gendisk
op_star
id|disk
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|disk-&gt;queue
suffix:semicolon
r_if
c_cond
(paren
id|q
op_logical_and
id|q-&gt;request_fn
)paren
(brace
id|elv_unregister_queue
c_func
(paren
id|q
)paren
suffix:semicolon
id|kobject_unregister
c_func
(paren
op_amp
id|q-&gt;kobj
)paren
suffix:semicolon
id|kobject_put
c_func
(paren
op_amp
id|disk-&gt;kobj
)paren
suffix:semicolon
)brace
)brace
eof
