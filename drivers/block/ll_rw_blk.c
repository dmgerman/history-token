multiline_comment|/*&n; *  linux/drivers/block/ll_rw_blk.c&n; *&n; * Copyright (C) 1991, 1992 Linus Torvalds&n; * Copyright (C) 1994,      Karl Keyte: Added support for disk statistics&n; * Elevator latency, (C) 2000  Andrea Arcangeli &lt;andrea@suse.de&gt; SuSE&n; * Queue request tables / lock, selectable elevator, Jens Axboe &lt;axboe@suse.de&gt;&n; * kernel-doc documentation started by NeilBrown &lt;neilb@cse.unsw.edu.au&gt; -  July2000&n; * bio rewrite, highmem i/o, etc, Jens Axboe &lt;axboe@suse.de&gt; - may 2001&n; */
multiline_comment|/*&n; * This handles all read/write requests to block devices&n; */
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/module.h&gt;
macro_line|#include &lt;linux/backing-dev.h&gt;
macro_line|#include &lt;linux/bio.h&gt;
macro_line|#include &lt;linux/blk.h&gt;
macro_line|#include &lt;linux/highmem.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/string.h&gt;
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/bootmem.h&gt;&t;/* for max_pfn/max_low_pfn */
macro_line|#include &lt;linux/completion.h&gt;
macro_line|#include &lt;linux/slab.h&gt;
r_static
r_void
id|blk_unplug_work
c_func
(paren
r_void
op_star
id|data
)paren
suffix:semicolon
r_static
r_void
id|blk_unplug_timeout
c_func
(paren
r_int
r_int
id|data
)paren
suffix:semicolon
multiline_comment|/*&n; * For the allocated request tables&n; */
DECL|variable|request_cachep
r_static
id|kmem_cache_t
op_star
id|request_cachep
suffix:semicolon
multiline_comment|/*&n; * plug management&n; */
r_static
id|LIST_HEAD
c_func
(paren
id|blk_plug_list
)paren
suffix:semicolon
DECL|variable|__cacheline_aligned_in_smp
r_static
id|spinlock_t
id|blk_plug_lock
id|__cacheline_aligned_in_smp
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
multiline_comment|/*&n; * Number of requests per queue.  This many for reads and for writes (twice&n; * this number, total).&n; */
DECL|variable|queue_nr_requests
r_static
r_int
id|queue_nr_requests
suffix:semicolon
multiline_comment|/*&n; * How many free requests must be available before we wake a process which&n; * is waiting for a request?&n; */
DECL|variable|batch_requests
r_static
r_int
id|batch_requests
suffix:semicolon
DECL|variable|blk_max_low_pfn
DECL|variable|blk_max_pfn
r_int
r_int
id|blk_max_low_pfn
comma
id|blk_max_pfn
suffix:semicolon
DECL|variable|blk_nohighio
r_int
id|blk_nohighio
op_assign
l_int|0
suffix:semicolon
DECL|struct|congestion_state
r_static
r_struct
id|congestion_state
(brace
DECL|member|wqh
id|wait_queue_head_t
id|wqh
suffix:semicolon
DECL|member|nr_congested_queues
id|atomic_t
id|nr_congested_queues
suffix:semicolon
DECL|member|nr_active_queues
id|atomic_t
id|nr_active_queues
suffix:semicolon
DECL|variable|congestion_states
)brace
id|congestion_states
(braket
l_int|2
)braket
suffix:semicolon
multiline_comment|/*&n; * Return the threshold (number of free requests) at which the queue is&n; * considered to be congested.  It include a little hysteresis to keep the&n; * context switch rate down.&n; */
DECL|function|queue_congestion_on_threshold
r_static
r_inline
r_int
id|queue_congestion_on_threshold
c_func
(paren
r_void
)paren
(brace
r_int
id|ret
suffix:semicolon
id|ret
op_assign
id|queue_nr_requests
op_div
l_int|8
op_minus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|ret
OL
l_int|0
)paren
id|ret
op_assign
l_int|1
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/*&n; * The threshold at which a queue is considered to be uncongested&n; */
DECL|function|queue_congestion_off_threshold
r_static
r_inline
r_int
id|queue_congestion_off_threshold
c_func
(paren
r_void
)paren
(brace
r_int
id|ret
suffix:semicolon
id|ret
op_assign
id|queue_nr_requests
op_div
l_int|8
op_plus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|ret
OG
id|queue_nr_requests
)paren
id|ret
op_assign
id|queue_nr_requests
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just exitted congestion.  Note this in the global counter of&n; * congested queues, and wake up anyone who was waiting for requests to be&n; * put back.&n; */
DECL|function|clear_queue_congested
r_static
r_void
id|clear_queue_congested
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
r_struct
id|congestion_state
op_star
id|cs
op_assign
op_amp
id|congestion_states
(braket
id|rw
)braket
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_congested
suffix:colon
id|BDI_read_congested
suffix:semicolon
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
)paren
id|atomic_dec
c_func
(paren
op_amp
id|cs-&gt;nr_congested_queues
)paren
suffix:semicolon
r_if
c_cond
(paren
id|waitqueue_active
c_func
(paren
op_amp
id|cs-&gt;wqh
)paren
)paren
id|wake_up
c_func
(paren
op_amp
id|cs-&gt;wqh
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just entered congestion.  Flag that in the queue&squot;s VM-visible&n; * state flags and increment the global gounter of congested queues.&n; */
DECL|function|set_queue_congested
r_static
r_void
id|set_queue_congested
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_congested
suffix:colon
id|BDI_read_congested
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_and_set_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
)paren
id|atomic_inc
c_func
(paren
op_amp
id|congestion_states
(braket
id|rw
)braket
dot
id|nr_congested_queues
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just put back its last read or write request and has fallen&n; * idle.&n; */
DECL|function|clear_queue_active
r_static
r_void
id|clear_queue_active
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_active
suffix:colon
id|BDI_read_active
suffix:semicolon
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
)paren
id|atomic_dec
c_func
(paren
op_amp
id|congestion_states
(braket
id|rw
)braket
dot
id|nr_active_queues
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * A queue has just taken its first read or write request and has become&n; * active.&n; */
DECL|function|set_queue_active
r_static
r_void
id|set_queue_active
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_enum
id|bdi_state
id|bit
suffix:semicolon
id|bit
op_assign
(paren
id|rw
op_eq
id|WRITE
)paren
ques
c_cond
id|BDI_write_active
suffix:colon
id|BDI_read_active
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|test_and_set_bit
c_func
(paren
id|bit
comma
op_amp
id|q-&gt;backing_dev_info.state
)paren
)paren
id|atomic_inc
c_func
(paren
op_amp
id|congestion_states
(braket
id|rw
)braket
dot
id|nr_active_queues
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_get_backing_dev_info - get the address of a queue&squot;s backing_dev_info&n; * @dev:&t;device&n; *&n; * Locates the passed device&squot;s request queue and returns the address of its&n; * backing_dev_info&n; *&n; * Will return NULL if the request queue cannot be located.&n; */
DECL|function|blk_get_backing_dev_info
r_struct
id|backing_dev_info
op_star
id|blk_get_backing_dev_info
c_func
(paren
r_struct
id|block_device
op_star
id|bdev
)paren
(brace
r_struct
id|backing_dev_info
op_star
id|ret
op_assign
l_int|NULL
suffix:semicolon
id|request_queue_t
op_star
id|q
op_assign
id|bdev_get_queue
c_func
(paren
id|bdev
)paren
suffix:semicolon
r_if
c_cond
(paren
id|q
)paren
id|ret
op_assign
op_amp
id|q-&gt;backing_dev_info
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_prep_rq - set a prepare_request function for queue&n; * @q:&t;&t;queue&n; * @pfn:&t;prepare_request function&n; *&n; * It&squot;s possible for a queue to register a prepare_request callback which&n; * is invoked before the request is handed to the request_fn. The goal of&n; * the function is to prepare a request for I/O, it can be used to build a&n; * cdb from the request data for instance.&n; *&n; */
DECL|function|blk_queue_prep_rq
r_void
id|blk_queue_prep_rq
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|prep_rq_fn
op_star
id|pfn
)paren
(brace
id|q-&gt;prep_rq_fn
op_assign
id|pfn
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_merge_bvec - set a merge_bvec function for queue&n; * @q:&t;&t;queue&n; * @mbfn:&t;merge_bvec_fn&n; *&n; * Usually queues have static limitations on the max sectors or segments that&n; * we can put in a request. Stacking drivers may have some settings that&n; * are dynamic, and thus we have to query the queue whether it is ok to&n; * add a new bio_vec to a bio at a given offset or not. If the block device&n; * has such limitations, it needs to register a merge_bvec_fn to control&n; * the size of bio&squot;s sent to it. Per default now merge_bvec_fn is defined for&n; * a queue, and only the fixed limits are honored.&n; *&n; */
DECL|function|blk_queue_merge_bvec
r_void
id|blk_queue_merge_bvec
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|merge_bvec_fn
op_star
id|mbfn
)paren
(brace
id|q-&gt;merge_bvec_fn
op_assign
id|mbfn
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_make_request - define an alternate make_request function for a device&n; * @q:  the request queue for the device to be affected&n; * @mfn: the alternate make_request function&n; *&n; * Description:&n; *    The normal way for &amp;struct bios to be passed to a device&n; *    driver is for them to be collected into requests on a request&n; *    queue, and then to allow the device driver to select requests&n; *    off that queue when it is ready.  This works well for many block&n; *    devices. However some block devices (typically virtual devices&n; *    such as md or lvm) do not benefit from the processing on the&n; *    request queue, and are served best by having the requests passed&n; *    directly to them.  This can be achieved by providing a function&n; *    to blk_queue_make_request().&n; *&n; * Caveat:&n; *    The driver that does this *must* be able to deal appropriately&n; *    with buffers in &quot;highmemory&quot;. This can be accomplished by either calling&n; *    bio_kmap() to get a temporary kernel mapping, or by calling&n; *    blk_queue_bounce() to create a buffer in normal memory.&n; **/
DECL|function|blk_queue_make_request
r_void
id|blk_queue_make_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|make_request_fn
op_star
id|mfn
)paren
(brace
multiline_comment|/*&n;&t; * set defaults&n;&t; */
id|q-&gt;max_phys_segments
op_assign
id|MAX_PHYS_SEGMENTS
suffix:semicolon
id|q-&gt;max_hw_segments
op_assign
id|MAX_HW_SEGMENTS
suffix:semicolon
id|q-&gt;make_request_fn
op_assign
id|mfn
suffix:semicolon
id|q-&gt;backing_dev_info.ra_pages
op_assign
(paren
id|VM_MAX_READAHEAD
op_star
l_int|1024
)paren
op_div
id|PAGE_CACHE_SIZE
suffix:semicolon
id|q-&gt;backing_dev_info.state
op_assign
l_int|0
suffix:semicolon
id|blk_queue_max_sectors
c_func
(paren
id|q
comma
id|MAX_SECTORS
)paren
suffix:semicolon
id|blk_queue_hardsect_size
c_func
(paren
id|q
comma
l_int|512
)paren
suffix:semicolon
id|blk_queue_dma_alignment
c_func
(paren
id|q
comma
l_int|511
)paren
suffix:semicolon
id|q-&gt;unplug_thresh
op_assign
l_int|4
suffix:semicolon
multiline_comment|/* hmm */
id|q-&gt;unplug_delay
op_assign
(paren
l_int|3
op_star
id|HZ
)paren
op_div
l_int|1000
suffix:semicolon
multiline_comment|/* 3 milliseconds */
r_if
c_cond
(paren
id|q-&gt;unplug_delay
op_eq
l_int|0
)paren
id|q-&gt;unplug_delay
op_assign
l_int|1
suffix:semicolon
id|init_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
id|INIT_WORK
c_func
(paren
op_amp
id|q-&gt;unplug_work
comma
id|blk_unplug_work
comma
id|q
)paren
suffix:semicolon
id|q-&gt;unplug_timer.function
op_assign
id|blk_unplug_timeout
suffix:semicolon
id|q-&gt;unplug_timer.data
op_assign
(paren
r_int
r_int
)paren
id|q
suffix:semicolon
multiline_comment|/*&n;&t; * by default assume old behaviour and bounce for any highmem page&n;&t; */
id|blk_queue_bounce_limit
c_func
(paren
id|q
comma
id|BLK_BOUNCE_HIGH
)paren
suffix:semicolon
id|init_waitqueue_head
c_func
(paren
op_amp
id|q-&gt;queue_wait
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|q-&gt;plug_list
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_bounce_limit - set bounce buffer limit for queue&n; * @q:  the request queue for the device&n; * @dma_addr:   bus address limit&n; *&n; * Description:&n; *    Different hardware can have different requirements as to what pages&n; *    it can do I/O directly to. A low level driver can call&n; *    blk_queue_bounce_limit to have lower memory pages allocated as bounce&n; *    buffers for doing I/O to pages residing above @page. By default&n; *    the block layer sets this to the highest numbered &quot;low&quot; memory page.&n; **/
DECL|function|blk_queue_bounce_limit
r_void
id|blk_queue_bounce_limit
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|u64
id|dma_addr
)paren
(brace
r_int
r_int
id|bounce_pfn
op_assign
id|dma_addr
op_rshift
id|PAGE_SHIFT
suffix:semicolon
r_int
r_int
id|mb
op_assign
id|dma_addr
op_rshift
l_int|20
suffix:semicolon
r_static
id|request_queue_t
op_star
id|last_q
suffix:semicolon
multiline_comment|/*&n;&t; * set appropriate bounce gfp mask -- unfortunately we don&squot;t have a&n;&t; * full 4GB zone, so we have to resort to low memory for any bounces.&n;&t; * ISA has its own &lt; 16MB zone.&n;&t; */
r_if
c_cond
(paren
id|bounce_pfn
OL
id|blk_max_low_pfn
)paren
(brace
id|BUG_ON
c_func
(paren
id|dma_addr
OL
id|BLK_BOUNCE_ISA
)paren
suffix:semicolon
id|init_emergency_isa_pool
c_func
(paren
)paren
suffix:semicolon
id|q-&gt;bounce_gfp
op_assign
id|GFP_NOIO
op_or
id|GFP_DMA
suffix:semicolon
)brace
r_else
id|q-&gt;bounce_gfp
op_assign
id|GFP_NOIO
suffix:semicolon
multiline_comment|/*&n;&t; * keep this for debugging for now...&n;&t; */
r_if
c_cond
(paren
id|dma_addr
op_ne
id|BLK_BOUNCE_HIGH
op_logical_and
id|q
op_ne
id|last_q
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;blk: queue %p, &quot;
comma
id|q
)paren
suffix:semicolon
r_if
c_cond
(paren
id|dma_addr
op_eq
id|BLK_BOUNCE_ANY
)paren
id|printk
c_func
(paren
l_string|&quot;no I/O memory limit&bslash;n&quot;
)paren
suffix:semicolon
r_else
id|printk
c_func
(paren
l_string|&quot;I/O limit %luMb (mask 0x%Lx)&bslash;n&quot;
comma
id|mb
comma
(paren
r_int
r_int
)paren
id|dma_addr
)paren
suffix:semicolon
)brace
id|q-&gt;bounce_pfn
op_assign
id|bounce_pfn
suffix:semicolon
id|last_q
op_assign
id|q
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_max_sectors - set max sectors for a request for this queue&n; * @q:  the request queue for the device&n; * @max_sectors:  max sectors in the usual 512b unit&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the size of&n; *    received requests.&n; **/
DECL|function|blk_queue_max_sectors
r_void
id|blk_queue_max_sectors
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_sectors
)paren
(brace
r_if
c_cond
(paren
(paren
id|max_sectors
op_lshift
l_int|9
)paren
OL
id|PAGE_CACHE_SIZE
)paren
(brace
id|max_sectors
op_assign
l_int|1
op_lshift
(paren
id|PAGE_CACHE_SHIFT
op_minus
l_int|9
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_sectors
)paren
suffix:semicolon
)brace
id|q-&gt;max_sectors
op_assign
id|max_sectors
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_max_phys_segments - set max phys segments for a request for this queue&n; * @q:  the request queue for the device&n; * @max_segments:  max number of segments&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the number of&n; *    physical data segments in a request.  This would be the largest sized&n; *    scatter list the driver could handle.&n; **/
DECL|function|blk_queue_max_phys_segments
r_void
id|blk_queue_max_phys_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_segments
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|max_segments
)paren
(brace
id|max_segments
op_assign
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_segments
)paren
suffix:semicolon
)brace
id|q-&gt;max_phys_segments
op_assign
id|max_segments
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_max_hw_segments - set max hw segments for a request for this queue&n; * @q:  the request queue for the device&n; * @max_segments:  max number of segments&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the number of&n; *    hw data segments in a request.  This would be the largest number of&n; *    address/length pairs the host adapter can actually give as once&n; *    to the device.&n; **/
DECL|function|blk_queue_max_hw_segments
r_void
id|blk_queue_max_hw_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_segments
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|max_segments
)paren
(brace
id|max_segments
op_assign
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_segments
)paren
suffix:semicolon
)brace
id|q-&gt;max_hw_segments
op_assign
id|max_segments
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_max_segment_size - set max segment size for blk_rq_map_sg&n; * @q:  the request queue for the device&n; * @max_size:  max size of segment in bytes&n; *&n; * Description:&n; *    Enables a low level driver to set an upper limit on the size of a&n; *    coalesced segment&n; **/
DECL|function|blk_queue_max_segment_size
r_void
id|blk_queue_max_segment_size
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|max_size
)paren
(brace
r_if
c_cond
(paren
id|max_size
OL
id|PAGE_CACHE_SIZE
)paren
(brace
id|max_size
op_assign
id|PAGE_CACHE_SIZE
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|max_size
)paren
suffix:semicolon
)brace
id|q-&gt;max_segment_size
op_assign
id|max_size
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_hardsect_size - set hardware sector size for the queue&n; * @q:  the request queue for the device&n; * @size:  the hardware sector size, in bytes&n; *&n; * Description:&n; *   This should typically be set to the lowest possible sector size&n; *   that the hardware can operate on (possible without reverting to&n; *   even internal read-modify-write operations). Usually the default&n; *   of 512 covers most hardware.&n; **/
DECL|function|blk_queue_hardsect_size
r_void
id|blk_queue_hardsect_size
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|size
)paren
(brace
id|q-&gt;hardsect_size
op_assign
id|size
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_segment_boundary - set boundary rules for segment merging&n; * @q:  the request queue for the device&n; * @mask:  the memory boundary mask&n; **/
DECL|function|blk_queue_segment_boundary
r_void
id|blk_queue_segment_boundary
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
r_int
id|mask
)paren
(brace
r_if
c_cond
(paren
id|mask
OL
id|PAGE_CACHE_SIZE
op_minus
l_int|1
)paren
(brace
id|mask
op_assign
id|PAGE_CACHE_SIZE
op_minus
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: set to minimum %lx&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|mask
)paren
suffix:semicolon
)brace
id|q-&gt;seg_boundary_mask
op_assign
id|mask
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_dma_alignment - set dma length and memory alignment&n; * @q:  the request queue for the device&n; * @dma_mask:  alignment mask&n; *&n; * description:&n; *    set required memory and length aligment for direct dma transactions.&n; *    this is used when buiding direct io requests for the queue.&n; *&n; **/
DECL|function|blk_queue_dma_alignment
r_void
id|blk_queue_dma_alignment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|mask
)paren
(brace
id|q-&gt;dma_alignment
op_assign
id|mask
suffix:semicolon
)brace
DECL|function|blk_queue_assign_lock
r_void
id|blk_queue_assign_lock
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|spinlock_t
op_star
id|lock
)paren
(brace
id|spin_lock_init
c_func
(paren
id|lock
)paren
suffix:semicolon
id|q-&gt;queue_lock
op_assign
id|lock
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_find_tag - find a request by its tag and queue&n; *&n; * @q:&t; The request queue for the device&n; * @tag: The tag of the request&n; *&n; * Notes:&n; *    Should be used when a device returns a tag and you want to match&n; *    it with a request.&n; *&n; *    no locks need be held.&n; **/
DECL|function|blk_queue_find_tag
r_struct
id|request
op_star
id|blk_queue_find_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|tag
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bqt
op_eq
l_int|NULL
op_logical_or
id|bqt-&gt;max_depth
OL
id|tag
)paren
)paren
(brace
r_return
l_int|NULL
suffix:semicolon
)brace
r_return
id|bqt-&gt;tag_index
(braket
id|tag
)braket
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_free_tags - release tag maintenance info&n; * @q:  the request queue for the device&n; *&n; *  Notes:&n; *    blk_cleanup_queue() will take care of calling this function, if tagging&n; *    has been used. So there&squot;s usually no need to call this directly, unless&n; *    tagging is just being disabled but the queue remains in function.&n; **/
DECL|function|blk_queue_free_tags
r_void
id|blk_queue_free_tags
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|bqt
)paren
r_return
suffix:semicolon
id|BUG_ON
c_func
(paren
id|bqt-&gt;busy
)paren
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|bqt-&gt;busy_list
)paren
)paren
suffix:semicolon
id|kfree
c_func
(paren
id|bqt-&gt;tag_index
)paren
suffix:semicolon
id|bqt-&gt;tag_index
op_assign
l_int|NULL
suffix:semicolon
id|kfree
c_func
(paren
id|bqt-&gt;tag_map
)paren
suffix:semicolon
id|bqt-&gt;tag_map
op_assign
l_int|NULL
suffix:semicolon
id|kfree
c_func
(paren
id|bqt
)paren
suffix:semicolon
id|q-&gt;queue_tags
op_assign
l_int|NULL
suffix:semicolon
id|q-&gt;queue_flags
op_and_assign
op_complement
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_QUEUED
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_init_tags - initialize the queue tag info&n; * @q:  the request queue for the device&n; * @depth:  the maximum queue depth supported&n; **/
DECL|function|blk_queue_init_tags
r_int
id|blk_queue_init_tags
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|depth
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|tags
suffix:semicolon
r_int
id|bits
comma
id|i
suffix:semicolon
r_if
c_cond
(paren
id|depth
OG
(paren
id|queue_nr_requests
op_star
l_int|2
)paren
)paren
(brace
id|depth
op_assign
(paren
id|queue_nr_requests
op_star
l_int|2
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;blk_queue_init_tags: adjusted depth to %d&bslash;n&quot;
comma
id|depth
)paren
suffix:semicolon
)brace
id|tags
op_assign
id|kmalloc
c_func
(paren
r_sizeof
(paren
r_struct
id|blk_queue_tag
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tags
)paren
r_goto
id|fail
suffix:semicolon
id|tags-&gt;tag_index
op_assign
id|kmalloc
c_func
(paren
id|depth
op_star
r_sizeof
(paren
r_struct
id|request
op_star
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tags-&gt;tag_index
)paren
r_goto
id|fail_index
suffix:semicolon
id|bits
op_assign
(paren
id|depth
op_div
id|BLK_TAGS_PER_LONG
)paren
op_plus
l_int|1
suffix:semicolon
id|tags-&gt;tag_map
op_assign
id|kmalloc
c_func
(paren
id|bits
op_star
r_sizeof
(paren
r_int
r_int
)paren
comma
id|GFP_ATOMIC
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|tags-&gt;tag_map
)paren
r_goto
id|fail_map
suffix:semicolon
id|memset
c_func
(paren
id|tags-&gt;tag_index
comma
l_int|0
comma
id|depth
op_star
r_sizeof
(paren
r_struct
id|request
op_star
)paren
)paren
suffix:semicolon
id|memset
c_func
(paren
id|tags-&gt;tag_map
comma
l_int|0
comma
id|bits
op_star
r_sizeof
(paren
r_int
r_int
)paren
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|tags-&gt;busy_list
)paren
suffix:semicolon
id|tags-&gt;busy
op_assign
l_int|0
suffix:semicolon
id|tags-&gt;max_depth
op_assign
id|depth
suffix:semicolon
multiline_comment|/*&n;&t; * set the upper bits if the depth isn&squot;t a multiple of the word size&n;&t; */
r_for
c_loop
(paren
id|i
op_assign
id|depth
suffix:semicolon
id|i
OL
id|bits
op_star
id|BLK_TAGS_PER_LONG
suffix:semicolon
id|i
op_increment
)paren
id|__set_bit
c_func
(paren
id|i
comma
id|tags-&gt;tag_map
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * assign it, all done&n;&t; */
id|q-&gt;queue_tags
op_assign
id|tags
suffix:semicolon
id|q-&gt;queue_flags
op_or_assign
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_QUEUED
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|fail_map
suffix:colon
id|kfree
c_func
(paren
id|tags-&gt;tag_index
)paren
suffix:semicolon
id|fail_index
suffix:colon
id|kfree
c_func
(paren
id|tags
)paren
suffix:semicolon
id|fail
suffix:colon
r_return
op_minus
id|ENOMEM
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_end_tag - end tag operations for a request&n; * @q:  the request queue for the device&n; * @tag:  the tag that has completed&n; *&n; *  Description:&n; *    Typically called when end_that_request_first() returns 0, meaning&n; *    all transfers have been done for a request. It&squot;s important to call&n; *    this function before end_that_request_last(), as that will put the&n; *    request back on the free list thus corrupting the internal tag list.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_end_tag
r_void
id|blk_queue_end_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_int
id|tag
op_assign
id|rq-&gt;tag
suffix:semicolon
id|BUG_ON
c_func
(paren
id|tag
op_eq
op_minus
l_int|1
)paren
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|tag
op_ge
id|bqt-&gt;max_depth
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|__test_and_clear_bit
c_func
(paren
id|tag
comma
id|bqt-&gt;tag_map
)paren
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;attempt to clear non-busy tag (%d)&bslash;n&quot;
comma
id|tag
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_QUEUED
suffix:semicolon
id|rq-&gt;tag
op_assign
op_minus
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_eq
l_int|NULL
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;tag %d is missing&bslash;n&quot;
comma
id|tag
)paren
suffix:semicolon
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_assign
l_int|NULL
suffix:semicolon
id|bqt-&gt;busy
op_decrement
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_start_tag - find a free tag and assign it&n; * @q:  the request queue for the device&n; * @rq:  the block request that needs tagging&n; *&n; *  Description:&n; *    This can either be used as a stand-alone helper, or possibly be&n; *    assigned as the queue &amp;prep_rq_fn (in which case &amp;struct request&n; *    automagically gets a tag assigned). Note that this function&n; *    assumes that any type of request can be queued! if this is not&n; *    true for your device, you must check the request type before&n; *    calling this function.  The request will also be removed from&n; *    the request queue, so it&squot;s the drivers responsibility to readd&n; *    it if it should need to be restarted for some reason.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_start_tag
r_int
id|blk_queue_start_tag
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_int
r_int
op_star
id|map
op_assign
id|bqt-&gt;tag_map
suffix:semicolon
r_int
id|tag
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
(paren
id|rq-&gt;flags
op_amp
id|REQ_QUEUED
)paren
)paren
)paren
(brace
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;request %p for device [%s] already tagged %d&quot;
comma
id|rq
comma
id|rq-&gt;rq_disk
ques
c_cond
id|rq-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
comma
id|rq-&gt;tag
)paren
suffix:semicolon
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
r_for
c_loop
(paren
id|map
op_assign
id|bqt-&gt;tag_map
suffix:semicolon
op_star
id|map
op_eq
op_minus
l_int|1UL
suffix:semicolon
id|map
op_increment
)paren
(brace
id|tag
op_add_assign
id|BLK_TAGS_PER_LONG
suffix:semicolon
r_if
c_cond
(paren
id|tag
op_ge
id|bqt-&gt;max_depth
)paren
r_return
l_int|1
suffix:semicolon
)brace
id|tag
op_add_assign
id|ffz
c_func
(paren
op_star
id|map
)paren
suffix:semicolon
id|__set_bit
c_func
(paren
id|tag
comma
id|bqt-&gt;tag_map
)paren
suffix:semicolon
id|rq-&gt;flags
op_or_assign
id|REQ_QUEUED
suffix:semicolon
id|rq-&gt;tag
op_assign
id|tag
suffix:semicolon
id|bqt-&gt;tag_index
(braket
id|tag
)braket
op_assign
id|rq
suffix:semicolon
id|blkdev_dequeue_request
c_func
(paren
id|rq
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|rq-&gt;queuelist
comma
op_amp
id|bqt-&gt;busy_list
)paren
suffix:semicolon
id|bqt-&gt;busy
op_increment
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_queue_invalidate_tags - invalidate all pending tags&n; * @q:  the request queue for the device&n; *&n; *  Description:&n; *   Hardware conditions may dictate a need to stop all pending requests.&n; *   In this case, we will safely clear the block side of the tag queue and&n; *   readd all requests to the request queue in the right order.&n; *&n; *  Notes:&n; *   queue lock must be held.&n; **/
DECL|function|blk_queue_invalidate_tags
r_void
id|blk_queue_invalidate_tags
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|blk_queue_tag
op_star
id|bqt
op_assign
id|q-&gt;queue_tags
suffix:semicolon
r_struct
id|list_head
op_star
id|tmp
comma
op_star
id|n
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|list_for_each_safe
c_func
(paren
id|tmp
comma
id|n
comma
op_amp
id|bqt-&gt;busy_list
)paren
(brace
id|rq
op_assign
id|list_entry_rq
c_func
(paren
id|tmp
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;tag
op_eq
op_minus
l_int|1
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;bad tag found on list&bslash;n&quot;
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_QUEUED
suffix:semicolon
)brace
r_else
id|blk_queue_end_tag
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|rq-&gt;flags
op_and_assign
op_complement
id|REQ_STARTED
suffix:semicolon
id|__elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
l_int|0
comma
l_int|0
)paren
suffix:semicolon
)brace
)brace
DECL|variable|rq_flags
r_static
r_char
op_star
id|rq_flags
(braket
)braket
op_assign
(brace
l_string|&quot;REQ_RW&quot;
comma
l_string|&quot;REQ_RW_AHEAD&quot;
comma
l_string|&quot;REQ_SOFTBARRIER&quot;
comma
l_string|&quot;REQ_HARDBARRIER&quot;
comma
l_string|&quot;REQ_CMD&quot;
comma
l_string|&quot;REQ_NOMERGE&quot;
comma
l_string|&quot;REQ_STARTED&quot;
comma
l_string|&quot;REQ_DONTPREP&quot;
comma
l_string|&quot;REQ_QUEUED&quot;
comma
l_string|&quot;REQ_PC&quot;
comma
l_string|&quot;REQ_BLOCK_PC&quot;
comma
l_string|&quot;REQ_SENSE&quot;
comma
l_string|&quot;REQ_FAILED&quot;
comma
l_string|&quot;REQ_QUIET&quot;
comma
l_string|&quot;REQ_SPECIAL&quot;
comma
l_string|&quot;REQ_DRIVE_CMD&quot;
comma
l_string|&quot;REQ_DRIVE_TASK&quot;
comma
l_string|&quot;REQ_DRIVE_TASKFILE&quot;
comma
)brace
suffix:semicolon
DECL|function|blk_dump_rq_flags
r_void
id|blk_dump_rq_flags
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_char
op_star
id|msg
)paren
(brace
r_int
id|bit
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: dev %s: flags = &quot;
comma
id|msg
comma
id|rq-&gt;rq_disk
ques
c_cond
id|rq-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
)paren
suffix:semicolon
id|bit
op_assign
l_int|0
suffix:semicolon
r_do
(brace
r_if
c_cond
(paren
id|rq-&gt;flags
op_amp
(paren
l_int|1
op_lshift
id|bit
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;%s &quot;
comma
id|rq_flags
(braket
id|bit
)braket
)paren
suffix:semicolon
id|bit
op_increment
suffix:semicolon
)brace
r_while
c_loop
(paren
id|bit
OL
id|__REQ_NR_BITS
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;&bslash;nsector %llu, nr/cnr %lu/%u&bslash;n&quot;
comma
(paren
r_int
r_int
r_int
)paren
id|rq-&gt;sector
comma
id|rq-&gt;nr_sectors
comma
id|rq-&gt;current_nr_sectors
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;bio %p, biotail %p, buffer %p, data %p, len %u&bslash;n&quot;
comma
id|rq-&gt;bio
comma
id|rq-&gt;biotail
comma
id|rq-&gt;buffer
comma
id|rq-&gt;data
comma
id|rq-&gt;data_len
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq-&gt;flags
op_amp
(paren
id|REQ_BLOCK_PC
op_or
id|REQ_PC
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;cdb: &quot;
)paren
suffix:semicolon
r_for
c_loop
(paren
id|bit
op_assign
l_int|0
suffix:semicolon
id|bit
OL
r_sizeof
(paren
id|rq-&gt;cmd
)paren
suffix:semicolon
id|bit
op_increment
)paren
id|printk
c_func
(paren
l_string|&quot;%02x &quot;
comma
id|rq-&gt;cmd
(braket
id|bit
)braket
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;&bslash;n&quot;
)paren
suffix:semicolon
)brace
)brace
DECL|function|blk_recount_segments
r_void
id|blk_recount_segments
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|bio_vec
op_star
id|bv
comma
op_star
id|bvprv
op_assign
l_int|NULL
suffix:semicolon
r_int
id|i
comma
id|nr_phys_segs
comma
id|nr_hw_segs
comma
id|seg_size
comma
id|cluster
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|bio-&gt;bi_io_vec
)paren
)paren
r_return
suffix:semicolon
id|cluster
op_assign
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
id|seg_size
op_assign
id|nr_phys_segs
op_assign
id|nr_hw_segs
op_assign
l_int|0
suffix:semicolon
id|bio_for_each_segment
c_func
(paren
id|bv
comma
id|bio
comma
id|i
)paren
(brace
r_if
c_cond
(paren
id|bvprv
op_logical_and
id|cluster
)paren
(brace
r_if
c_cond
(paren
id|seg_size
op_plus
id|bv-&gt;bv_len
OG
id|q-&gt;max_segment_size
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bv
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bvprv
comma
id|bv
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
id|seg_size
op_add_assign
id|bv-&gt;bv_len
suffix:semicolon
id|bvprv
op_assign
id|bv
suffix:semicolon
r_continue
suffix:semicolon
)brace
id|new_segment
suffix:colon
r_if
c_cond
(paren
op_logical_neg
id|bvprv
op_logical_or
op_logical_neg
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bv
)paren
)paren
id|nr_hw_segs
op_increment
suffix:semicolon
id|nr_phys_segs
op_increment
suffix:semicolon
id|bvprv
op_assign
id|bv
suffix:semicolon
id|seg_size
op_assign
id|bv-&gt;bv_len
suffix:semicolon
)brace
id|bio-&gt;bi_phys_segments
op_assign
id|nr_phys_segs
suffix:semicolon
id|bio-&gt;bi_hw_segments
op_assign
id|nr_hw_segs
suffix:semicolon
id|bio-&gt;bi_flags
op_or_assign
(paren
l_int|1
op_lshift
id|BIO_SEG_VALID
)paren
suffix:semicolon
)brace
DECL|function|blk_phys_contig_segment
r_int
id|blk_phys_contig_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
comma
r_struct
id|bio
op_star
id|nxt
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|nxt
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|bio-&gt;bi_size
op_plus
id|nxt-&gt;bi_size
OG
id|q-&gt;max_segment_size
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * bio and nxt are contigous in memory, check if the queue allows&n;&t; * these two to be merged into one&n;&t; */
r_if
c_cond
(paren
id|BIO_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bio
comma
id|nxt
)paren
)paren
r_return
l_int|1
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|blk_hw_contig_segment
r_int
id|blk_hw_contig_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
comma
r_struct
id|bio
op_star
id|nxt
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
(paren
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|nxt
)paren
)paren
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|bio-&gt;bi_size
op_plus
id|nxt-&gt;bi_size
OG
id|q-&gt;max_segment_size
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * bio and nxt are contigous in memory, check if the queue allows&n;&t; * these two to be merged into one&n;&t; */
r_if
c_cond
(paren
id|BIO_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bio
comma
id|nxt
)paren
)paren
r_return
l_int|1
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * map a request to scatterlist, return number of sg entries setup. Caller&n; * must make sure sg can hold rq-&gt;nr_phys_segments entries&n; */
DECL|function|blk_rq_map_sg
r_int
id|blk_rq_map_sg
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
comma
r_struct
id|scatterlist
op_star
id|sg
)paren
(brace
r_struct
id|bio_vec
op_star
id|bvec
comma
op_star
id|bvprv
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_int
id|nsegs
comma
id|i
comma
id|cluster
suffix:semicolon
id|nsegs
op_assign
l_int|0
suffix:semicolon
id|cluster
op_assign
id|q-&gt;queue_flags
op_amp
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * for each bio in rq&n;&t; */
id|bvprv
op_assign
l_int|NULL
suffix:semicolon
id|rq_for_each_bio
c_func
(paren
id|bio
comma
id|rq
)paren
(brace
multiline_comment|/*&n;&t;&t; * for each segment in bio&n;&t;&t; */
id|bio_for_each_segment
c_func
(paren
id|bvec
comma
id|bio
comma
id|i
)paren
(brace
r_int
id|nbytes
op_assign
id|bvec-&gt;bv_len
suffix:semicolon
r_if
c_cond
(paren
id|bvprv
op_logical_and
id|cluster
)paren
(brace
r_if
c_cond
(paren
id|sg
(braket
id|nsegs
op_minus
l_int|1
)braket
dot
id|length
op_plus
id|nbytes
OG
id|q-&gt;max_segment_size
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_PHYS_MERGEABLE
c_func
(paren
id|bvprv
comma
id|bvec
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|BIOVEC_SEG_BOUNDARY
c_func
(paren
id|q
comma
id|bvprv
comma
id|bvec
)paren
)paren
r_goto
id|new_segment
suffix:semicolon
id|sg
(braket
id|nsegs
op_minus
l_int|1
)braket
dot
id|length
op_add_assign
id|nbytes
suffix:semicolon
)brace
r_else
(brace
id|new_segment
suffix:colon
id|memset
c_func
(paren
op_amp
id|sg
(braket
id|nsegs
)braket
comma
l_int|0
comma
r_sizeof
(paren
r_struct
id|scatterlist
)paren
)paren
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|page
op_assign
id|bvec-&gt;bv_page
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|length
op_assign
id|nbytes
suffix:semicolon
id|sg
(braket
id|nsegs
)braket
dot
id|offset
op_assign
id|bvec-&gt;bv_offset
suffix:semicolon
id|nsegs
op_increment
suffix:semicolon
)brace
id|bvprv
op_assign
id|bvec
suffix:semicolon
)brace
multiline_comment|/* segments in bio */
)brace
multiline_comment|/* bios in rq */
r_return
id|nsegs
suffix:semicolon
)brace
multiline_comment|/*&n; * the standard queue merge functions, can be overridden with device&n; * specific ones if so desired&n; */
DECL|function|ll_new_mergeable
r_static
r_inline
r_int
id|ll_new_mergeable
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_phys_segs
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_phys_segments
op_plus
id|nr_phys_segs
OG
id|q-&gt;max_phys_segments
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * A hw segment is just getting larger, bump just the phys&n;&t; * counter.&n;&t; */
id|req-&gt;nr_phys_segments
op_add_assign
id|nr_phys_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|ll_new_hw_segment
r_static
r_inline
r_int
id|ll_new_hw_segment
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|nr_hw_segs
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_int
id|nr_phys_segs
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;nr_hw_segments
op_plus
id|nr_hw_segs
OG
id|q-&gt;max_hw_segments
op_logical_or
id|req-&gt;nr_phys_segments
op_plus
id|nr_phys_segs
OG
id|q-&gt;max_phys_segments
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * This will form the start of a new hw segment.  Bump both&n;&t; * counters.&n;&t; */
id|req-&gt;nr_hw_segments
op_add_assign
id|nr_hw_segs
suffix:semicolon
id|req-&gt;nr_phys_segments
op_add_assign
id|nr_phys_segs
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|ll_back_merge_fn
r_static
r_int
id|ll_back_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_if
c_cond
(paren
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|req-&gt;biotail
)paren
comma
id|__BVEC_START
c_func
(paren
id|bio
)paren
)paren
)paren
r_return
id|ll_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
r_return
id|ll_new_hw_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
DECL|function|ll_front_merge_fn
r_static
r_int
id|ll_front_merge_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_if
c_cond
(paren
id|req-&gt;nr_sectors
op_plus
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
(brace
id|req-&gt;flags
op_or_assign
id|REQ_NOMERGE
suffix:semicolon
id|q-&gt;last_merge
op_assign
l_int|NULL
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
r_if
c_cond
(paren
id|BIOVEC_VIRT_MERGEABLE
c_func
(paren
id|__BVEC_END
c_func
(paren
id|bio
)paren
comma
id|__BVEC_START
c_func
(paren
id|req-&gt;bio
)paren
)paren
)paren
r_return
id|ll_new_mergeable
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
r_return
id|ll_new_hw_segment
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
suffix:semicolon
)brace
DECL|function|ll_merge_requests_fn
r_static
r_int
id|ll_merge_requests_fn
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|request
op_star
id|next
)paren
(brace
r_int
id|total_phys_segments
op_assign
id|req-&gt;nr_phys_segments
op_plus
id|next-&gt;nr_phys_segments
suffix:semicolon
r_int
id|total_hw_segments
op_assign
id|req-&gt;nr_hw_segments
op_plus
id|next-&gt;nr_hw_segments
suffix:semicolon
multiline_comment|/*&n;&t; * First check if the either of the requests are re-queued&n;&t; * requests.  Can&squot;t merge them if they are.&n;&t; */
r_if
c_cond
(paren
id|req-&gt;special
op_logical_or
id|next-&gt;special
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * Will it become to large?&n;&t; */
r_if
c_cond
(paren
(paren
id|req-&gt;nr_sectors
op_plus
id|next-&gt;nr_sectors
)paren
OG
id|q-&gt;max_sectors
)paren
r_return
l_int|0
suffix:semicolon
id|total_phys_segments
op_assign
id|req-&gt;nr_phys_segments
op_plus
id|next-&gt;nr_phys_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_phys_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
id|total_phys_segments
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|total_phys_segments
OG
id|q-&gt;max_phys_segments
)paren
r_return
l_int|0
suffix:semicolon
id|total_hw_segments
op_assign
id|req-&gt;nr_hw_segments
op_plus
id|next-&gt;nr_hw_segments
suffix:semicolon
r_if
c_cond
(paren
id|blk_hw_contig_segment
c_func
(paren
id|q
comma
id|req-&gt;biotail
comma
id|next-&gt;bio
)paren
)paren
id|total_hw_segments
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|total_hw_segments
OG
id|q-&gt;max_hw_segments
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/* Merge is OK... */
id|req-&gt;nr_phys_segments
op_assign
id|total_phys_segments
suffix:semicolon
id|req-&gt;nr_hw_segments
op_assign
id|total_hw_segments
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
multiline_comment|/*&n; * &quot;plug&quot; the device if there are no outstanding requests: this will&n; * force the transfer to start only after we have put all the requests&n; * on the list.&n; *&n; * This is called with interrupts off and no requests on the queue and&n; * with the queue lock held.&n; */
DECL|function|blk_plug_device
r_void
id|blk_plug_device
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|WARN_ON
c_func
(paren
op_logical_neg
id|irqs_disabled
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|blk_queue_plugged
c_func
(paren
id|q
)paren
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
id|list_add_tail
c_func
(paren
op_amp
id|q-&gt;plug_list
comma
op_amp
id|blk_plug_list
)paren
suffix:semicolon
id|mod_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
comma
id|jiffies
op_plus
id|q-&gt;unplug_delay
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * remove the queue from the plugged list, if present. called with&n; * queue lock held and interrupts disabled.&n; */
DECL|function|blk_remove_plug
r_int
id|blk_remove_plug
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|WARN_ON
c_func
(paren
op_logical_neg
id|irqs_disabled
c_func
(paren
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|blk_queue_plugged
c_func
(paren
id|q
)paren
)paren
(brace
id|spin_lock
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|q-&gt;plug_list
)paren
suffix:semicolon
id|del_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * remove the plug and let it rip..&n; */
DECL|function|__generic_unplug_device
r_static
r_inline
r_void
id|__generic_unplug_device
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|blk_remove_plug
c_func
(paren
id|q
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
r_return
suffix:semicolon
id|del_timer
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * was plugged, fire request_fn if queue has stuff to do&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|elv_queue_empty
c_func
(paren
id|q
)paren
)paren
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * generic_unplug_device - fire a request queue&n; * @data:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   Linux uses plugging to build bigger requests queues before letting&n; *   the device have at them. If a queue is plugged, the I/O scheduler&n; *   is still adding and merging requests on the queue. Once the queue&n; *   gets unplugged (either by manually calling this function, or by&n; *   calling blk_run_queues()), the request_fn defined for the&n; *   queue is invoked and transfers started.&n; **/
DECL|function|generic_unplug_device
r_void
id|generic_unplug_device
c_func
(paren
r_void
op_star
id|data
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|data
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
)brace
DECL|function|blk_unplug_work
r_static
r_void
id|blk_unplug_work
c_func
(paren
r_void
op_star
id|data
)paren
(brace
id|generic_unplug_device
c_func
(paren
id|data
)paren
suffix:semicolon
)brace
DECL|function|blk_unplug_timeout
r_static
r_void
id|blk_unplug_timeout
c_func
(paren
r_int
r_int
id|data
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
(paren
id|request_queue_t
op_star
)paren
id|data
suffix:semicolon
id|schedule_work
c_func
(paren
op_amp
id|q-&gt;unplug_work
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_start_queue - restart a previously stopped queue&n; * @q:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   blk_start_queue() will clear the stop flag on the queue, and call&n; *   the request_fn for the queue if it was in a stopped state when&n; *   entered. Also see blk_stop_queue(). Must not be called from driver&n; *   request function due to recursion issues.&n; **/
DECL|function|blk_start_queue
r_void
id|blk_start_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|elv_queue_empty
c_func
(paren
id|q
)paren
)paren
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/**&n; * __blk_stop_queue: see blk_stop_queue()&n; *&n; * Description:&n; *  Like blk_stop_queue(), but queue_lock must be held&n; **/
DECL|function|__blk_stop_queue
r_void
id|__blk_stop_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|blk_remove_plug
c_func
(paren
id|q
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|QUEUE_FLAG_STOPPED
comma
op_amp
id|q-&gt;queue_flags
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_stop_queue - stop a queue&n; * @q:    The &amp;request_queue_t in question&n; *&n; * Description:&n; *   The Linux block layer assumes that a block driver will consume all&n; *   entries on the request queue when the request_fn strategy is called.&n; *   Often this will not happen, because of hardware limitations (queue&n; *   depth settings). If a device driver gets a &squot;queue full&squot; response,&n; *   or if it simply chooses not to queue more I/O at one point, it can&n; *   call this function to prevent the request_fn from being called until&n; *   the driver has signalled it&squot;s ready to go again. This happens by calling&n; *   blk_start_queue() to restart queue operations.&n; **/
DECL|function|blk_stop_queue
r_void
id|blk_stop_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|__blk_stop_queue
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_run_queue - run a single device queue&n; * @q&t;The queue to run&n; */
DECL|function|__blk_run_queue
r_void
id|__blk_run_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
id|blk_remove_plug
c_func
(paren
id|q
)paren
suffix:semicolon
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_run_queues - fire all plugged queues&n; *&n; * Description:&n; *   Start I/O on all plugged queues known to the block layer. Queues that&n; *   are currently stopped are ignored. This is equivalent to the older&n; *   tq_disk task queue run.&n; **/
DECL|macro|blk_plug_entry
mdefine_line|#define blk_plug_entry(entry) list_entry((entry), request_queue_t, plug_list)
DECL|function|blk_run_queues
r_void
id|blk_run_queues
c_func
(paren
r_void
)paren
(brace
id|LIST_HEAD
c_func
(paren
id|local_plug_list
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * this will happen fairly often&n;&t; */
r_if
c_cond
(paren
id|list_empty
c_func
(paren
op_amp
id|blk_plug_list
)paren
)paren
r_goto
id|out
suffix:semicolon
id|list_splice_init
c_func
(paren
op_amp
id|blk_plug_list
comma
op_amp
id|local_plug_list
)paren
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|local_plug_list
)paren
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|blk_plug_entry
c_func
(paren
id|local_plug_list.next
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
id|q
op_member_access_from_pointer
id|unplug_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
)brace
id|out
suffix:colon
id|spin_unlock_irq
c_func
(paren
op_amp
id|blk_plug_lock
)paren
suffix:semicolon
)brace
DECL|function|__blk_cleanup_queue
r_static
r_int
id|__blk_cleanup_queue
c_func
(paren
r_struct
id|request_list
op_star
id|list
)paren
(brace
r_struct
id|list_head
op_star
id|head
op_assign
op_amp
id|list-&gt;free
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
r_int
id|i
op_assign
l_int|0
suffix:semicolon
r_while
c_loop
(paren
op_logical_neg
id|list_empty
c_func
(paren
id|head
)paren
)paren
(brace
id|rq
op_assign
id|list_entry
c_func
(paren
id|head-&gt;next
comma
r_struct
id|request
comma
id|queuelist
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|kmem_cache_free
c_func
(paren
id|request_cachep
comma
id|rq
)paren
suffix:semicolon
id|i
op_increment
suffix:semicolon
)brace
r_if
c_cond
(paren
id|i
op_ne
id|list-&gt;count
)paren
id|printk
c_func
(paren
l_string|&quot;request list leak!&bslash;n&quot;
)paren
suffix:semicolon
id|list-&gt;count
op_assign
l_int|0
suffix:semicolon
r_return
id|i
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_cleanup_queue: - release a &amp;request_queue_t when it is no longer needed&n; * @q:    the request queue to be released&n; *&n; * Description:&n; *     blk_cleanup_queue is the pair to blk_init_queue().  It should&n; *     be called when a request queue is being released; typically&n; *     when a block device is being de-registered.  Currently, its&n; *     primary task it to free all the &amp;struct request structures that&n; *     were allocated to the queue.&n; * Caveat:&n; *     Hopefully the low level driver will have finished any&n; *     outstanding requests first...&n; **/
DECL|function|blk_cleanup_queue
r_void
id|blk_cleanup_queue
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_int
id|count
op_assign
(paren
id|queue_nr_requests
op_star
l_int|2
)paren
suffix:semicolon
id|elevator_exit
c_func
(paren
id|q
)paren
suffix:semicolon
id|count
op_sub_assign
id|__blk_cleanup_queue
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|READ
)braket
)paren
suffix:semicolon
id|count
op_sub_assign
id|__blk_cleanup_queue
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|WRITE
)braket
)paren
suffix:semicolon
id|del_timer_sync
c_func
(paren
op_amp
id|q-&gt;unplug_timer
)paren
suffix:semicolon
id|flush_scheduled_work
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|count
)paren
id|printk
c_func
(paren
l_string|&quot;blk_cleanup_queue: leaked requests (%d)&bslash;n&quot;
comma
id|count
)paren
suffix:semicolon
r_if
c_cond
(paren
id|blk_queue_tagged
c_func
(paren
id|q
)paren
)paren
id|blk_queue_free_tags
c_func
(paren
id|q
)paren
suffix:semicolon
id|memset
c_func
(paren
id|q
comma
l_int|0
comma
r_sizeof
(paren
op_star
id|q
)paren
)paren
suffix:semicolon
)brace
DECL|function|blk_init_free_list
r_static
r_int
id|blk_init_free_list
c_func
(paren
id|request_queue_t
op_star
id|q
)paren
(brace
r_struct
id|request_list
op_star
id|rl
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
r_int
id|i
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|READ
)braket
dot
id|free
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|WRITE
)braket
dot
id|free
)paren
suffix:semicolon
id|q-&gt;rq
(braket
id|READ
)braket
dot
id|count
op_assign
l_int|0
suffix:semicolon
id|q-&gt;rq
(braket
id|WRITE
)braket
dot
id|count
op_assign
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * Divide requests in half between read and write&n;&t; */
id|rl
op_assign
op_amp
id|q-&gt;rq
(braket
id|READ
)braket
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
(paren
id|queue_nr_requests
op_star
l_int|2
)paren
suffix:semicolon
id|i
op_increment
)paren
(brace
id|rq
op_assign
id|kmem_cache_alloc
c_func
(paren
id|request_cachep
comma
id|SLAB_KERNEL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
)paren
r_goto
id|nomem
suffix:semicolon
multiline_comment|/*&n;&t;&t; * half way through, switch to WRITE list&n;&t;&t; */
r_if
c_cond
(paren
id|i
op_eq
id|queue_nr_requests
)paren
id|rl
op_assign
op_amp
id|q-&gt;rq
(braket
id|WRITE
)braket
suffix:semicolon
id|memset
c_func
(paren
id|rq
comma
l_int|0
comma
r_sizeof
(paren
r_struct
id|request
)paren
)paren
suffix:semicolon
id|rq-&gt;rq_status
op_assign
id|RQ_INACTIVE
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|rq-&gt;queuelist
comma
op_amp
id|rl-&gt;free
)paren
suffix:semicolon
id|rl-&gt;count
op_increment
suffix:semicolon
)brace
id|init_waitqueue_head
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|READ
)braket
dot
id|wait
)paren
suffix:semicolon
id|init_waitqueue_head
c_func
(paren
op_amp
id|q-&gt;rq
(braket
id|WRITE
)braket
dot
id|wait
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|nomem
suffix:colon
id|blk_cleanup_queue
c_func
(paren
id|q
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
r_static
r_int
id|__make_request
c_func
(paren
id|request_queue_t
op_star
comma
r_struct
id|bio
op_star
)paren
suffix:semicolon
multiline_comment|/**&n; * blk_init_queue  - prepare a request queue for use with a block device&n; * @q:    The &amp;request_queue_t to be initialised&n; * @rfn:  The function to be called to process requests that have been&n; *        placed on the queue.&n; *&n; * Description:&n; *    If a block device wishes to use the standard request handling procedures,&n; *    which sorts requests and coalesces adjacent requests, then it must&n; *    call blk_init_queue().  The function @rfn will be called when there&n; *    are requests on the queue that need to be processed.  If the device&n; *    supports plugging, then @rfn may not be called immediately when requests&n; *    are available on the queue, but may be called at some time later instead.&n; *    Plugged queues are generally unplugged when a buffer belonging to one&n; *    of the requests on the queue is needed, or due to memory pressure.&n; *&n; *    @rfn is not required, or even expected, to remove all requests off the&n; *    queue, but only as many as it can handle at a time.  If it does leave&n; *    requests on the queue, it is responsible for arranging that the requests&n; *    get dealt with eventually.&n; *&n; *    The queue spin lock must be held while manipulating the requests on the&n; *    request queue.&n; *&n; * Note:&n; *    blk_init_queue() must be paired with a blk_cleanup_queue() call&n; *    when the block device is deactivated (such as at module unload).&n; **/
DECL|function|blk_init_queue
r_int
id|blk_init_queue
c_func
(paren
id|request_queue_t
op_star
id|q
comma
id|request_fn_proc
op_star
id|rfn
comma
id|spinlock_t
op_star
id|lock
)paren
(brace
r_int
id|ret
suffix:semicolon
r_if
c_cond
(paren
id|blk_init_free_list
c_func
(paren
id|q
)paren
)paren
r_return
op_minus
id|ENOMEM
suffix:semicolon
r_if
c_cond
(paren
(paren
id|ret
op_assign
id|elevator_init
c_func
(paren
id|q
comma
op_amp
id|iosched_deadline
)paren
)paren
)paren
(brace
id|blk_cleanup_queue
c_func
(paren
id|q
)paren
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
id|q-&gt;request_fn
op_assign
id|rfn
suffix:semicolon
id|q-&gt;back_merge_fn
op_assign
id|ll_back_merge_fn
suffix:semicolon
id|q-&gt;front_merge_fn
op_assign
id|ll_front_merge_fn
suffix:semicolon
id|q-&gt;merge_requests_fn
op_assign
id|ll_merge_requests_fn
suffix:semicolon
id|q-&gt;prep_rq_fn
op_assign
l_int|NULL
suffix:semicolon
id|q-&gt;unplug_fn
op_assign
id|generic_unplug_device
suffix:semicolon
id|q-&gt;queue_flags
op_assign
(paren
l_int|1
op_lshift
id|QUEUE_FLAG_CLUSTER
)paren
suffix:semicolon
id|q-&gt;queue_lock
op_assign
id|lock
suffix:semicolon
id|blk_queue_segment_boundary
c_func
(paren
id|q
comma
l_int|0xffffffff
)paren
suffix:semicolon
id|blk_queue_make_request
c_func
(paren
id|q
comma
id|__make_request
)paren
suffix:semicolon
id|blk_queue_max_segment_size
c_func
(paren
id|q
comma
id|MAX_SEGMENT_SIZE
)paren
suffix:semicolon
id|blk_queue_max_hw_segments
c_func
(paren
id|q
comma
id|MAX_HW_SEGMENTS
)paren
suffix:semicolon
id|blk_queue_max_phys_segments
c_func
(paren
id|q
comma
id|MAX_PHYS_SEGMENTS
)paren
suffix:semicolon
id|INIT_LIST_HEAD
c_func
(paren
op_amp
id|q-&gt;plug_list
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|macro|blkdev_free_rq
mdefine_line|#define blkdev_free_rq(list) list_entry((list)-&gt;next, struct request, queuelist)
multiline_comment|/*&n; * Get a free request. queue lock must be held and interrupts&n; * disabled on the way in.&n; */
DECL|function|get_request
r_static
r_struct
id|request
op_star
id|get_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_struct
id|request
op_star
id|rq
op_assign
l_int|NULL
suffix:semicolon
r_struct
id|request_list
op_star
id|rl
op_assign
id|q-&gt;rq
op_plus
id|rw
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|rl-&gt;free
)paren
)paren
(brace
id|rq
op_assign
id|blkdev_free_rq
c_func
(paren
op_amp
id|rl-&gt;free
)paren
suffix:semicolon
id|list_del_init
c_func
(paren
op_amp
id|rq-&gt;queuelist
)paren
suffix:semicolon
id|rq-&gt;ref_count
op_assign
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
op_eq
id|queue_nr_requests
)paren
id|set_queue_active
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|rl-&gt;count
op_decrement
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
OL
id|queue_congestion_on_threshold
c_func
(paren
)paren
)paren
id|set_queue_congested
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|rq-&gt;flags
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;rq_status
op_assign
id|RQ_ACTIVE
suffix:semicolon
id|rq-&gt;errors
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;special
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;buffer
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;data
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;sense
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;q
op_assign
id|q
suffix:semicolon
id|rq-&gt;rl
op_assign
id|rl
suffix:semicolon
)brace
r_return
id|rq
suffix:semicolon
)brace
multiline_comment|/*&n; * No available requests for this queue, unplug the device.&n; */
DECL|function|get_request_wait
r_static
r_struct
id|request
op_star
id|get_request_wait
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
r_struct
id|request_list
op_star
id|rl
op_assign
op_amp
id|q-&gt;rq
(braket
id|rw
)braket
suffix:semicolon
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|spin_lock_prefetch
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
r_do
(brace
r_int
id|block
op_assign
l_int|0
suffix:semicolon
id|prepare_to_wait_exclusive
c_func
(paren
op_amp
id|rl-&gt;wait
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rl-&gt;count
)paren
id|block
op_assign
l_int|1
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
id|block
)paren
id|io_schedule
c_func
(paren
)paren
suffix:semicolon
id|finish_wait
c_func
(paren
op_amp
id|rl-&gt;wait
comma
op_amp
id|wait
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|rq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
id|rq
op_eq
l_int|NULL
)paren
suffix:semicolon
r_return
id|rq
suffix:semicolon
)brace
DECL|function|blk_get_request
r_struct
id|request
op_star
id|blk_get_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
comma
r_int
id|gfp_mask
)paren
(brace
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|BUG_ON
c_func
(paren
id|rw
op_ne
id|READ
op_logical_and
id|rw
op_ne
id|WRITE
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|rq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq
op_logical_and
(paren
id|gfp_mask
op_amp
id|__GFP_WAIT
)paren
)paren
id|rq
op_assign
id|get_request_wait
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq
)paren
(brace
id|rq-&gt;flags
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;buffer
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
)brace
r_return
id|rq
suffix:semicolon
)brace
multiline_comment|/*&n; * Non-locking blk_get_request variant, for special requests from drivers.&n; */
DECL|function|__blk_get_request
r_struct
id|request
op_star
id|__blk_get_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_int
id|rw
)paren
(brace
r_struct
id|request
op_star
id|rq
suffix:semicolon
id|BUG_ON
c_func
(paren
id|rw
op_ne
id|READ
op_logical_and
id|rw
op_ne
id|WRITE
)paren
suffix:semicolon
id|rq
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rq
)paren
(brace
id|rq-&gt;flags
op_assign
l_int|0
suffix:semicolon
id|rq-&gt;buffer
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;bio
op_assign
id|rq-&gt;biotail
op_assign
l_int|NULL
suffix:semicolon
id|rq-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
)brace
r_return
id|rq
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_insert_request - insert a special request in to a request queue&n; * @q:&t;&t;request queue where request should be inserted&n; * @rq:&t;&t;request to be inserted&n; * @at_head:&t;insert request at head or tail of queue&n; * @data:&t;private data&n; *&n; * Description:&n; *    Many block devices need to execute commands asynchronously, so they don&squot;t&n; *    block the whole kernel from preemption during request execution.  This is&n; *    accomplished normally by inserting aritficial requests tagged as&n; *    REQ_SPECIAL in to the corresponding request queue, and letting them be&n; *    scheduled for actual execution by the request queue.&n; *&n; *    We have the option of inserting the head or the tail of the queue.&n; *    Typically we use the tail for new ioctls and so forth.  We use the head&n; *    of the queue for things like a QUEUE_FULL message from a device, or a&n; *    host that is unable to accept a particular command.&n; */
DECL|function|blk_insert_request
r_void
id|blk_insert_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
comma
r_int
id|at_head
comma
r_void
op_star
id|data
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
multiline_comment|/*&n;&t; * tell I/O scheduler that this isn&squot;t a regular read/write (ie it&n;&t; * must not attempt merges on this) and that it acts as a soft&n;&t; * barrier&n;&t; */
id|rq-&gt;flags
op_or_assign
id|REQ_SPECIAL
op_or
id|REQ_SOFTBARRIER
suffix:semicolon
id|rq-&gt;special
op_assign
id|data
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * If command is tagged, release the tag&n;&t; */
r_if
c_cond
(paren
id|blk_rq_tagged
c_func
(paren
id|rq
)paren
)paren
id|blk_queue_end_tag
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|__elv_add_request
c_func
(paren
id|q
comma
id|rq
comma
op_logical_neg
id|at_head
comma
l_int|0
)paren
suffix:semicolon
id|q
op_member_access_from_pointer
id|request_fn
c_func
(paren
id|q
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
DECL|function|drive_stat_acct
r_void
id|drive_stat_acct
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_int
id|nr_sectors
comma
r_int
id|new_io
)paren
(brace
r_int
id|rw
op_assign
id|rq_data_dir
c_func
(paren
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;rq_disk
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|rw
op_eq
id|READ
)paren
(brace
id|rq-&gt;rq_disk-&gt;read_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_io
)paren
id|rq-&gt;rq_disk-&gt;read_merges
op_increment
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
id|rw
op_eq
id|WRITE
)paren
(brace
id|rq-&gt;rq_disk-&gt;write_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|new_io
)paren
id|rq-&gt;rq_disk-&gt;write_merges
op_increment
suffix:semicolon
)brace
r_if
c_cond
(paren
id|new_io
)paren
(brace
id|disk_round_stats
c_func
(paren
id|rq-&gt;rq_disk
)paren
suffix:semicolon
id|rq-&gt;rq_disk-&gt;in_flight
op_increment
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * add-request adds a request to the linked list.&n; * queue lock is held and interrupts disabled, as we muck with the&n; * request queue list.&n; */
DECL|function|add_request
r_static
r_inline
r_void
id|add_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|list_head
op_star
id|insert_here
)paren
(brace
id|drive_stat_acct
c_func
(paren
id|req
comma
id|req-&gt;nr_sectors
comma
l_int|1
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * elevator indicated where it wants this request to be&n;&t; * inserted at elevator_merge time&n;&t; */
id|__elv_add_request_pos
c_func
(paren
id|q
comma
id|req
comma
id|insert_here
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * disk_round_stats()&t;- Round off the performance stats on a struct&n; * disk_stats.&n; *&n; * The average IO queue length and utilisation statistics are maintained&n; * by observing the current state of the queue length and the amount of&n; * time it has been in this state for.&n; *&n; * Normally, that accounting is done on IO completion, but that can result&n; * in more than a second&squot;s worth of IO being accounted for within any one&n; * second, leading to &gt;100% utilisation.  To deal with that, we call this&n; * function to do a round-off before returning the results when reading&n; * /proc/diskstats.  This accounts immediately for all queue usage up to&n; * the current jiffies and restarts the counters again.&n; */
DECL|function|disk_round_stats
r_void
id|disk_round_stats
c_func
(paren
r_struct
id|gendisk
op_star
id|disk
)paren
(brace
r_int
r_int
id|now
op_assign
id|jiffies
suffix:semicolon
id|disk-&gt;time_in_queue
op_add_assign
id|disk-&gt;in_flight
op_star
(paren
id|now
op_minus
id|disk-&gt;stamp
)paren
suffix:semicolon
id|disk-&gt;stamp
op_assign
id|now
suffix:semicolon
r_if
c_cond
(paren
id|disk-&gt;in_flight
)paren
id|disk-&gt;io_ticks
op_add_assign
(paren
id|now
op_minus
id|disk-&gt;stamp_idle
)paren
suffix:semicolon
id|disk-&gt;stamp_idle
op_assign
id|now
suffix:semicolon
)brace
DECL|function|__blk_put_request
r_void
id|__blk_put_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
)paren
(brace
r_struct
id|request_list
op_star
id|rl
op_assign
id|req-&gt;rl
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_decrement
id|req-&gt;ref_count
)paren
)paren
r_return
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
op_logical_neg
id|q
)paren
)paren
r_return
suffix:semicolon
id|req-&gt;rq_status
op_assign
id|RQ_INACTIVE
suffix:semicolon
id|req-&gt;q
op_assign
l_int|NULL
suffix:semicolon
id|req-&gt;rl
op_assign
l_int|NULL
suffix:semicolon
multiline_comment|/*&n;&t; * Request may not have originated from ll_rw_blk. if not,&n;&t; * it didn&squot;t come out of our reserved rq pools&n;&t; */
r_if
c_cond
(paren
id|rl
)paren
(brace
r_int
id|rw
op_assign
l_int|0
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|list_empty
c_func
(paren
op_amp
id|req-&gt;queuelist
)paren
)paren
suffix:semicolon
id|list_add
c_func
(paren
op_amp
id|req-&gt;queuelist
comma
op_amp
id|rl-&gt;free
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl
op_eq
op_amp
id|q-&gt;rq
(braket
id|WRITE
)braket
)paren
id|rw
op_assign
id|WRITE
suffix:semicolon
r_else
r_if
c_cond
(paren
id|rl
op_eq
op_amp
id|q-&gt;rq
(braket
id|READ
)braket
)paren
id|rw
op_assign
id|READ
suffix:semicolon
r_else
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|rl-&gt;count
op_increment
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
op_ge
id|queue_congestion_off_threshold
c_func
(paren
)paren
)paren
id|clear_queue_congested
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
op_eq
id|queue_nr_requests
)paren
id|clear_queue_active
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
r_if
c_cond
(paren
id|rl-&gt;count
op_ge
id|batch_requests
op_logical_and
id|waitqueue_active
c_func
(paren
op_amp
id|rl-&gt;wait
)paren
)paren
id|wake_up
c_func
(paren
op_amp
id|rl-&gt;wait
)paren
suffix:semicolon
)brace
)brace
DECL|function|blk_put_request
r_void
id|blk_put_request
c_func
(paren
r_struct
id|request
op_star
id|req
)paren
(brace
id|request_queue_t
op_star
id|q
op_assign
id|req-&gt;q
suffix:semicolon
multiline_comment|/*&n;&t; * if req-&gt;q isn&squot;t set, this request didnt originate from the&n;&t; * block layer, so it&squot;s safe to just disregard it&n;&t; */
r_if
c_cond
(paren
id|q
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|__blk_put_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/**&n; * blk_congestion_wait - wait for a queue to become uncongested&n; * @rw: READ or WRITE&n; * @timeout: timeout in jiffies&n; *&n; * Waits for up to @timeout jiffies for a queue (any queue) to exit congestion.&n; * If no queues are congested then just wait for the next request to be&n; * returned.&n; */
DECL|function|blk_congestion_wait
r_void
id|blk_congestion_wait
c_func
(paren
r_int
id|rw
comma
r_int
id|timeout
)paren
(brace
id|DEFINE_WAIT
c_func
(paren
id|wait
)paren
suffix:semicolon
r_struct
id|congestion_state
op_star
id|cs
op_assign
op_amp
id|congestion_states
(braket
id|rw
)braket
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|atomic_read
c_func
(paren
op_amp
id|cs-&gt;nr_active_queues
)paren
)paren
r_return
suffix:semicolon
id|blk_run_queues
c_func
(paren
)paren
suffix:semicolon
id|prepare_to_wait
c_func
(paren
op_amp
id|cs-&gt;wqh
comma
op_amp
id|wait
comma
id|TASK_UNINTERRUPTIBLE
)paren
suffix:semicolon
r_if
c_cond
(paren
id|atomic_read
c_func
(paren
op_amp
id|cs-&gt;nr_active_queues
)paren
)paren
id|io_schedule_timeout
c_func
(paren
id|timeout
)paren
suffix:semicolon
id|finish_wait
c_func
(paren
op_amp
id|cs-&gt;wqh
comma
op_amp
id|wait
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Has to be called with the request spinlock acquired&n; */
DECL|function|attempt_merge
r_static
r_int
id|attempt_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|req
comma
r_struct
id|request
op_star
id|next
)paren
(brace
r_if
c_cond
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
op_logical_or
op_logical_neg
id|rq_mergeable
c_func
(paren
id|next
)paren
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * not contigious&n;&t; */
r_if
c_cond
(paren
id|req-&gt;sector
op_plus
id|req-&gt;nr_sectors
op_ne
id|next-&gt;sector
)paren
r_return
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
op_ne
id|rq_data_dir
c_func
(paren
id|next
)paren
op_logical_or
id|req-&gt;rq_disk
op_ne
id|next-&gt;rq_disk
op_logical_or
id|next-&gt;waiting
op_logical_or
id|next-&gt;special
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * If we are allowed to merge, then append bio list&n;&t; * from next to rq and release next. merge_requests_fn&n;&t; * will have updated segment counts, update sector&n;&t; * counts here.&n;&t; */
r_if
c_cond
(paren
id|q
op_member_access_from_pointer
id|merge_requests_fn
c_func
(paren
id|q
comma
id|req
comma
id|next
)paren
)paren
(brace
id|req-&gt;biotail-&gt;bi_next
op_assign
id|next-&gt;bio
suffix:semicolon
id|req-&gt;biotail
op_assign
id|next-&gt;biotail
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|next-&gt;hard_nr_sectors
suffix:semicolon
id|elv_merge_requests
c_func
(paren
id|q
comma
id|req
comma
id|next
)paren
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;rq_disk
)paren
(brace
id|disk_round_stats
c_func
(paren
id|req-&gt;rq_disk
)paren
suffix:semicolon
id|req-&gt;rq_disk-&gt;in_flight
op_decrement
suffix:semicolon
)brace
id|__blk_put_request
c_func
(paren
id|q
comma
id|next
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|attempt_back_merge
r_static
r_inline
r_int
id|attempt_back_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|request
op_star
id|next
op_assign
id|elv_latter_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|next
)paren
r_return
id|attempt_merge
c_func
(paren
id|q
comma
id|rq
comma
id|next
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|attempt_front_merge
r_static
r_inline
r_int
id|attempt_front_merge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|request
op_star
id|prev
op_assign
id|elv_former_request
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|prev
)paren
r_return
id|attempt_merge
c_func
(paren
id|q
comma
id|prev
comma
id|rq
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/**&n; * blk_attempt_remerge  - attempt to remerge active head with next request&n; * @q:    The &amp;request_queue_t belonging to the device&n; * @rq:   The head request (usually)&n; *&n; * Description:&n; *    For head-active devices, the queue can easily be unplugged so quickly&n; *    that proper merging is not done on the front request. This may hurt&n; *    performance greatly for some devices. The block layer cannot safely&n; *    do merging on that first request for these queues, but the driver can&n; *    call this function and make it happen any way. Only the driver knows&n; *    when it is safe to do so.&n; **/
DECL|function|blk_attempt_remerge
r_void
id|blk_attempt_remerge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|spin_lock_irqsave
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
id|attempt_back_merge
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
id|spin_unlock_irqrestore
c_func
(paren
id|q-&gt;queue_lock
comma
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Non-locking blk_attempt_remerge variant.&n; */
DECL|function|__blk_attempt_remerge
r_void
id|__blk_attempt_remerge
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|request
op_star
id|rq
)paren
(brace
id|attempt_back_merge
c_func
(paren
id|q
comma
id|rq
)paren
suffix:semicolon
)brace
DECL|function|__make_request
r_static
r_int
id|__make_request
c_func
(paren
id|request_queue_t
op_star
id|q
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|request
op_star
id|req
comma
op_star
id|freereq
op_assign
l_int|NULL
suffix:semicolon
r_int
id|el_ret
comma
id|rw
comma
id|nr_sectors
comma
id|cur_nr_sectors
comma
id|barrier
suffix:semicolon
r_struct
id|list_head
op_star
id|insert_here
suffix:semicolon
id|sector_t
id|sector
suffix:semicolon
id|sector
op_assign
id|bio-&gt;bi_sector
suffix:semicolon
id|nr_sectors
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|cur_nr_sectors
op_assign
id|bio_iovec
c_func
(paren
id|bio
)paren
op_member_access_from_pointer
id|bv_len
op_rshift
l_int|9
suffix:semicolon
id|rw
op_assign
id|bio_data_dir
c_func
(paren
id|bio
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * low level driver can indicate that it wants pages above a&n;&t; * certain limit bounced to low memory (ie for highmem, or even&n;&t; * ISA dma in theory)&n;&t; */
id|blk_queue_bounce
c_func
(paren
id|q
comma
op_amp
id|bio
)paren
suffix:semicolon
id|spin_lock_prefetch
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|barrier
op_assign
id|test_bit
c_func
(paren
id|BIO_RW_BARRIER
comma
op_amp
id|bio-&gt;bi_rw
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
id|again
suffix:colon
id|insert_here
op_assign
l_int|NULL
suffix:semicolon
r_if
c_cond
(paren
id|blk_queue_empty
c_func
(paren
id|q
)paren
)paren
(brace
id|blk_plug_device
c_func
(paren
id|q
)paren
suffix:semicolon
r_goto
id|get_rq
suffix:semicolon
)brace
r_if
c_cond
(paren
id|barrier
)paren
r_goto
id|get_rq
suffix:semicolon
id|el_ret
op_assign
id|elv_merge
c_func
(paren
id|q
comma
op_amp
id|insert_here
comma
id|bio
)paren
suffix:semicolon
r_switch
c_cond
(paren
id|el_ret
)paren
(brace
r_case
id|ELEVATOR_BACK_MERGE
suffix:colon
id|req
op_assign
id|list_entry_rq
c_func
(paren
id|insert_here
)paren
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
op_member_access_from_pointer
id|back_merge_fn
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
)paren
(brace
id|insert_here
op_assign
op_amp
id|req-&gt;queuelist
suffix:semicolon
r_break
suffix:semicolon
)brace
id|req-&gt;biotail-&gt;bi_next
op_assign
id|bio
suffix:semicolon
id|req-&gt;biotail
op_assign
id|bio
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
id|drive_stat_acct
c_func
(paren
id|req
comma
id|nr_sectors
comma
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|attempt_back_merge
c_func
(paren
id|q
comma
id|req
)paren
)paren
id|elv_merged_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
r_case
id|ELEVATOR_FRONT_MERGE
suffix:colon
id|req
op_assign
id|list_entry_rq
c_func
(paren
id|insert_here
)paren
suffix:semicolon
id|BUG_ON
c_func
(paren
op_logical_neg
id|rq_mergeable
c_func
(paren
id|req
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
op_member_access_from_pointer
id|front_merge_fn
c_func
(paren
id|q
comma
id|req
comma
id|bio
)paren
)paren
(brace
id|insert_here
op_assign
id|req-&gt;queuelist.prev
suffix:semicolon
r_break
suffix:semicolon
)brace
id|bio-&gt;bi_next
op_assign
id|req-&gt;bio
suffix:semicolon
id|req-&gt;bio
op_assign
id|bio
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * may not be valid. if the low level driver said&n;&t;&t;&t; * it didn&squot;t need a bounce buffer then it better&n;&t;&t;&t; * not touch req-&gt;buffer either...&n;&t;&t;&t; */
id|req-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
id|req-&gt;current_nr_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;hard_cur_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;sector
op_assign
id|req-&gt;hard_sector
op_assign
id|sector
suffix:semicolon
id|req-&gt;nr_sectors
op_assign
id|req-&gt;hard_nr_sectors
op_add_assign
id|nr_sectors
suffix:semicolon
id|drive_stat_acct
c_func
(paren
id|req
comma
id|nr_sectors
comma
l_int|0
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|attempt_front_merge
c_func
(paren
id|q
comma
id|req
)paren
)paren
id|elv_merged_request
c_func
(paren
id|q
comma
id|req
)paren
suffix:semicolon
r_goto
id|out
suffix:semicolon
multiline_comment|/*&n;&t;&t; * elevator says don&squot;t/can&squot;t merge. get new request&n;&t;&t; */
r_case
id|ELEVATOR_NO_MERGE
suffix:colon
r_break
suffix:semicolon
r_default
suffix:colon
id|printk
c_func
(paren
l_string|&quot;elevator returned crap (%d)&bslash;n&quot;
comma
id|el_ret
)paren
suffix:semicolon
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * Grab a free request from the freelist - if that is empty, check&n;&t; * if we are doing read ahead and abort instead of blocking for&n;&t; * a free slot.&n;&t; */
id|get_rq
suffix:colon
r_if
c_cond
(paren
id|freereq
)paren
(brace
id|req
op_assign
id|freereq
suffix:semicolon
id|freereq
op_assign
l_int|NULL
suffix:semicolon
)brace
r_else
r_if
c_cond
(paren
(paren
id|req
op_assign
id|get_request
c_func
(paren
id|q
comma
id|rw
)paren
)paren
op_eq
l_int|NULL
)paren
(brace
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * READA bit set&n;&t;&t; */
r_if
c_cond
(paren
id|bio_flagged
c_func
(paren
id|bio
comma
id|BIO_RW_AHEAD
)paren
)paren
r_goto
id|end_io
suffix:semicolon
id|freereq
op_assign
id|get_request_wait
c_func
(paren
id|q
comma
id|rw
)paren
suffix:semicolon
id|spin_lock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_goto
id|again
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * first three bits are identical in rq-&gt;flags and bio-&gt;bi_rw,&n;&t; * see bio.h and blkdev.h&n;&t; */
id|req-&gt;flags
op_assign
(paren
id|bio-&gt;bi_rw
op_amp
l_int|7
)paren
op_or
id|REQ_CMD
suffix:semicolon
multiline_comment|/*&n;&t; * REQ_BARRIER implies no merging, but lets make it explicit&n;&t; */
r_if
c_cond
(paren
id|barrier
)paren
id|req-&gt;flags
op_or_assign
(paren
id|REQ_HARDBARRIER
op_or
id|REQ_NOMERGE
)paren
suffix:semicolon
id|req-&gt;errors
op_assign
l_int|0
suffix:semicolon
id|req-&gt;hard_sector
op_assign
id|req-&gt;sector
op_assign
id|sector
suffix:semicolon
id|req-&gt;hard_nr_sectors
op_assign
id|req-&gt;nr_sectors
op_assign
id|nr_sectors
suffix:semicolon
id|req-&gt;current_nr_sectors
op_assign
id|req-&gt;hard_cur_sectors
op_assign
id|cur_nr_sectors
suffix:semicolon
id|req-&gt;nr_phys_segments
op_assign
id|bio_phys_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|req-&gt;nr_hw_segments
op_assign
id|bio_hw_segments
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
id|req-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|bio
)paren
suffix:semicolon
multiline_comment|/* see -&gt;buffer comment above */
id|req-&gt;waiting
op_assign
l_int|NULL
suffix:semicolon
id|req-&gt;bio
op_assign
id|req-&gt;biotail
op_assign
id|bio
suffix:semicolon
id|req-&gt;rq_disk
op_assign
id|bio-&gt;bi_bdev-&gt;bd_disk
suffix:semicolon
id|req-&gt;start_time
op_assign
id|jiffies
suffix:semicolon
id|add_request
c_func
(paren
id|q
comma
id|req
comma
id|insert_here
)paren
suffix:semicolon
id|out
suffix:colon
r_if
c_cond
(paren
id|freereq
)paren
id|__blk_put_request
c_func
(paren
id|q
comma
id|freereq
)paren
suffix:semicolon
r_if
c_cond
(paren
id|blk_queue_plugged
c_func
(paren
id|q
)paren
)paren
(brace
r_int
id|nr_queued
op_assign
(paren
id|queue_nr_requests
op_minus
id|q-&gt;rq
(braket
l_int|0
)braket
dot
id|count
)paren
op_plus
(paren
id|queue_nr_requests
op_minus
id|q-&gt;rq
(braket
l_int|1
)braket
dot
id|count
)paren
suffix:semicolon
r_if
c_cond
(paren
id|nr_queued
op_eq
id|q-&gt;unplug_thresh
)paren
id|__generic_unplug_device
c_func
(paren
id|q
)paren
suffix:semicolon
)brace
id|spin_unlock_irq
c_func
(paren
id|q-&gt;queue_lock
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
id|end_io
suffix:colon
id|bio_endio
c_func
(paren
id|bio
comma
id|nr_sectors
op_lshift
l_int|9
comma
op_minus
id|EWOULDBLOCK
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
multiline_comment|/*&n; * If bio-&gt;bi_dev is a partition, remap the location&n; */
DECL|function|blk_partition_remap
r_static
r_inline
r_void
id|blk_partition_remap
c_func
(paren
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_struct
id|block_device
op_star
id|bdev
op_assign
id|bio-&gt;bi_bdev
suffix:semicolon
r_struct
id|gendisk
op_star
id|disk
op_assign
id|bdev-&gt;bd_disk
suffix:semicolon
r_struct
id|hd_struct
op_star
id|p
suffix:semicolon
r_if
c_cond
(paren
id|bdev
op_eq
id|bdev-&gt;bd_contains
)paren
r_return
suffix:semicolon
id|p
op_assign
op_amp
id|disk-&gt;part
(braket
id|bdev-&gt;bd_dev
op_minus
id|MKDEV
c_func
(paren
id|disk-&gt;major
comma
id|disk-&gt;first_minor
)paren
op_minus
l_int|1
)braket
suffix:semicolon
r_switch
c_cond
(paren
id|bio-&gt;bi_rw
)paren
(brace
r_case
id|READ
suffix:colon
id|p-&gt;read_sectors
op_add_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|p-&gt;reads
op_increment
suffix:semicolon
r_break
suffix:semicolon
r_case
id|WRITE
suffix:colon
id|p-&gt;write_sectors
op_add_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|p-&gt;writes
op_increment
suffix:semicolon
r_break
suffix:semicolon
)brace
id|bio-&gt;bi_sector
op_add_assign
id|bdev-&gt;bd_offset
suffix:semicolon
id|bio-&gt;bi_bdev
op_assign
id|bdev-&gt;bd_contains
suffix:semicolon
)brace
multiline_comment|/**&n; * generic_make_request: hand a buffer to it&squot;s device driver for I/O&n; * @bio:  The bio describing the location in memory and on the device.&n; *&n; * generic_make_request() is used to make I/O requests of block&n; * devices. It is passed a &amp;struct bio, which describes the I/O that needs&n; * to be done.&n; *&n; * generic_make_request() does not return any status.  The&n; * success/failure status of the request, along with notification of&n; * completion, is delivered asynchronously through the bio-&gt;bi_end_io&n; * function described (one day) else where.&n; *&n; * The caller of generic_make_request must make sure that bi_io_vec&n; * are set to describe the memory buffer, and that bi_dev and bi_sector are&n; * set to describe the device address, and the&n; * bi_end_io and optionally bi_private are set to describe how&n; * completion notification should be signaled.&n; *&n; * generic_make_request and the drivers it calls may use bi_next if this&n; * bio happens to be merged with someone else, and may change bi_dev and&n; * bi_sector for remaps as it sees fit.  So the values of these fields&n; * should NOT be depended on after the call to generic_make_request.&n; *&n; * */
DECL|function|generic_make_request
r_void
id|generic_make_request
c_func
(paren
r_struct
id|bio
op_star
id|bio
)paren
(brace
id|request_queue_t
op_star
id|q
suffix:semicolon
id|sector_t
id|maxsector
suffix:semicolon
r_int
id|ret
comma
id|nr_sectors
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
multiline_comment|/* Test device or partition size, when known. */
id|maxsector
op_assign
id|bio-&gt;bi_bdev-&gt;bd_inode-&gt;i_size
op_rshift
l_int|9
suffix:semicolon
r_if
c_cond
(paren
id|maxsector
)paren
(brace
id|sector_t
id|sector
op_assign
id|bio-&gt;bi_sector
suffix:semicolon
r_if
c_cond
(paren
id|maxsector
OL
id|nr_sectors
op_logical_or
id|maxsector
op_minus
id|nr_sectors
OL
id|sector
)paren
(brace
multiline_comment|/* This may well happen - the kernel calls&n;&t;&t;&t; * bread() without checking the size of the&n;&t;&t;&t; * device, e.g., when mounting a device. */
id|printk
c_func
(paren
id|KERN_INFO
l_string|&quot;attempt to access beyond end of device&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
id|KERN_INFO
l_string|&quot;%s: rw=%ld, want=%Lu, limit=%Lu&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
)paren
comma
id|bio-&gt;bi_rw
comma
(paren
r_int
r_int
r_int
)paren
id|sector
op_plus
id|nr_sectors
comma
(paren
r_int
r_int
)paren
id|maxsector
)paren
suffix:semicolon
id|set_bit
c_func
(paren
id|BIO_EOF
comma
op_amp
id|bio-&gt;bi_flags
)paren
suffix:semicolon
r_goto
id|end_io
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * Resolve the mapping until finished. (drivers are&n;&t; * still free to implement/resolve their own stacking&n;&t; * by explicitly returning 0)&n;&t; *&n;&t; * NOTE: we don&squot;t repeat the blk_size check for each new device.&n;&t; * Stacking drivers are expected to know what they are doing.&n;&t; */
r_do
(brace
id|q
op_assign
id|bdev_get_queue
c_func
(paren
id|bio-&gt;bi_bdev
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|q
)paren
(brace
id|printk
c_func
(paren
id|KERN_ERR
l_string|&quot;generic_make_request: Trying to access nonexistent block-device %s (%Lu)&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
)paren
comma
(paren
r_int
r_int
)paren
id|bio-&gt;bi_sector
)paren
suffix:semicolon
id|end_io
suffix:colon
id|bio_endio
c_func
(paren
id|bio
comma
id|bio-&gt;bi_size
comma
op_minus
id|EIO
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bio_sectors
c_func
(paren
id|bio
)paren
OG
id|q-&gt;max_sectors
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;bio too big device %s (%u &gt; %u)&bslash;n&quot;
comma
id|bdevname
c_func
(paren
id|bio-&gt;bi_bdev
)paren
comma
id|bio_sectors
c_func
(paren
id|bio
)paren
comma
id|q-&gt;max_sectors
)paren
suffix:semicolon
r_goto
id|end_io
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t; * If this device has partitions, remap block n&n;&t;&t; * of partition p to block n+start(p) of the disk.&n;&t;&t; */
id|blk_partition_remap
c_func
(paren
id|bio
)paren
suffix:semicolon
id|ret
op_assign
id|q
op_member_access_from_pointer
id|make_request_fn
c_func
(paren
id|q
comma
id|bio
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
id|ret
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * submit_bio: submit a bio to the block device layer for I/O&n; * @rw: whether to %READ or %WRITE, or maybe to %READA (read ahead)&n; * @bio: The &amp;struct bio which describes the I/O&n; *&n; * submit_bio() is very similar in purpose to generic_make_request(), and&n; * uses that function to do most of the work. Both are fairly rough&n; * interfaces, @bio must be presetup and ready for I/O.&n; *&n; */
DECL|function|submit_bio
r_int
id|submit_bio
c_func
(paren
r_int
id|rw
comma
r_struct
id|bio
op_star
id|bio
)paren
(brace
r_int
id|count
op_assign
id|bio_sectors
c_func
(paren
id|bio
)paren
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
op_logical_neg
id|bio-&gt;bi_size
)paren
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
op_logical_neg
id|bio-&gt;bi_io_vec
)paren
suffix:semicolon
id|bio-&gt;bi_rw
op_assign
id|rw
suffix:semicolon
r_if
c_cond
(paren
id|rw
op_amp
id|WRITE
)paren
id|mod_page_state
c_func
(paren
id|pgpgout
comma
id|count
)paren
suffix:semicolon
r_else
id|mod_page_state
c_func
(paren
id|pgpgin
comma
id|count
)paren
suffix:semicolon
id|generic_make_request
c_func
(paren
id|bio
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
DECL|function|blk_recalc_rq_segments
r_void
id|blk_recalc_rq_segments
c_func
(paren
r_struct
id|request
op_star
id|rq
)paren
(brace
r_struct
id|bio
op_star
id|bio
suffix:semicolon
r_int
id|nr_phys_segs
comma
id|nr_hw_segs
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|rq-&gt;bio
)paren
r_return
suffix:semicolon
id|rq-&gt;buffer
op_assign
id|bio_data
c_func
(paren
id|rq-&gt;bio
)paren
suffix:semicolon
id|nr_phys_segs
op_assign
id|nr_hw_segs
op_assign
l_int|0
suffix:semicolon
id|rq_for_each_bio
c_func
(paren
id|bio
comma
id|rq
)paren
(brace
multiline_comment|/* Force bio hw/phys segs to be recalculated. */
id|bio-&gt;bi_flags
op_and_assign
op_complement
(paren
l_int|1
op_lshift
id|BIO_SEG_VALID
)paren
suffix:semicolon
id|nr_phys_segs
op_add_assign
id|bio_phys_segments
c_func
(paren
id|rq-&gt;q
comma
id|bio
)paren
suffix:semicolon
id|nr_hw_segs
op_add_assign
id|bio_hw_segments
c_func
(paren
id|rq-&gt;q
comma
id|bio
)paren
suffix:semicolon
)brace
id|rq-&gt;nr_phys_segments
op_assign
id|nr_phys_segs
suffix:semicolon
id|rq-&gt;nr_hw_segments
op_assign
id|nr_hw_segs
suffix:semicolon
)brace
DECL|function|blk_recalc_rq_sectors
r_void
id|blk_recalc_rq_sectors
c_func
(paren
r_struct
id|request
op_star
id|rq
comma
r_int
id|nsect
)paren
(brace
r_if
c_cond
(paren
id|blk_fs_request
c_func
(paren
id|rq
)paren
)paren
(brace
id|rq-&gt;hard_sector
op_add_assign
id|nsect
suffix:semicolon
id|rq-&gt;nr_sectors
op_assign
id|rq-&gt;hard_nr_sectors
op_sub_assign
id|nsect
suffix:semicolon
id|rq-&gt;sector
op_assign
id|rq-&gt;hard_sector
suffix:semicolon
id|rq-&gt;current_nr_sectors
op_assign
id|bio_iovec
c_func
(paren
id|rq-&gt;bio
)paren
op_member_access_from_pointer
id|bv_len
op_rshift
l_int|9
suffix:semicolon
id|rq-&gt;hard_cur_sectors
op_assign
id|rq-&gt;current_nr_sectors
suffix:semicolon
multiline_comment|/*&n;&t;&t; * if total number of sectors is less than the first segment&n;&t;&t; * size, something has gone terribly wrong&n;&t;&t; */
r_if
c_cond
(paren
id|rq-&gt;nr_sectors
OL
id|rq-&gt;current_nr_sectors
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;blk: request botched&bslash;n&quot;
)paren
suffix:semicolon
id|rq-&gt;nr_sectors
op_assign
id|rq-&gt;current_nr_sectors
suffix:semicolon
)brace
)brace
)brace
DECL|function|__end_that_request_first
r_static
r_int
id|__end_that_request_first
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_bytes
)paren
(brace
r_int
id|total_bytes
comma
id|bio_nbytes
comma
id|error
op_assign
l_int|0
comma
id|next_idx
op_assign
l_int|0
suffix:semicolon
r_struct
id|bio
op_star
id|bio
suffix:semicolon
multiline_comment|/*&n;&t; * for a REQ_BLOCK_PC request, we want to carry any eventual&n;&t; * sense key with us all the way through&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|blk_pc_request
c_func
(paren
id|req
)paren
)paren
id|req-&gt;errors
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|uptodate
)paren
(brace
id|error
op_assign
op_minus
id|EIO
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
(paren
id|req-&gt;flags
op_amp
id|REQ_QUIET
)paren
)paren
id|printk
c_func
(paren
l_string|&quot;end_request: I/O error, dev %s, sector %llu&bslash;n&quot;
comma
id|req-&gt;rq_disk
ques
c_cond
id|req-&gt;rq_disk-&gt;disk_name
suffix:colon
l_string|&quot;?&quot;
comma
(paren
r_int
r_int
r_int
)paren
id|req-&gt;sector
)paren
suffix:semicolon
)brace
id|total_bytes
op_assign
id|bio_nbytes
op_assign
l_int|0
suffix:semicolon
r_while
c_loop
(paren
(paren
id|bio
op_assign
id|req-&gt;bio
)paren
)paren
(brace
r_int
id|nbytes
suffix:semicolon
r_if
c_cond
(paren
id|nr_bytes
op_ge
id|bio-&gt;bi_size
)paren
(brace
id|req-&gt;bio
op_assign
id|bio-&gt;bi_next
suffix:semicolon
id|nbytes
op_assign
id|bio-&gt;bi_size
suffix:semicolon
id|bio_endio
c_func
(paren
id|bio
comma
id|nbytes
comma
id|error
)paren
suffix:semicolon
id|next_idx
op_assign
l_int|0
suffix:semicolon
id|bio_nbytes
op_assign
l_int|0
suffix:semicolon
)brace
r_else
(brace
r_int
id|idx
op_assign
id|bio-&gt;bi_idx
op_plus
id|next_idx
suffix:semicolon
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|bio-&gt;bi_idx
op_ge
id|bio-&gt;bi_vcnt
)paren
)paren
(brace
id|blk_dump_rq_flags
c_func
(paren
id|req
comma
l_string|&quot;__end_that&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;%s: bio idx %d &gt;= vcnt %d&bslash;n&quot;
comma
id|__FUNCTION__
comma
id|bio-&gt;bi_idx
comma
id|bio-&gt;bi_vcnt
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
id|nbytes
op_assign
id|bio_iovec_idx
c_func
(paren
id|bio
comma
id|idx
)paren
op_member_access_from_pointer
id|bv_len
suffix:semicolon
id|BIO_BUG_ON
c_func
(paren
id|nbytes
OG
id|bio-&gt;bi_size
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * not a complete bvec done&n;&t;&t;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|nbytes
OG
id|nr_bytes
)paren
)paren
(brace
id|bio_iovec
c_func
(paren
id|bio
)paren
op_member_access_from_pointer
id|bv_offset
op_add_assign
id|nr_bytes
suffix:semicolon
id|bio_iovec
c_func
(paren
id|bio
)paren
op_member_access_from_pointer
id|bv_len
op_sub_assign
id|nr_bytes
suffix:semicolon
id|bio_nbytes
op_add_assign
id|nr_bytes
suffix:semicolon
id|total_bytes
op_add_assign
id|nr_bytes
suffix:semicolon
r_break
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t;&t; * advance to the next vector&n;&t;&t;&t; */
id|next_idx
op_increment
suffix:semicolon
id|bio_nbytes
op_add_assign
id|nbytes
suffix:semicolon
)brace
id|total_bytes
op_add_assign
id|nbytes
suffix:semicolon
id|nr_bytes
op_sub_assign
id|nbytes
suffix:semicolon
r_if
c_cond
(paren
(paren
id|bio
op_assign
id|req-&gt;bio
)paren
)paren
(brace
multiline_comment|/*&n;&t;&t;&t; * end more in this run, or just return &squot;not-done&squot;&n;&t;&t;&t; */
r_if
c_cond
(paren
id|unlikely
c_func
(paren
id|nr_bytes
op_le
l_int|0
)paren
)paren
r_break
suffix:semicolon
)brace
)brace
multiline_comment|/*&n;&t; * completely done&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|req-&gt;bio
)paren
r_return
l_int|0
suffix:semicolon
multiline_comment|/*&n;&t; * if the request wasn&squot;t completed, update state&n;&t; */
r_if
c_cond
(paren
id|bio_nbytes
)paren
(brace
id|bio_endio
c_func
(paren
id|bio
comma
id|bio_nbytes
comma
id|error
)paren
suffix:semicolon
id|req-&gt;bio-&gt;bi_idx
op_add_assign
id|next_idx
suffix:semicolon
)brace
id|blk_recalc_rq_sectors
c_func
(paren
id|req
comma
id|total_bytes
op_rshift
l_int|9
)paren
suffix:semicolon
id|blk_recalc_rq_segments
c_func
(paren
id|req
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
multiline_comment|/**&n; * end_that_request_first - end I/O on a request&n; * @req:      the request being processed&n; * @uptodate: 0 for I/O error&n; * @nr_sectors: number of sectors to end I/O on&n; *&n; * Description:&n; *     Ends I/O on a number of sectors attached to @req, and sets it up&n; *     for the next range of segments (if any) in the cluster.&n; *&n; * Return:&n; *     0 - we are done with this request, call end_that_request_last()&n; *     1 - still buffers pending for this request&n; **/
DECL|function|end_that_request_first
r_int
id|end_that_request_first
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_sectors
)paren
(brace
r_return
id|__end_that_request_first
c_func
(paren
id|req
comma
id|uptodate
comma
id|nr_sectors
op_lshift
l_int|9
)paren
suffix:semicolon
)brace
multiline_comment|/**&n; * end_that_request_chunk - end I/O on a request&n; * @req:      the request being processed&n; * @uptodate: 0 for I/O error&n; * @nr_bytes: number of bytes to complete&n; *&n; * Description:&n; *     Ends I/O on a number of bytes attached to @req, and sets it up&n; *     for the next range of segments (if any). Like end_that_request_first(),&n; *     but deals with bytes instead of sectors.&n; *&n; * Return:&n; *     0 - we are done with this request, call end_that_request_last()&n; *     1 - still buffers pending for this request&n; **/
DECL|function|end_that_request_chunk
r_int
id|end_that_request_chunk
c_func
(paren
r_struct
id|request
op_star
id|req
comma
r_int
id|uptodate
comma
r_int
id|nr_bytes
)paren
(brace
r_return
id|__end_that_request_first
c_func
(paren
id|req
comma
id|uptodate
comma
id|nr_bytes
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * queue lock must be held&n; */
DECL|function|end_that_request_last
r_void
id|end_that_request_last
c_func
(paren
r_struct
id|request
op_star
id|req
)paren
(brace
r_struct
id|gendisk
op_star
id|disk
op_assign
id|req-&gt;rq_disk
suffix:semicolon
r_if
c_cond
(paren
id|req-&gt;waiting
)paren
id|complete
c_func
(paren
id|req-&gt;waiting
)paren
suffix:semicolon
r_if
c_cond
(paren
id|disk
)paren
(brace
r_int
r_int
id|duration
op_assign
id|jiffies
op_minus
id|req-&gt;start_time
suffix:semicolon
r_switch
c_cond
(paren
id|rq_data_dir
c_func
(paren
id|req
)paren
)paren
(brace
r_case
id|WRITE
suffix:colon
id|disk-&gt;writes
op_increment
suffix:semicolon
id|disk-&gt;write_ticks
op_add_assign
id|duration
suffix:semicolon
r_break
suffix:semicolon
r_case
id|READ
suffix:colon
id|disk-&gt;reads
op_increment
suffix:semicolon
id|disk-&gt;read_ticks
op_add_assign
id|duration
suffix:semicolon
r_break
suffix:semicolon
)brace
id|disk_round_stats
c_func
(paren
id|disk
)paren
suffix:semicolon
id|disk-&gt;in_flight
op_decrement
suffix:semicolon
)brace
id|__blk_put_request
c_func
(paren
id|req-&gt;q
comma
id|req
)paren
suffix:semicolon
)brace
DECL|function|blk_dev_init
r_int
id|__init
id|blk_dev_init
c_func
(paren
r_void
)paren
(brace
r_int
id|total_ram
op_assign
id|nr_free_pages
c_func
(paren
)paren
op_lshift
(paren
id|PAGE_SHIFT
op_minus
l_int|10
)paren
suffix:semicolon
r_int
id|i
suffix:semicolon
id|request_cachep
op_assign
id|kmem_cache_create
c_func
(paren
l_string|&quot;blkdev_requests&quot;
comma
r_sizeof
(paren
r_struct
id|request
)paren
comma
l_int|0
comma
l_int|0
comma
l_int|NULL
comma
l_int|NULL
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|request_cachep
)paren
id|panic
c_func
(paren
l_string|&quot;Can&squot;t create request pool slab cache&bslash;n&quot;
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Free request slots per queue.  One per quarter-megabyte.&n;&t; * We use this many requests for reads, and this many for writes.&n;&t; */
id|queue_nr_requests
op_assign
(paren
id|total_ram
op_rshift
l_int|9
)paren
op_amp
op_complement
l_int|7
suffix:semicolon
r_if
c_cond
(paren
id|queue_nr_requests
OL
l_int|16
)paren
id|queue_nr_requests
op_assign
l_int|16
suffix:semicolon
r_if
c_cond
(paren
id|queue_nr_requests
OG
l_int|128
)paren
id|queue_nr_requests
op_assign
l_int|128
suffix:semicolon
id|batch_requests
op_assign
id|queue_nr_requests
op_div
l_int|8
suffix:semicolon
r_if
c_cond
(paren
id|batch_requests
OG
l_int|8
)paren
id|batch_requests
op_assign
l_int|8
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;block request queues:&bslash;n&quot;
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot; %d requests per read queue&bslash;n&quot;
comma
id|queue_nr_requests
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot; %d requests per write queue&bslash;n&quot;
comma
id|queue_nr_requests
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot; %d requests per batch&bslash;n&quot;
comma
id|batch_requests
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot; enter congestion at %d&bslash;n&quot;
comma
id|queue_congestion_on_threshold
c_func
(paren
)paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot; exit congestion at %d&bslash;n&quot;
comma
id|queue_congestion_off_threshold
c_func
(paren
)paren
)paren
suffix:semicolon
id|blk_max_low_pfn
op_assign
id|max_low_pfn
suffix:semicolon
id|blk_max_pfn
op_assign
id|max_pfn
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|ARRAY_SIZE
c_func
(paren
id|congestion_states
)paren
suffix:semicolon
id|i
op_increment
)paren
(brace
id|init_waitqueue_head
c_func
(paren
op_amp
id|congestion_states
(braket
id|i
)braket
dot
id|wqh
)paren
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|congestion_states
(braket
id|i
)braket
dot
id|nr_congested_queues
comma
l_int|0
)paren
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|congestion_states
(braket
id|i
)braket
dot
id|nr_active_queues
comma
l_int|0
)paren
suffix:semicolon
)brace
r_return
l_int|0
suffix:semicolon
)brace
suffix:semicolon
DECL|variable|end_that_request_first
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_first
)paren
suffix:semicolon
DECL|variable|end_that_request_chunk
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_chunk
)paren
suffix:semicolon
DECL|variable|end_that_request_last
id|EXPORT_SYMBOL
c_func
(paren
id|end_that_request_last
)paren
suffix:semicolon
DECL|variable|blk_init_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_init_queue
)paren
suffix:semicolon
DECL|variable|blk_cleanup_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_cleanup_queue
)paren
suffix:semicolon
DECL|variable|blk_queue_make_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_make_request
)paren
suffix:semicolon
DECL|variable|blk_queue_bounce_limit
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_bounce_limit
)paren
suffix:semicolon
DECL|variable|generic_make_request
id|EXPORT_SYMBOL
c_func
(paren
id|generic_make_request
)paren
suffix:semicolon
DECL|variable|generic_unplug_device
id|EXPORT_SYMBOL
c_func
(paren
id|generic_unplug_device
)paren
suffix:semicolon
DECL|variable|blk_plug_device
id|EXPORT_SYMBOL
c_func
(paren
id|blk_plug_device
)paren
suffix:semicolon
DECL|variable|blk_remove_plug
id|EXPORT_SYMBOL
c_func
(paren
id|blk_remove_plug
)paren
suffix:semicolon
DECL|variable|blk_attempt_remerge
id|EXPORT_SYMBOL
c_func
(paren
id|blk_attempt_remerge
)paren
suffix:semicolon
DECL|variable|__blk_attempt_remerge
id|EXPORT_SYMBOL
c_func
(paren
id|__blk_attempt_remerge
)paren
suffix:semicolon
DECL|variable|blk_max_low_pfn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_max_low_pfn
)paren
suffix:semicolon
DECL|variable|blk_max_pfn
id|EXPORT_SYMBOL
c_func
(paren
id|blk_max_pfn
)paren
suffix:semicolon
DECL|variable|blk_queue_max_sectors
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_sectors
)paren
suffix:semicolon
DECL|variable|blk_queue_max_phys_segments
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_phys_segments
)paren
suffix:semicolon
DECL|variable|blk_queue_max_hw_segments
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_hw_segments
)paren
suffix:semicolon
DECL|variable|blk_queue_max_segment_size
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_max_segment_size
)paren
suffix:semicolon
DECL|variable|blk_queue_hardsect_size
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_hardsect_size
)paren
suffix:semicolon
DECL|variable|blk_queue_segment_boundary
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_segment_boundary
)paren
suffix:semicolon
DECL|variable|blk_queue_dma_alignment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_dma_alignment
)paren
suffix:semicolon
DECL|variable|blk_rq_map_sg
id|EXPORT_SYMBOL
c_func
(paren
id|blk_rq_map_sg
)paren
suffix:semicolon
DECL|variable|blk_nohighio
id|EXPORT_SYMBOL
c_func
(paren
id|blk_nohighio
)paren
suffix:semicolon
DECL|variable|blk_dump_rq_flags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_dump_rq_flags
)paren
suffix:semicolon
DECL|variable|submit_bio
id|EXPORT_SYMBOL
c_func
(paren
id|submit_bio
)paren
suffix:semicolon
DECL|variable|blk_queue_assign_lock
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_assign_lock
)paren
suffix:semicolon
DECL|variable|blk_phys_contig_segment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_phys_contig_segment
)paren
suffix:semicolon
DECL|variable|blk_hw_contig_segment
id|EXPORT_SYMBOL
c_func
(paren
id|blk_hw_contig_segment
)paren
suffix:semicolon
DECL|variable|blk_get_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_get_request
)paren
suffix:semicolon
DECL|variable|__blk_get_request
id|EXPORT_SYMBOL
c_func
(paren
id|__blk_get_request
)paren
suffix:semicolon
DECL|variable|blk_put_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_put_request
)paren
suffix:semicolon
DECL|variable|blk_insert_request
id|EXPORT_SYMBOL
c_func
(paren
id|blk_insert_request
)paren
suffix:semicolon
DECL|variable|blk_queue_prep_rq
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_prep_rq
)paren
suffix:semicolon
DECL|variable|blk_queue_merge_bvec
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_merge_bvec
)paren
suffix:semicolon
DECL|variable|blk_queue_find_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_find_tag
)paren
suffix:semicolon
DECL|variable|blk_queue_init_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_init_tags
)paren
suffix:semicolon
DECL|variable|blk_queue_free_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_free_tags
)paren
suffix:semicolon
DECL|variable|blk_queue_start_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_start_tag
)paren
suffix:semicolon
DECL|variable|blk_queue_end_tag
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_end_tag
)paren
suffix:semicolon
DECL|variable|blk_queue_invalidate_tags
id|EXPORT_SYMBOL
c_func
(paren
id|blk_queue_invalidate_tags
)paren
suffix:semicolon
DECL|variable|blk_start_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_start_queue
)paren
suffix:semicolon
DECL|variable|blk_stop_queue
id|EXPORT_SYMBOL
c_func
(paren
id|blk_stop_queue
)paren
suffix:semicolon
DECL|variable|__blk_stop_queue
id|EXPORT_SYMBOL
c_func
(paren
id|__blk_stop_queue
)paren
suffix:semicolon
DECL|variable|__blk_run_queue
id|EXPORT_SYMBOL
c_func
(paren
id|__blk_run_queue
)paren
suffix:semicolon
DECL|variable|blk_run_queues
id|EXPORT_SYMBOL
c_func
(paren
id|blk_run_queues
)paren
suffix:semicolon
eof
